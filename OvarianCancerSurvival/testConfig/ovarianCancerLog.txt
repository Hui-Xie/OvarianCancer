n# May 24th, Monday, 2021
Micorsoft Azure Cloud Service.
DSVM:
https://docs.microsoft.com/en-us/azure/machine-learning/data-science-virtual-machine/overview

A new idea:
1  Use VAE model to reconstruct abdominal CT images.
   Use the space compress algorithm of VAE to get size-reduced latent space,  in order to reduce overfitting.
2  the latent vector of the VAE model is regularized.
   The size of latent vector should be less than the numbers of training sample.
3  Use the latent vector to predict all possible cancer clinical label and OC and benign masses.
   Here the clinical label acts as some regualization facgtors over latent space input.

A question:
In your medical knowledge, how do determine a CT image is a benign mass, instead of an ovarian cancer?
In other words, how do get the benign mass label or ovarian cancer label for all abdominal CT images?

I think the benign mass vs ovarian caner labels are different from the surgical optimal survival result which I have worked last year.
The surgical optimal survival result is decided by 3 factors: survival 3 months, positive chemo response, and optimal cytoreduction.
I guess that it may exist a case that surgical optimal is good, but this patient dies after 6 months as it is a real ovarian cancer, instead of benign mass.
It may also exist a case that an aged patient has a benign mass, but he dies within 3 months after sugery as serious complication and side effect of the surgery.

In some sense, I think predicting the benign mass and ovarian cancer is more feasible than predicting the surgical optimal result which really is decided by a lot of extra factors.

===================================================================================================
Gonzalez Jesus Relied in May 25th, 2021:
A benign mass is decided when we do surgery and the pathologist say is benign. Is a dichotomous classification: benign vs malignant.
The problem: there is only imaging clues and symptoms before surgery that are suggestive of benign vs malignant, not a good method.
This has not changed for the last 20 years. Now we have a possibility to do so.

Thank you very much, professor Jesus.

Your answer is very informative.

It shows that the traditional method uses the pathology check of the tissue samples excised from heavy surgeries
to determine the tumor is benign or malignant. It is very expensive in medical cost and very onerous in patient's life quality.

Now, we hope to use the tumor distribution in body, texture, pattern, location, size etc information directly from the abdominal CT image without expensive surgeries to
judge whether the tumor is benign or malignant. It is very valuable in medical application.

Now I have more confidence that predicting benign or malignant tumor using deep learning is more feasible than predicting the surgical optimal result like before.

For this kind of dichotomous classification, more patient cases ,better prediction result we can get.
And we do not need tedious segmentation, just collecting more raw patient CT images and his benign and malignant label is enough.

==================================================================================================================
The choosing principle of tumor tissue samples and pathology judging criterion of benign mass or malignant ovarian cancer.

Deep learniing is not an super-machine which can do anything.
A better deep learning network always mimics domain knowledge to better locate features or ROI, especially at a small number of training cases.

The answers to belows questions will help us better design network adaptive to our application.

Further questions:
1   What is the principle of choosing tumor tissue sample after surgery to send to pathology check?
    For example, one sample from primary cancer, one sample from the metastasis, or one sample near ovaries.
    Or tumor tissue color/texture is some consideration to send to pathology check? Or something else.

2   How is a pathologist to judge a tumor tissue sample is benign and malignant?
    The pathologist just observes the tumor tissue morphology, or dose he need to do some bio-chemo experiments to culture the tissue cells and then observe the reproductive result?
    What is the major factors to let a pathologist judge a tumor tissue sample is benign or malignant?
    Size, color, texture, morphology, or something else?
========================================================================================================================

Douglas replied on May 25th, 2021:
We always send tissue for pathology of the main specimen. For instance if it is an ovarian mass that we are removing,
we will always send that ovary for pathology. We will often send other nearby structures for pathology as well if those were removed.
For instance if there's an ovarian mass removed but we do a full hysterectomy the uterus will also be sent for pathology.
Occasionally there is an additional "suspicious" piece of tissue sent for pathology - that would often be just based on
 how it visually looks during surgery. For instance it might be friable tissue or plaque-like.
 For "full staging" procedures that are performed once a primary malignancy is identified on frozen pathology
 we take the following in ovarian cancer: peritoneal cytology, multiple peritoneal biopsies, omentectomy, pelvic and para-aortic lymph node samples.

The pathologist uses their experience to check the morphology under the microscope.
This is somewhat subjective but there are specific signs and features that they are looking for that can often be subtle.
The changes are exactly as you said - size, shape, color of cells and their intracellular components.
How the cells interact with each other - for instance if it's invading surrounding areas, involving nerves, etc.
So primarily morphology - but sometimes will also do immunostaining or other molecular testing as you alluded to,
often to either to make a more specific diagnosis or when the morphology is equivocal.
It takes an entire residency to become competent in this so I'm afraid I don't have more information specifically
but maybe could put you in touch with our pathologist who does to answer this in more detail if needed.
=========================================================================================================================

Hui answer on May 26th, 2021.

n other words, the samples sent to pathology include main ovarian mass, ovary, uterus, suspicious tissues(friable tissue, plaque tissue),  peritoneum, omentum, pelvic and periaortic lymph nodes, etc.
They include broad tissues in the abdomen. The sample choice implies that the whole CT abdominal volume, instead of the primary cancer region, as input to a deep learning network is a better choice.
And a Hi-resolution volume image may help, as it needs some subtle information on the peritoneum, omentum, peri-aorta.

Now the microscope pathology will give us a big challenge. Our CT image physical resolution is 0.7mm x 0.7mm x 3 mm in general for each voxel, while the cancer cell has a size of about 10 um,
 which means one CT voxel may contain 1.47 million cancer cells (700x700x3000/(10x10x10)), which can not give us information about the cancer cell morphology, shape, interaction, invading, etc information.
 Especially, when the morphology is equivocal, more molecular tests are needed, which is unreachable by CT image information.

In other words, CT images can not offer molecular-level information which is exactly the basis of pathology analysis for benign or malignant judgement.
While CT images offer possible cancer distribution, region shape, abnormal tissue in a human-naked-eye resolution.
This information in the CT image may only offer a low-accuracy prediction to the benign or malignant prediction, as it lacks molecular-level information.

Now I have an initial prediction accuracy estimation on ovarian cancer projects, as deep learning is not a super machine exceeding human intelligence.
Project C: use pathology microscope images of ovarian mass tissues to predict benign or malignant. Directly use cell patterns and interaction to do predict. I estimate prediction accuracy can get about 80-90%.
Project B: use abdominal CT image to predict benign or malignant. Predict current status by rough CT information. I estimate the prediction accuracy can get about 60%-70%.
Project A: use abdominal CT image to predict the surgical optimal result. Predict the future by rough CT information. I estimate the prediction accuracy can get about 50-60%.

For project B, I think we need to put some effort into the medical knowledge or history medical experiments. Some questions are:
A.  Does the CT image information plus some clinical data have enough information to predict the benign or malignant tumor?
B.  What are the medical experiments or history knowledge to support the logic deducing judgment from abdominal CT images to benign/malignant judgment?
I suspect the review experts in the OCRA may also ask these questions in the grant review process.
If the answers to the above 2 questions are not solid, I suspect the prediction result will be a low-accuracy whatever we spend a lot of efforts on it.
========================================================================================================================

Jesus answered on May 27th, 2021

You are overthinking this.

The main objective would be to differentiate benign from malignant. Project B, if you will.

We will not use microscopic at this time, because there are many types of tumors (benign and malignant) and that only could complicate things without any specific gain.
=========================================================================================================================================================================
Yes. Professor Jesus. You are right that we do not use the microscope image as input at this time.

I just gave an assumed context as project C. If an assumed deep learning network taking input of tumor microscope images would directly learn the experience and knowledge of a pathologist to get a high prediction accuracy.

At this time, we can assume that abdominal CT images have similar resolution with human-naked eyes. CT image has a 3D gray 0.7mm x0.7mm x3mm resolution volume images,
while when a surgeon opens the abdomen of a woman, he can also see 3D color 1mm x1 mm x1mm resolution volume images in front of his eyes.  The advantage of CT images is we can get similar image resolution without the expensive surgery.

Now the deep learning network of our project B needs to learn and mimic the knowledge and experience of the ovarian cancer surgeon.
Professor Jesus, as an ovarian cancer expert and surgeon, your experience and knowledge on the below questions will help us better understand and design our project B network.

A.  What is your criterion with your naked eyes to judge the tumor(benign or malignant) before sending the removing samples to pathology? For example, tissue color, mass distribution, tissue texture, tumor size, or something else? More details, more helpful.
B.  According to your experience, what is the prediction accuracy of tumor (benign or malignant) just using your naked eyes, comparing with the return result from pathology?
     My intuition is that our final successful network prediction accuracy will be similar to your prediction accuracy with your naked eyes.
C.  When you use your naked eyes to judge the tumor(benign or malignant), do you use the age, BMI, blood type, blood pressure, etc clinical information in your thinking? Or what is other information for your thinking in the judgment?
   This answer will help us on how to integrate the clinical information into our network.

=============================================================================================================================================================================================================================================




























Note that we should handle 200 OC + 400 benign cases:
total 600 cases.
case size: 600x600x200  pixels,   600*600*200*4 = 300 MB
storage space: 300MB/case * 600 case/experiment *20 experiment =  4TB
memory requirement: 300 MB/case * 16 case/batch * 8   = 40GB, where 8 is considering input,network architecture of VAE


Yes. The Data Science Virtual Machine (DSVM) for Linux from Microsoft Azure will upgrade our current bottle-neck
computing resource and data access speed. As our input abdominal volume CT image has a image size of 600x600x200 in pixel,
which needs 300 MB each case for loading into memory.  Considering a batch size 16 for deep learning training,
it needs  300MB x16 = 4.7GB for input space only. Plus outpace space, network tensor space,  and back propagation space,
it needs about 40GB GPU memory for training.  We have total 600 cases, but it can not load into memory for all at one time.
The SSD offered by Azure will accelerate the batch loading speed about 10 times (1.2GB/s in SSD vs 100MB/s in HDD general),
 which will explicitly improve our training speed.

at Aug 9th, 2019, merge the 1st and 2nd batch data, excluding the non-standard data:

Statistics Information of Images:
Image Directories:
    /home/hxie1/data/OvarianCancerCT/rawNrrd/images
Totally compute 220  image files
Dimension = 3
Dimension     X      Y    Z
MinSize:    399   493   38
MaxSize:    736   736   633
MeanSize:    515   518   198
MinOrigin:    -275.7   -494.012   -937.3
MaxOrigin:    -142.198   -18.3321   1904.63
MeanOrigin:    -192.097   -280.586   56.2154
MinSpacing:    0.585938   0.585938   0.699982
MaxSpacing:    1   1   5
MeanSpacing:    0.747252   0.747255   2.90267
MinPhysicalSize:    300   300   190
MaxPhysicalSize:    502.018   508   700.247
MeanPhysicalSize:    384.633   387.387   435.725
=======End of Image Files Statistics==============




# March 27th, Saturday, 2021
=========Summary Ovarian Cancer Experiments================

==========Data==========================

=========Segmentation===================


=========Response Prediction============
