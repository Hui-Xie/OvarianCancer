# May 17th, Monday, 2021:
Dauphin et al argue that the difficulty in minimizing the loss arises from saddle points rather than poor local minima.
So increasing learning rate at this time is not a bad idea.

discriminative fine tuning: the ealier layers has smaller learning rate.
The intuition behind this method of configuration is that the first few layers would typically contain very granular
details of the data, such as the lines and the edges — of which we normally wouldn’t want to change much and like to
 retain it’s information. As such, there’s not much need to change their weights by a big amount.


A rule of thumb here is to double the learning rate as you double the batch size.
One of the downsides of using large batch sizes, however, is that they might lead to solutions that
generalize worse than those trained with smaller batches.

torch.tensor() always copies data. If you have a numpy array that you want to convert, use torch.as_tensor() or torch.from_numpy() to avoid copying the data.

Momentum or SGD with momentum is method which helps accelerate gradients vectors in the right directions, thus leading to faster converging.
Instead, we’re estimating it on a small batch. Which means we’re not always going in the optimal direction, because our derivatives are ‘noisy’.
Just like in my graphs above. So, exponentially weighed averages can provide us a better estimate which is closer to the actual derivate than our noisy calculations.
This is one reason why momentum might work better than classic SGD.


Current: learningR = 0.1, patience=20, reduceLrOnPlateau:

If use OneCycleLR:  minLr = 1.0e-5, maxLr = 0.1.
Task:
1  write a separate training for IVUS, use OneCycleLR + SGD   --done
2  pixel size chaneg to um unit.   --cancel.
3  use validation loss min to save network parameters.  --done
4  add L1Loss weight in Q nework.   --done.
   need to modify other config.     --done
5  not use muError measurement.      --done






# May 15th, Satursday, 2021:
trained 4 networks:
40650 ?        Rl   2019:14 python3 ./SurfaceSubnet_Train.py ./testConfig_IVUS/expIVUS_20210514_SurfaceSubnetQ64_10percent_A_skm2.yaml
51171 ?        Rl   15549:49 python3 ./SurfaceSubnet_Train.py ./testConfig_IVUS/expIVUS_20210514_YufanHe_10percent_A_skm2.yaml
59848 ?        Rl   13972:27 python3 ./SurfaceSubnet_Train.py ./testConfig_IVUS/expIVUS_20210514_YufanHe_100percent_A_skm2.yaml
75457 ?        Rl   1935:45 python3 ./SurfaceSubnet_Train.py ./testConfig_IVUS/expIVUS_20210514_SurfaceSubnetQ64_100percent_A_skm2.yaml

Prediction result dir: /raid001/users/hxie1/data/IVUS/polarNumpy/log/SurfaceSubnet_Q/expIVUS_20210514_SurfaceSubnetQ64_100percent_A_skm2/testResult/text
>> Test set has 326 images comparing with ground truth at /raid001/users/hxie1/data/IVUS/Test_Set/Data_set_B/LABELS_obs2_v1.
              Jacc		   Dice		   HD		   PAD
>> Lumen:	 0.84±0.15	0.90±0.13	0.53±0.52	0.11±0.16	>>
   Media:	 0.86±0.14	0.92±0.12	0.67±0.56	0.09±0.14	>>


Prediction result dir: /raid001/users/hxie1/data/IVUS/polarNumpy/log/SurfacesUnet_YufanHe_2/expIVUS_20210514_YufanHe_100percent_A_skm2/testResult/text
>> Test set has 326 images comparing with ground truth at /raid001/users/hxie1/data/IVUS/Test_Set/Data_set_B/LABELS_obs2_v1.
>> >> >> >> 	Jacc		Dice		HD		     PAD
>> Lumen:	>> 0.84±0.16	0.90±0.15	0.45±0.48	0.11±0.17	>>
   Media:	>> 0.86±0.15	0.91±0.14	0.62±0.44	0.09±0.15	>>

Prediction result dir: /raid001/users/hxie1/data/IVUS/polarNumpy_10percent/log/SurfaceSubnet_Q/expIVUS_20210514_SurfaceSubnetQ64_10percent_A_skm2/testResult/text
>> Test set has 326 images comparing with ground truth at /raid001/users/hxie1/data/IVUS/Test_Set/Data_set_B/LABELS_obs2_v1.
>> >> >> >> >> Jacc		    Dice		 HD		     PAD
>> Lumen:	>> 0.82±0.12	0.89±0.11	0.58±0.39	0.12±0.15	>>
   Media:	>> 0.79±0.22	0.86±0.21	0.89±0.51	0.14±0.21	>>

Prediction result dir: /raid001/users/hxie1/data/IVUS/polarNumpy_10percent/log/SurfacesUnet_YufanHe_2/expIVUS_20210514_YufanHe_10percent_A_skm2/testResult/text
>> Test set has 326 images comparing with ground truth at /raid001/users/hxie1/data/IVUS/Test_Set/Data_set_B/LABELS_obs2_v1.
>> >> >> >> >> Jacc		     Dice		   HD		  PAD
>> Lumen:	>> 0.83±0.09	0.91±0.07	0.45±0.30	0.11±0.10	>>
   Media:	>> 0.83±0.10	0.90±0.06	0.74±0.39	0.11±0.09	>>

Rethink LearningRate and SGD:
1  OneCycleLR + SGD is beter than Adam.
2  critizon for save network pararmeter.
3  Why Adam is not match ReduceLrOnPlateau
4  IVUS use about 6.5K iteration.
5  Lr_finder()











# May 14th, Friday, 2021
Prepare IVUS data for sufraceSubnet_Q experiment:
This IVUS (Intravascular Ultrasound) data set is a public dataset B from IVUS challenge 2011 \cite{IVUSChallenge2011}.
Its goal is to segment the inner wall(lumen) and outer wall(media) of vessels in intra-vascular ultrasound images obtained by 20 MHz IVUS scanner from 10 patients.
Training set includes 109 images, in which we randomly choose 9 images for validation in training process;
and test data includes 326 images. The raw IVUS image has pixel size of 384*384 with in-frame resolution of 0.026*0.026mm.
We convert them into polar coordinate images of size 192*360 pixels, around the center point of the raw image, where 192 is maximum radial coordinate,
and 360 is the maximum angular coordinate in degree.
We feed these polar images into our deep learning network, and directly evaluate our prediction result using a Matlab script published in IVUS Chanellenge \cite{IVUSChallenge2011}.
The Matlab scrip evaluates the average Jaccard similarity measurement(Jacc), Dice, Hausdorff Distance(HD), and Percentage of Area Difference (PAD) referred from \cite{IVUSChallenge2011}.
In our experiment, we used dynamic $\vec{\sigma}$ from $\vec{\mu}/\vec{\sigma}$ computation module to generate Gaussian ground truth,
and used gaussian noise, pepper\&salt noise, and arbitrary degree rotation on raw image for data augmentation.
Test used TTA(Test-Time Augmentation) in \SI{20}{\degree} step rotation, and then average 18 rotated back result as our final result.
FBBR-2 and our method use same data augmentationa and TTA.

IVUS data set(100%):
training: 100 images.
validaiton: 9 images.
test:     326 images.

IVUS data set(10%):
training: 10 images.
validaiton: 9 images.
test:     326 images.

image size: 192x360 in HxW in polar coordination.
numSurface: 2

Experiment design:
1  100% training set.
2  10%  training set.
3  Methods: our method, YufanHe's method.  total 4 experiments.

Tasks:
1  prepare 10% data in training set. validation and test set keep same with 100% data.  --done.
2  copy data to skm2, and iibi007, and modify path name.
   src: /home/hxie1/data/IVUS/polarNumpy
        /home/hxie1/data/IVUS/polarNumpy_10percent
        /home/hxie1/data/IVUS/Training_Set
   dst: skm2, c-iibi007   --done.
   modify path name: -- done.

3  config yaml:  --done.

4  IVUS dataset class:
   data augmentation.(shift/rotation first + flip+ noise+ saltPepper)   --done.

5  IVUS training script:
   A  output format, and save  __same with OCT, --done.
   C  data augmentation in training and validation.  --done

6  a new IVUS test script:
   refer previous: /home/sheen/projects/DeepLearningSeg/OCTMultiSurfaces/network/CVTestSurfaces_PolarImage.py
   A  output format, path name, and save file name.   --done
   B  measurement.
   C  no data augmentation.   --done
   D  output lumen and media txt files.  --done
   F  output restore into tube shape back.  --done







