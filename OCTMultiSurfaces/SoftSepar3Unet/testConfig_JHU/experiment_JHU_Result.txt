# May 06th, Thursday, 2021:
1  When model size doubles, test error decreases.  But there is double descent phenomenon.
2  When prunning network, as features are correlated, retraining or finetune is very important.

Current the best networks:
SurfaceSubnet: expJHU_20210505_SurfaceSubnetP_fullData_A_skm2
ThicknessSubnet: expJHU_20210501_ThicknessM5_fullData_A_skm2




# May 05th, Wednesday, 2021:
Best Surface Subnet design:
1  use MultiSurfaceCrossEntropyLoss on surface locations probability.
2  use SmoothL1Loss on surface locations.
3  After all losses, use ReLU to correct surface order.

Best Thickness Subnet design:
1  From surface locaiton to refer the thickness.
2  use MultiSurfaceCrossEntropyLoss on surface locations probability.
3  use SmoothL1Loss on thickness.
4  do not use ReLU, as a negative thickness does not hurt some thing.





# May 04th, Tuesday, 2021
Compare with diffferent data sets:
============================================
1 Duke AMD data statistics:  51 Bscan / volume.
  training set: 266 volumes x 51 slices per volume, where 187 AMD + 79 control = 266 volumes;
  validation set: 59 volumes x 51 slice per volume, where 41 AMD + 18 control  =  59 volumes;
  test set:  59 volumes x 51 slice per volume, where 41 AMD + 18 control  =  59 volumes;

  For training set:  10% of total data is 27 volume x 51 Bscan/volume, total 27x51 = 1377 Bscans.

2 OCT_Tongren Control data:   31 Bscan /volume
  test: 5 patients;  validation: 5 patients;  training: 36 patients,
  total Bscan in training: 36x31 = 1116 Bscans.

3 OCT_JHU data: 49 Bcans / volume.
    training set: 6 health control patients(HC), 9 multiple sclerosis patients(MS).
    test     set: 8 health control patients(HC), 12 mulitple sclerosis patients(MS)



# May 3rd, Monday, 2021:
JHU test data on surface prediction
==============================================================================================================================================================================================================================================================================
ExperimentName                                              muError stdError    muSurfaceError(um, 0-8)                                                     stdSurfaceError(um, 0-8)                                                HausdorffDistance(pixel)             Notes
expJHU_20210429_SurfaceSubnet_fullData_A_iibi007            2.8055  1.0587      2.3776, 2.9819, 2.8236, 3.1029, 2.7316, 2.6560, 2.0537, 3.4722, 3.0501      0.3840, 0.6973, 0.4049, 0.4542, 0.6341, 0.6381, 0.9800, 0.8224, 2.3743  54  44  35  32  28  17  12  11  12
expJHU_20210501_SurfaceSubnetM5_fullData_A_skm2             2.8060  1.0321      2.4373, 2.8499, 2.8418, 3.0725, 2.7413, 2.7378, 2.0850, 3.4285, 3.0601      0.4652, 0.6999, 0.5031, 0.4133, 0.6269, 0.6466, 1.0564, 0.9334, 2.2034  47  24  18  26  15  23  18  10  11
expJHU_20210501_YufanHe_fullData_A_skm2                     2.8000  1.0309      2.3583, 3.0140, 2.8638, 3.1508, 2.7788, 2.5730, 1.9977, 3.3685, 3.0955      0.3946, 0.7455, 0.4256, 0.3867, 0.6285, 0.7639, 0.7363, 0.7816, 2.2997  47  20  22  21  27  11  10   9  11
expJHU_20210505_SurfaceSubnetP_fullData_A_skm2              2.8018  1.0068      2.3971, 2.9492, 3.0071, 3.1272, 2.8634, 2.5642, 1.9938, 3.3066, 3.0084      0.3207, 0.6366, 0.4318, 0.5891, 0.6192, 0.7821, 0.8439, 0.7679, 2.1902  44. 23. 16. 16. 16.  8.  9. 11. 13.
expJHU_20210506_SurfaceSubnetQ_fullData_A_skm2
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
expJHU_20210501_SurfaceSubnetM5_1HC2MS_A_skm2               3.5110  1.5345      2.4986, 3.8312, 4.3174, 4.3484, 4.7453, 2.8084, 2.1339, 3.8604, 3.0554      0.3617, 2.0810, 1.3966, 1.0812, 1.4231, 0.7962, 0.5029, 0.8691, 1.9647  34. 25. 16. 15. 19. 22. 28. 32. 28.
expJHU_20210501_YufanHe_1HC2MS_A_skm2                       2.9799  1.0511      2.5425, 3.3542, 3.1691, 3.5274, 3.0380, 2.6217, 1.9596, 3.7046, 2.9026      0.4849, 1.0842, 0.5572, 0.6394, 0.8340, 0.6438, 0.7338, 0.9278, 1.8095  38. 34. 23. 23. 30. 37. 10. 16. 27.
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
expJHU_20210501_SurfaceSubnetM5_1HC1MS_A_skm2               3.7516  1.5135      2.7964, 4.0756, 4.5106, 4.6866, 4.9495, 3.2597, 2.4081, 3.9146, 3.1633      0.6203, 1.6643, 1.2542, 1.2290, 1.6233, 1.0777, 0.5303, 0.8100, 1.9889  28. 35. 17. 18. 14. 11. 10.  13. 12.
expJHU_20210501_YufanHe_1HC1MS_A_skm2                       3.3019  1.4292      2.6041, 4.1426, 3.8114, 3.8467, 3.9660, 2.7825, 2.0247, 3.4871, 3.0522      0.5363, 2.4971, 1.1810, 0.7289, 1.2160, 0.9540, 0.6498, 0.6001, 1.7934  38. 41. 25. 15. 17. 10.  9.  11. 22.
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
expJHU_20210430_SoftSeparation_D_fullData_A_iibi007         2.8025  1.0590      2.3736, 2.9787, 2.8208, 3.1000, 2.7249, 2.6556, 2.0523, 3.4682, 3.0486      0.3840, 0.6980, 0.4051, 0.4547, 0.6342, 0.6382, 0.9809, 0.8235, 2.3750  54  44  35  32  28  17  12  11  12
expJHU_20210503_SoftSeparation_M5_fullData_A_skm2           2.8053  1.0323      2.4371, 2.8480, 2.8399, 3.0728, 2.7412, 2.7376, 2.0836, 3.4279, 3.0600      0.4652, 0.7000, 0.5032, 0.4131, 0.6269, 0.6466, 1.0571, 0.9338, 2.2035  47. 24. 18. 26. 15. 23. 18. 10. 11.
expJHU_20210503_SoftSeparation_YufanHeM5_fullData_B_skm2    2.7998  1.0310      2.3583, 3.0135, 2.8629, 3.1510, 2.7786, 2.5730, 1.9971, 3.3685, 3.0955      0.3946, 0.7454, 0.4257, 0.3863, 0.6282, 0.7640, 0.7370, 0.7816, 2.2996  47. 20. 22. 21. 27. 11. 10.  9. 11.
=============================================================================================================================================================================================================================================================================

Summary:
1  YufanHe's paper report result on above JHU data: muError=2.83 um.
2  OCT_JHU data: 49 Bcans / volume, 9 surfaces.
    training set: 6 health control patients(HC), 9 multiple sclerosis patients(MS).
    test     set: 8 health control patients(HC), 12 mulitple sclerosis patients(MS)
3  expJHU_20210503_SoftSeparation_M5_fullData_A_skm2: use surfaceSubnet expJHU_20210501_SurfaceSubnetM5_fullData_A_skm2, and thicknessSubnet expJHU_20210501_ThicknessM5_fullData_A_skm2;
   expJHU_20210503_SoftSeparation_YufanHeM5_fullData_B_skm2:  use surfaeSubnet  expJHU_20210501_YufanHe_fullData_A_skm2, and thicknessSubnet expJHU_20210501_ThicknessM5_fullData_A_skm2.
   Both softSeparation networks improved a little over its corresponding surface subnet.
4  The accuracy of surfaceSubnet majorly decides the final accuracy of softSeparation.
   Here surfaceError=2.8 um, and thicknessError 3.72 um (=1.33  x surfaceError), in the context of pixel size = 3.87um, softSeparation improvement is not significant.
5  In reduced data design of JHU data, (maybe 1 HC and 1 MS patient is too extreme), reduced data does not keep same accuracy.
   As Duke_AMD data is big (266 patient for training), reducing data to 10% is still bigger than the JHU full data. It may will be ok.
6  This result is similar with Duke_AMD result: softSeparation improves surface error a little.
   In this JHU data, soft Separation method does not explicitly improve the Hausdorff distance.
   While in Duke_AMD data, our surfaceNet, instead of softSeparation, improves Hausdorff distance.


JHU test data on Thickness
=============================================================================================================================================================================================================================================================================
ExperimentName                                          muError stdError  muThickError(um, 0-7)                                                   stdThicknessError(um, 0-7)                                              HausdorffDistance(pixel)            Notes
expJHU_20210429_Thickness_M2_fullData_A_iibi007         8.1345  11.9278   3.5436, 3.7382, 3.8983, 3.9912, 3.8208, 3.0979, 3.5816, 39.4047         0.5503, 0.6099, 0.5523, 0.6475, 0.5461, 0.8327, 0.5747, 3.3164          36  30   11  17  16   5    6  20
expJHU_20210501_ThicknessM5_fullData_A_skm2             3.7227  0.7049    3.5378, 3.8383, 3.8479, 3.9793, 3.9245, 3.0874, 3.6882, 3.8783          0.5128, 0.5963, 0.5169, 0.5983, 0.5914, 0.8595, 0.5215, 0.9613          38. 19.  13. 19. 13.  14. 10. 11.
expJHU_20210503_ThicknessN_fullData_A_skm2              6.1573  4.0857    9.2878, 13.6853,3.9390, 4.3544, 6.9553, 3.1241, 3.7491, 4.1640          3.5789, 4.2638, 0.4606, 0.9948, 2.2896, 0.8183, 0.6629, 1.3933          44. 18.   9. 15. 17.   5.  7. 10.
expJHU_20210505_ThicknessP_fullData_A_skm2              3.8172  0.8772    4.0796, 3.8575, 3.8985, 3.9836, 3.9025, 3.1328, 3.5589, 4.1248          0.8890, 0.7505, 0.5130, 0.6511, 0.6438, 0.8883, 0.6908, 1.3923          47. 22.  11. 16. 14.   8.  7.  7.
expJHU_20210506_ThicknessQ_fullData_A_skm2
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
expJHU_20210501_ThicknessM5_1HC2MS_A_skm2               4.1465  1.1646    4.3207, 4.4489, 4.0856, 4.4465, 4.3579, 3.1829, 3.6589, 4.6712          1.5841, 0.9895, 0.5364, 1.0699, 0.8844, 0.8149, 0.7838, 1.6059          48. 38.  11. 20. 25.  12. 10. 11.
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
expJHU_20210501_ThicknessM5_1HC1MS_A_skm                4.6934  1.5432    4.8866, 5.6501, 4.4439, 5.3218, 5.4742, 3.1937, 3.9382, 4.6392          2.1923, 1.4844, 0.5876, 1.5279, 1.3235, 0.7733, 0.7725, 1.4830          31. 20.  11. 16. 20.   5. 10. 11.
=============================================================================================================================================================================================================================================================================





Analysis:
1  For thickness subnet: M5 improves a lot over M2.
   M5 introduces cross entropy on the surface probability.
2  Bigger dataset will bring more outliers, which add Hausdorff distance.
3  Combine surfaceSubnet_M5 and ThicknessM5 together to do softSepearation.
    A.  Combine surfaceSubnet_M5 and ThicknessM5
    B.  combine YufanHe  and ThicknessM5.
4  In fullData, the HD distance in thickness network is less than surfaceSubnet, it predict that softSeparation will improves the result.






# May 1st, Saturday, 2021
Test error(meean patient absolute error) on reduced training data on JHU data:
===========================================================================================================================
DataContent    TrainingRate     YufanHe_2Network(um)    SurfaceSubnet_M5(um)      Thickness_M5(um)     SoftSeparation_D(um)
6HC_9MS        100%             2.805                   2.822                     3.757
1HC_2MS        20%              3.002                   3.548                     4.181
1HC_1MS        13%              3.367                   3.769                     4.333
===========================================================================================================================

Test error standand deviation (meean patient absolute error) on reduced training data on JHU data:
===========================================================================================================================
DataContent    TrainingRate     YufanHe_2Network(um)    SurfaceSubnet_M5(um)      Thickness_M5(um)     SoftSeparation_D(um)
6HC_9MS        100%             1.037                   1.033                     0.7127
1HC_2MS        20%              1.054                   1.52                      1.174
1HC_1MS        13%              1.456                   1.501                     1.262
===========================================================================================================================

Notes:
1  JHU OCT data set:
    training set: 6 health control patients(HC), 9 multiple sclerosis patients(MS).
    test     set: 8 health control patients(HC), 12 mulitple sclerosis patients(MS)
2  JHU OCT data set: 9 surfaces, H=128, W = 1024, 49 Bscan/volume, 3.86725 um/pixel in A scan direction.
3  Soft Separation involves matrix inverse operation of size of 9216x9216, very slow.
4  YufanHe's paper reported the 100% training got muError 2.83 um, higher than my implementation.




JHU experiment on validation data:
======================================================================================================================
expName                                         validationError(um)     std     epoch    Notes
expUnetJHU_20200310_sigma8_grad4_WeighedDiv10   2.792                   0.856   82       IPM surface
expJHU_20210429_SurfaceSubnet_fullData_A        2.815                   1.1043  87       ReLu surface
expJHU_20210429_Thickness_M2_fullData_A         8.141                   11.93   27       thickness
======================================================================================================================


In training data:
total 735 images = 49 Bscans/patient x 15 patients.
in 15 patients in training data:
   A first 6 patients are HC;
   B the second 9 patients are MS.
if we consider to get 1 HC patient, 2 MS patient, total 3/15 = 20% of original training data.
if we consider to get 1 HC paitent, 1 MS patient, total 2/15 = 13.3% of original training data.

Now numpy_1HC_1MS and numpy_1HC_1MS data are ready.

compare with YufanHe network: SurfacesUnet_YufanHe_2

In skm2 GPU Server:
========================================================================================
          SurfaceUnet_YufanHe_2    SufaceSubnet_M5   Thickness_M5   SoftSeparation_D
6HC_9MS:    GPU2                   GPU1               GPU4
1HC_1MS:    GPU2                   GPU1               GPU4
1HC-2MS:    GPU3                   GPU1               GPU5
=========================================================================================




# JHU data introduction on April 29th, 2021
This public JHU retinal OCT data includes 35 human retina scans acquired
on a Heidelberg Spectralis OCT system, 14 of which are healthy controls (HC)
and 21 have a diagnosis of multiple sclerosis (MS). Each patient has 49 B-scans
with pixel size 496*1024, and 9 ground truth surfaces each
B-Scan. The axial resolution in each A-scan is 3.9 micrometer. Raw image were
manually delineated with 21 control points on each surface, and then were cubic
interpolated into 1024 points crossing all A-scan to form ground truth by a
Matlab script. Raw images then crop center 128 rows into 128*1024 feeding
into network. We use same data config and input with of training on the last 6
HC and last 9 MS subjects, and test on the other 20 subjects. In our experiment,
we used a fixed Ïƒ = 8 to generate Gaussian ground truth, and used gaussian
noise and pepper&salt noise on raw image for data augmentation. Visual result of
this experiment are in appendix C.