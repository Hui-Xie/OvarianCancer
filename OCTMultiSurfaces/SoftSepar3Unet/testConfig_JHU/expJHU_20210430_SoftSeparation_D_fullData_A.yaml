# surfaceUnet + thicknessUnet+ learning Lamba
# For SoftSeparationNet D: no NxW learning lambda, directly learn alpha.

debug: False # debug mark
dataIn1Parcel: True
# Duke data is not in one parcel, while Tongren, JHU are in one parcel.
# dataIn1Parcel means each patient has a volume file.
dataInSlice: False

status: "trainLambda" # only 3 status: # "trainLambda" #"test"  "fineTune"
# test: pure test, no any backward propagation
# fineTune: all networks support backward propagation
# trainLambda: only lambda module uses backward propagation.


dataDir: "/home/hxie1/data/OCT_JHU/numpy"
existGTLabel: True
# log will save at: dataDir + "/log/" + network + "/" + experimentName
K: 0  # Kfold cross validation
k: -1   # the fold k test
batchSize: 4
groundTruthInteger: False

network: "SoftSeparationNet_D"
device: torch.device('cuda:3')   # same with lambda device
sigma: 8.0  # For gaussian  ground truth, in float, 0 means use dynamic Sigma

# some physical parameter of images
inputHeight: 128   # original height
inputWidth: 1024   # rawImageWidth
slicesPerPatient: 49  # for test and validation set
hPixelSize: 3.86725  # unit: micrometer, in y/height direction
numSurfaces: 9  # num of surfaces in an image
gradChannels: 7   # the added gradient channels beside raw image channel
bothSideGrad: True # False use singleSideGrad
addCoordinatesXYChannels: True
useRift: True
smoothRift: False  # smooth Rift in ground truth
scaleNumerator: 1
scaleDenominator: 1
useLayerDice: True

careLambdaLossOnly: True  #  True: only backward lambdaLoss; False: backward 3 losses.

# data augmentation
augmentProb: 0.4  #  data augmentation rate
gaussianNoiseStd: 0.1 # gausssian nosie std with mean =0
# for salt pepper noise
saltPepperRate: 0.05  # rate = (salt+pepper)/allPixels
saltRate: 0.5  # saltRate = salt/(salt+pepper)
rotation: False
TTA: False       #TestTime Augmentation
TTA_StepDegree: 0 # roration step degree of TTA, in integer degree
lacingWidth: 0  # Lace the both end of 0 or 360 degree to offset inaccurate segementation at boundary of input image


# for 2 Unets + learning Lambda
surfaceSubnet: "SurfaceSubnet"
surfaceSubnetYaml: "/home/hxie1/projects/DeepLearningSeg/OCTMultiSurfaces/SoftSepar3Unet/testConfig_JHU/expJHU_20210429_SurfaceSubnet_fullData_A.yaml"
surfaceSubnetDevice: torch.device('cuda:1')   #GPU ID
surfaceSubnetLr: 0.005  # pretain at epoch 81  # in test status, it does not care

thicknessSubnet: "ThicknessSubnet_M2"
# for a new trained network.
thicknessSubnetYaml: "/home/hxie1/projects/DeepLearningSeg/OCTMultiSurfaces/SoftSepar3Unet/testConfig_JHU/expJHU_20210429_Thickness_M2_fullData_A.yaml"
thicknessSubnetDevice: torch.device('cuda:2')   #GPU ID
thicknessSubnetLr: 0.05  # pretrain at epoch 60   # in test status, it does not care

lambdaModule: "LambdaModule_E"
lambdaModuleYaml: ""
lambdaModuleDevice: torch.device('cuda:3')   #GPU ID
lambdaModuleLr: 0.1
# alpha: 0.001  # use learning alpha deduced from lambda
maxAlpha: 0.1
lambdaOutputC: 8  # output Channel = numSurface -1

netPath: "/home/hxie1/data/OCT_JHU/numpy/netParameters"  # net is saved at netpath / network / self_filename
loadNetPath: ""
outputDir: ""
logDir: "/home/hxie1/data/OCT_JHU/numpy/log"
refXMLFile: "/home/hxie1/data/OCT_Tongren/refXML/1062_OD_9512_Volume_Sequence_Surfaces_Iowa.xml"
