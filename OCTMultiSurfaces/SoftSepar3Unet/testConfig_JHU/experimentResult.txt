# April 30th, Friday, 2021
JHU experiment on validation data:
======================================================================================================================
expName                                         validationError(um)     std     epoch    Notes
expUnetJHU_20200310_sigma8_grad4_WeighedDiv10   2.792                   0.856   82       IPM surface
expJHU_20210429_SurfaceSubnet_fullData_A        2.815                   1.1043  87       ReLu surface
expJHU_20210429_Thickness_M2_fullData_A         8.141                   11.93   27       thickness
======================================================================================================================


In training data:
total 735 images = 49 Bscans/patient x 15 patients.
in 15 patients in training data:
   A first 6 patients are HC;
   B the second 9 patients are MS.
if we consider to get 1 HC patient, 2 MS patient, total 3/15 = 20% of original training data.
if we consider to get 1 HC paitent, 1 MS patient, total 2/15 = 13.3% of original training data.

Now numpy_1HC_1MS and numpy_1HC_1MS data are ready.

compare with YufanHe network: SurfacesUnet_YufanHe_2

          SurfaceUnet_YufanHe_2    SufaceSubnet   Thickness_M2   SoftSeparation_D
6HC_9MS:
1HC_1MS:
1HC-2MS:





# JHU data introduction on April 29th, 2021
This public JHU retinal OCT data includes 35 human retina scans acquired
on a Heidelberg Spectralis OCT system, 14 of which are healthy controls (HC)
and 21 have a diagnosis of multiple sclerosis (MS). Each patient has 49 B-scans
with pixel size 496*1024, and 9 ground truth surfaces each
B-Scan. The axial resolution in each A-scan is 3.9 micrometer. Raw image were
manually delineated with 21 control points on each surface, and then were cubic
interpolated into 1024 points crossing all A-scan to form ground truth by a
Matlab script. Raw images then crop center 128 rows into 128*1024 feeding
into network. We use same data config and input with of training on the last 6
HC and last 9 MS subjects, and test on the other 20 subjects. In our experiment,
we used a fixed Ïƒ = 8 to generate Gaussian ground truth, and used gaussian
noise and pepper&salt noise on raw image for data augmentation. Visual result of
this experiment are in appendix C.