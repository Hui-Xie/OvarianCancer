# surfaceUnet + thicknessUnet+ learning Lamba
# For SoftSeparationNet D: no NxW learning lambda, directly learn alpha.

debug: False # debug mark
dataIn1Parcel: True
# Duke data is not in one parcel, while Tongren, JHU are in one parcel.
# dataIn1Parcel means each patient has a volume file.
dataInSlice: False

status: "trainLambda" # only 3 status: # "trainLambda" #"test"  "fineTune"
# test: pure test, no any backward propagation
# fineTune: all networks support backward propagation
# trainLambda: only lambda module uses backward propagation.


dataDir: "/raid001/users/hxie1/data/OCT_JHU/numpy"
existGTLabel: True
# log will save at: dataDir + "/log/" + network + "/" + experimentName
K: 0  # Kfold cross validation
k: -1   # the fold k test
batchSize: 4
groundTruthInteger: False

network: "MergeNet_Q"
device: torch.device('cuda:3')   # same with lambda device
sigma: 0  # For gaussian  ground truth, in float, 0 means use dynamic Sigma or do not use sigma.

# some physical parameter of images
inputHeight: 128   # original height
inputWidth: 1024   # rawImageWidth
slicesPerPatient: 49  # for test and validation set
hPixelSize: 3.86725  # unit: micrometer, in y/height direction
numSurfaces: 9  # num of surfaces in an image
gradChannels: 7   # the added gradient channels beside raw image channel
bothSideGrad: True # False use singleSideGrad
addCoordinatesXYChannels: True
useRift: True
smoothRift: False  # smooth Rift in ground truth
scaleNumerator: 1
scaleDenominator: 1
useLayerDice: True

careLambdaLossOnly: True  #  True: only backward lambdaLoss; False: backward 3 losses.

# data augmentation
augmentProb: 0.4  #  data augmentation rate
gaussianNoiseStd: 0.1 # gausssian nosie std with mean =0
# for salt pepper noise
saltPepperRate: 0.05  # rate = (salt+pepper)/allPixels
saltRate: 0.5  # saltRate = salt/(salt+pepper)
rotation: False
flippingProb: 0.3
TTA: False       #TestTime Augmentation
TTA_StepDegree: 0 # roration step degree of TTA, in integer degree
lacingWidth: 0  # Lace the both end of 0 or 360 degree to offset inaccurate segementation at boundary of input image


# for 2 Unets + learning Lambda
surfaceSubnet: "SurfaceSubnet_Q"
surfaceSubnetYaml: "/raid001/users/hxie1/projects/DeepLearningSeg/OCTMultiSurfaces/SoftSepar3Unet/testConfig_JHU/expJHU_20210507_SurfaceSubnetQ64_fullData_A_skm2.yaml"
surfaceSubnetDevice: torch.device('cuda:3')   #GPU ID
surfaceSubnetLr: 0.1  # pretain at epoch 26  # in test status, it does not care
surfaceSubnetLrReset: False

thicknessSubnet: "ThicknessSubnet_Q"
# for a new trained network.
thicknessSubnetYaml: "/raid001/users/hxie1/projects/DeepLearningSeg/OCTMultiSurfaces/SoftSepar3Unet/testConfig_JHU/expJHU_20210507_ThicknessQ64_fullData_A_skm2.yaml"
thicknessSubnetDevice: torch.device('cuda:3')   #GPU ID
thicknessSubnetLr: 0.1  # pretrain at epoch 37   # in test status, it does not care
thicknessSubnetLrReset: False

lambdaModule: "SegmentModule_Q"
lambdaModuleYaml: ""
lambdaModuleDevice: torch.device('cuda:3')   #GPU ID
lambdaModuleLr: 0.1
lambdaModuleLrReset: True
copyWeightFromSubnets: True  # copy weights from the pretrain surface and thickness subnets.

netPath: "/raid001/users/hxie1/data/OCT_JHU/numpy/netParameters"  # net is saved at netpath / network / self_filename
loadNetPath: ""
outputDir: ""
logDir: "/raid001/users/hxie1/data/OCT_JHU/numpy/log"
refXMLFile: "/raid001/users/hxie1/data/OCT_Tongren/refXML/1062_OD_9512_Volume_Sequence_Surfaces_Iowa.xml"


# constrained model, both False meaning RelU
# ReLU to guarantee layer order not to cross each other
# 0: NoReLU; 1: ReLU;  2: IPM;
hardSeparation: 1
softSeparation: False
useReLUInPretrain: True
