# train and test JHU OCT data
# Use basic Unet + KLDLoss for OCT multisurface
# Unet with a residual link inside each block + Gaussian Ground truth for multi-surface + KLDivLoss + Soft argMax + SmoothL1Loss
# Feb 28th, 2020, User SurfacesNet, sigma= 8
# March 02th, 2020, use dynamic Sigma
# Mar 06th, 2020, use dynamic sigma, and suport back propagating sigma;
#                 use layer2SurfaceMu.
#                 Expriment shows: After about 200 epochs, surface 8 error reduce down form 20 to 3.
#                 without guarantee layer order modification.
#Mar 7th, 2020. Add LayerConf and guarantee layer order.
#Mar 9th, 2020, Layerconf and Sigma=8
#                and add 3 gradient channels in input.
#Mar 10th, 2020,  add update GaussianDitr with image grdient magnitude
#                  and add 4 gradient channels in input.
#                   use fixed sigma =8
#                  imagegradient weight =10, weighted DivLoss

#April 29th, 2021:
# this config file inherits from:
#  /home/sheen/projects/DeepLearningSeg/OCTMultiSurfaces/testConfig/expUnetJHU_Surface_Layer_20200206/expUnetJHU_20200310_sigma8_grad4_WeighedDiv10.yaml

debug: False # debug mark
dataIn1Parcel: True
useIndependentValidation: False
# Duke data is not in one parcel, while Tongren and JHU are in one parcel.
# Not dataIn1Parcel means each patient has a volume file.
dataInSlice: False
existGTLabel: True

dataDir: "/raid001/users/hxie1/data/OCT_JHU/numpy"
# log will save at: dataDir + "/log/" + network + "/" + experimentName
K: 0
k: -1   # -1 means do not use cross validation
# when use cross validation:
# training data:  dataDir + training + images_CV{k}.npy
#         label: dataDir + training + surfaces_CV{k}.npy
#         IDs  : dataDir + training + patientID_CV{k}.json

# validation data:  dataDir + validation + images_CV{k}.npy
#           label: dataDir + validation + surfaces_CV{k}.npy
#           IDs  : dataDir + validation + patientID_CV{k}.json

# test data:  dataDir + test + images_CV{k}.npy
#     label: dataDir + test + surfaces_CV{k}.npy
#     IDs  : dataDir + test + patientID_CV{k}.json

# when do not use cross validation:
# training data:  dataDir + training + images.npy
#         label: dataDir + training + surfaces.npy
#         IDs  : dataDir + training + patientID.json

# validation data:  dataDir + validation + images.npy
#           label: dataDir + validation + surfaces.npy
#           IDs  : dataDir + validation + patientID.json

# test data:  dataDir + test + images.npy
#     label: dataDir + test + surfaces.npy
#     IDs  : dataDir + test + patientID.json

groundTruthInteger: False
sigma: 0  # For gaussian  ground truth, in float; 0 means use dynamic Sigma or not use Gaussian.
device: torch.device('cuda:3')   #GPU ID
#device: torch.device('cpu')
batchSize: 4
learningRate: 0.1
epochs: 800

optim: "AdamPlateau" # "AdamPlateau", "SGDOneCycle"
network: "SurfaceSubnet_Q"
inputHeight: 128   # original height
inputWidth: 1024   # rawImageWidth
scaleNumerator: 1
scaleDenominator: 1
inputChannels: 8 # rawImage + gradChannels
nLayers: 7
numSurfaces: 9  # num of surfaces in an image
startFilters: 24  # the num of filters in first layer of Unet
gradChannels: 7   # the added gradient channels beside raw image channel
bothSideGrad: True # False use singleSideGrad
gradWeight: 10   # image grade weight to adjust WeightedDivLoss.
addCoordinatesXYChannels: False
segChannels: 64  # number of channel in the segmentation part.

# some physical parameter of images
slicesPerPatient: 49
hPixelSize: 3.86725  # unit: micrometer, in y/height direction

# data augmentation
augmentProb: 0.4  #  data augmentation rate
gaussianNoiseStd: 0.1 # gausssian nosie std with mean =0
# for salt-pepper noise
saltPepperRate: 0.05  # rate = (salt+pepper)/allPixels
saltRate: 0.5  # saltRate = salt/(salt+pepper)
rotation: False
flippingProb: 0.3
lacingWidth: 0  # Lace the both end of 0 or 360 degree to offset inaccurate segementation at boundary of input image
TTA: False       #Test-Time Augmentation
TTA_StepDegree: 0 # roration step degree of TTA, in integer degree
# data augmentation

netPath: "/raid001/users/hxie1/data/OCT_JHU/numpy/netParameters"  # net is saved at netpath / network / self_filename
# if loadNetPath !="", netPath will be replaced by loadNetPath
# below loadNetPath is copied from "/raid001/users/hxie1/data/OCT_JHU/numpy/netParameters/OCTUnetJHU/expUnetJHU_20200130" on 20200201 17:33
loadNetPath:  ""  # this is pretrained network
outputDir:  ""
logDir: "/raid001/users/hxie1/data/OCT_JHU/numpy/log"
refXMLFile: "/raid001/users/hxie1/data/OCT_Tongren/refXML/1062_OD_9512_Volume_Sequence_Surfaces_Iowa.xml"

# Proximal IPM Optimization
useProxialIPM: False
learningStepIPM: 0.1
maxIterationIPM: 100
criterionIPM: 0.1 # the criterion of average difference of 2 adjacent iterations in IPM: less than this value, IPM exits.

useDynamicProgramming: False
usePrimalDualIPM: False
useLayerDice: False
useReferSurfaceFromLayer: False
useLayerCE: False
useCEReplaceKLDiv: False
useSmoothSurfaceLoss: False
useWeightedDivLoss: False
useRift: False
smoothRift: False  # smooth Rift in ground truth
smoothHalfWidth: 15  # 5% of image width
smoothPadddingMode: "reflect" # paddingMode: 'constant', 'reflect', 'replicate' or 'circular'.
smoothRbeforeLoss: False  # use smooth predicted R to compare loss with smooth ground truth R
useMultiSurfaceCEWeight:  False

gradientRiftConvGoBack: False



# constrained model, both False meaning RelU
# ReLU to guarantee layer order not to cross each other
# 0: NoReLU; 1: ReLU;  2: IPM;
hardSeparation: 1
softSeparation: False
useReLUInPretrain: True

goodBscans: []