# 2 Unets train Surface, Rift
# search one lambda for all surfaces.
# use predicted R to grid search lambda
# search range: 1.0e-5 downward with step 1.0e-8


debug: False # debug mark
dataIn1Parcel: False
useIndependentValidation: True
# Duke data is not in one parcel, while Tongren, JHU are in one parcel.
# dataIn1Parcel False means each patient has a volume file.
dataInSlice: True

status: "test" #"fineTuneSurfaceRift" # "trainLambda" #"test"

# grid search lambda
lambdaInitialValue: 1.0e-5
lambdaSearchStep: 1.0e-8

# for 3 Unets
surfaceSubnet: "SurfaceSubnet"
surfaceSubnetYaml: "/home/hxie1/Projects/DeepLearningSeg/OCTMultiSurfaces/SoftSepar3Unet/testConfig_Duke/expDuke_20200902A_SurfaceSubnet.yaml"
surfaceSubnetDevice: torch.device('cuda:1')   #GPU ID
surfaceSubnetLr: 5.0e-3  # pretain at epoch 74

riftSubnet: "RiftSubnet"
riftSubnetYaml: "/home/hxie1/Projects/DeepLearningSeg/OCTMultiSurfaces/SoftSepar3Unet/testConfig_Duke/expDuke_20200902A_RiftSubnet.yaml"
riftSubnetDevice: torch.device('cuda:2')   #GPU ID
riftSubnetLr: 1.25e-3  # pretrain at epoch 101


lambdaSubnetDevice: torch.device('cuda:0')   #GPU ID
oneLambdaForAllSurfaces: True # False: each surface has a lambda


trainLambdaUsingValidation: False

replaceRwithGT: 0 # 0: use predicted R; 1: use riftGT without smoothness; 2: use smoothed riftGT;

dataDir: "/home/hxie1/data/OCT_Duke/numpy_slices"
existGTLabel: True
# log will save at: dataDir + "/log/" + network + "/" + experimentName
K: 0  # Kfold cross validation
k: -1   # the fold k test
# training data:  dataDir + training + images_CV{k}.npy
#         label: dataDir + training + surfaces_CV{k}.npy
#         IDs  : dataDir + training + patientID_CV{k}.json

# validation data:  dataDir + validation + images_CV{k}.npy
#           label: dataDir + validation + surfaces_CV{k}.npy
#           IDs  : dataDir + validation + patientID_CV{k}.json

# test data:  dataDir + test + images_CV{k}.npy
#     label: dataDir + test + surfaces_CV{k}.npy
#     IDs  : dataDir + test + patientID_CV{k}.json

# when do not use cross validation:
# training data:  dataDir + training + images.npy
#         label: dataDir + training + surfaces.npy
#         IDs  : dataDir + training + patientID.json

# validation data:  dataDir + validation + images.npy
#           label: dataDir + validation + surfaces.npy
#           IDs  : dataDir + validation + patientID.json

# test data:  dataDir + test + images.npy
#     label: dataDir + test + surfaces.npy
#     IDs  : dataDir + test + patientID.json

groundTruthInteger: True
sigma: 20.0  # For gaussian  ground truth, in float, 0 means use dynamic Sigma
device: torch.device('cuda:0')   #GPU ID
batchSize: 8


network: "SearchLambda2Unet"
inputHeight: 512   # original height
inputWidth: 361   # rawImageWidth
scaleNumerator: 1
scaleDenominator: 1
inputChannels: 8 # rawImage + gradChannels
nLayers: 7
numSurfaces: 3  # num of surfaces in an image
startFilters: 24  # the num of filters in first layer of Unet
gradChannels: 7   # the added gradient channels beside raw image channel
bothSideGrad: True # False use singleSideGrad
gradWeight: 10   # image grade weight to adjust WeightedDivLoss.

# some physical parameter of images
slicesPerPatient: 51  # for test and validation set
hPixelSize: 3.24  # unit: micrometer, in y/height direction

# data augmentation
augmentProb: 0.4  #  data augmentation rate
gaussianNoiseStd: 0.1 # gausssian nosie std with mean =0
# for salt pepper noise
saltPepperRate: 0.05  # rate = (salt+pepper)/allPixels
saltRate: 0.5  # saltRate = salt/(salt+pepper)
rotation: False
flippingProb: 0.3
lacingWidth: 0  # Lace the both end of 0 or 360 degree to offset inaccurate segementation at boundary of input image
TTA: False       #TestTime Augmentation
TTA_StepDegree: 0 # roration step degree of TTA, in integer degree
# data augmentation

netPath: "/home/hxie1/data/OCT_Duke/numpy_slices/netParameters"  # net is saved at netpath / network / self_filename
loadNetPath: ""
outputDir: ""

usePrimalDualIPM: True
useLayerDice: False
useReferSurfaceFromLayer: False
useLayerCE: False
useCEReplaceKLDiv: False
useSmoothSurfaceLoss: True
useWeightedDivLoss: True
useRift: True
smoothRift: True  # smooth Rift in ground truth
smoothHalfWidth: 15  # 5% of image width
smoothPadddingMode: "reflect" # paddingMode: 'constant', 'reflect', 'replicate' or 'circular'.
smoothRbeforeLoss: False  # use smooth predicted R to compare loss with smooth ground truth R

gradientRiftConvGoBack: False

useCalibrate: False  # Calibrate mu according to r and sigma2
useMergeMuRift: False #  update mu according to r and sigma2
useLearningPairWeight: True  # learning pairwise weight
fixedPairWeight: False  # in soft constraint, pairwise terms add weight $\sigma_i^2/(\sigma_i^2 + \sigma_{i-1}^2)$



# constrained model, both False meaning RelU
hardSeparation: 1
softSeparation: True
useReLUInPretrain: True

goodBscans: []