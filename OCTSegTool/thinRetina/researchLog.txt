# May 12th, Wednesday, 2021
Meeting time: 10am -11am May 12th, Wednesday, 2021
Attendee:  Jui Kai, Hui
Topic: About BMO prediction and VAE project
Minutes:
1  BMO prediction project:
   We can first use 2D Bscans as input to predict the middle-broken low boundaries of RPE complex.
   The 2 opening points of BMO are usually corresponding around the swelling peak on ILM, which can give some information to help prediction.
   Each patient may have 3 Bscans for our data.
2  Use VAE to detect segmentation map.
   The output of VAE is not the recovery image as the traditional VAE, but the low dimension surface segmentation.
   The final goal of this project is to manipulate the latent vector to get different surface shape, which expresses the disease manifestations.

1 In the thin RNFL case, there is still some boundary information of low boundary of the thin RNFL.
2 Some time, the Ophthalmologist needs to use other Bscan information to infer the surface boundary of the current Bscan.
3 The dataset for glaucoma:
  diseased cases: about 25, control case: about 25,   with size of 200x200x1024, where X: #Ascans, Y:#Bscans, Z, Penetration depth.
  number of surfaces: about 5.
  OCT may have different dimension size, we need to unify them into one same size.
4 further thinking: Use volume OCT image with VAE to detect Bruch membrane opening (BMO).


#May 11th, research VAE
1  Generative Adversarial Networks (GANs) and Variational Autoencoders (VAEs) arr both generative models.
   a VAE is an autoencoder whose encodings distribution is regularised during the training in order to
   ensure that its latent space has good properties allowing us to generate some new data.

autoencoders cannot be used to generate new data and will introduce Variational Autoencoders that are
 regularised versions of autoencoders making the generative process possible.

Encoder extracts/compresses feature into encoded space or latent space,
 which is a kind of loosy dimensionality reduction.

 the autoencoder is solely trained to encode and decode
  with as few loss as possible, no matter how the latent space is organised.

  satisfying this way the expected continuity and completeness conditions.
  Naturally, as for any regularisation term, this comes at the price of a higher reconstruction error
   on the training data




#May 5th, Wednesday, 2021:
Meeting time: 10am -11am May 5th, Wednesday, 2021
Attendee:  Jui Kai, Hui
Topic: about the OCT segmentation tool.
Minutes:
1 In the thin RNFL case, there is still some boundary information of low boundary of the thin RNFL.
2 Some time, the Ophthalmologist needs to use other Bscan information to infer the surface boundary of the current Bscan.
3 The dataset for glaucoma:
  diseased cases: about 25, control case: about 25,   with size of 200x200x1024, where X: #Ascans, Y:#Bscans, Z, Penetration depth.
  number of surfaces: about 5.
  OCT may have different dimension size, we need to unify them into one same size.
4 further thinking: Use volume OCT image with VAE to detect Bruch membrane opening (BMO).


# April 29th,Thursday, 2021:
Questions needing discussions:
1  I want to know the knowledge and logic from the OCT image which leads you to determine this is a thin RNFL, and the surface RNFL/GCL is very close to or overlaps with the surface ILM.
   If we can express this knowledge and logic as a model or constraint into our network, it may get better accuracy and a more valuable paper.

2   And what are other characteristics of this special disease OCT images?

3   A possible way is to involve a prior knowledge about the normal subject range:
    If this is a case, do we need to add normal/control OCT images with ground truth to help network
    distinguish normal and disease OCT Images.


# April 28th, Wednesday, 2021


Meeting: Wu, Ray, Hui
Details of the segmentation method, including setting up ground truth, network structure, ect..
IRB
Working load/hours/updates
Potential conferences that we can aim for


# Ray email on April 23rd, 2021:
Current issue:
• Currently, the layer segmentation is done by the graph-search algorithm. For most of the healthy
subjects, the macular scans can be segmented correctly. However, for some glaucoma subjects,
due to damage of the optic nerve, the retinal nerve fiber layer (RNFL) and ganglion cell + inner
plexiform layer (GCIPL) start to get thinning [please see the figures above]. Due to the graph-
search inter-surface constrains, the algorithm has a good chance to miss the "invisible" RNFL and
sees the thinning GCIPL as a part of the unreal thick RNFL. Consequently, the GCIPL segmentation
outcome gets to push down to another layer.

Goal:
• We first would like to develop a relatively straightforward deep-learning-based tool to overcome
this segmentation problem for these thin retinas. We hope that the deep learning neural network
can label interested layers correctly and robustly. To make this problem more manageable, we
currently only needs to segment a few layers/surfaces that contains the key information that we
want to measure [e.g., the GCIPL, the internal limiting membrane (ILM), the lower surface of the
outer plexiform layer and the RPE complex. Furthermore, we would like the developing deep
neural network could have the ability to output a projected-view pixel-based layer segmentation
confidence map. So, for a large amount of scan processing, we could only focus on a small portion
of images that need attention for quality control.