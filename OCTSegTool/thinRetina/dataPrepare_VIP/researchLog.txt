# June 21th, Monday,2021
Initial Test result:
  510  nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210620_SurfaceSubnetQ128_10Cases_B3_iibi007.yaml &    18G      meanError = 3.96  maxHD = 118
  511  nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210620_SurfaceSubnetQ128_10Cases_B7_iibi007.yaml &             meanError = 4.25  maxHD = 51    3 validate constraints.
  512  nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210620_SurfaceSubnetQ128_10Cases_B9_iibi007.yaml &             meanError = 3.90  maxHD = 97
  516  nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210620_SurfaceSubnetQ128_10Cases_B11_iibi007.yaml &   18G      meanError = 3.99  maxHD = 58

  462  2021-06-20 09:00:58 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210620_SurfaceSubnetQ96_10Cases_A7_skm2.yaml &   17GB   meanError=4.00 maxHD=64
  463  2021-06-20 09:01:08 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210620_SurfaceSubnetQ96_10Cases_A11_skm2.yaml &  17GB   meanError=3.94 maxHD=70

  440  2021-06-19 17:32:42 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210619_SurfaceSubnetQ64_10Cases_A_skm2.yaml &  17GB     meanError=4.10  maxHD=56
  441  2021-06-19 17:33:44 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210619_SurfaceSubnetQ64_10Cases_B_skm2.yaml &           meanError=3.95  maxHD=63
  442  2021-06-19 17:33:59 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210619_SurfaceSubnetQ96_10Cases_A_skm2.yaml &           meanError=4.16  maxHD=98
  443  2021-06-19 17:34:07 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210619_SurfaceSubnetQ96_10Cases_B_skm2.yaml &           meanError=3.88  maxHD=51  (best)
  444  2021-06-19 17:34:19 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210619_SurfaceSubnetQ128_10Cases_A_skm2.yaml &          meanError=3.83  maxHD = 109
  445  2021-06-19 17:34:25 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210619_SurfaceSubnetQ128_10Cases_B_skm2.yaml &   18GB   meanError=3.92  maxHD = 57


It looks the best result with considering HD is:  testConfig_VIP/expVIP_20210619_SurfaceSubnetQ96_10Cases_B_skm2.
The whole looks good, but at right ends, there are some horizontal short line section, which is reason of overkilling of adjusting.

Use new factor=3.0 for outlier, and switch on/off the smoothingwithprecison:
  500  2021-06-21 22:27:10 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210621_SurfaceSubnetQ96_10Cases_B_skm2.yaml &
  501  2021-06-21 22:27:17 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210621_SurfaceSubnetQ96_10Cases_C_skm2.yaml &
  502  2021-06-21 22:27:23 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210621_SurfaceSubnetQ96_10Cases_E_skm2.yaml &
  503  2021-06-21 22:27:29 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210621_SurfaceSubnetQ96_10Cases_F_skm2.yaml &
  504  2021-06-21 22:27:38 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210621_SurfaceSubnetQ128_10Cases_B_skm2.yaml &
  505  2021-06-21 22:27:43 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210621_SurfaceSubnetQ128_10Cases_C_skm2.yaml &
  506  2021-06-21 22:27:48 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210621_SurfaceSubnetQ128_10Cases_E_skm2.yaml &
  507  2021-06-21 22:27:54 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210621_SurfaceSubnetQ128_10Cases_F_skm2.yaml &






# June 20th, Sunday, 2021

launch traiing for different precision slide window size at 08:47 am June 20th.
  510  nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210620_SurfaceSubnetQ128_10Cases_B3_iibi007.yaml &    18G
  511  nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210620_SurfaceSubnetQ128_10Cases_B7_iibi007.yaml &
  512  nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210620_SurfaceSubnetQ128_10Cases_B9_iibi007.yaml &
  516  nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210620_SurfaceSubnetQ128_10Cases_B11_iibi007.yaml &   18G

  And their test program has run.

===============================================
Run its test program!
  462  2021-06-20 09:00:58 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210620_SurfaceSubnetQ96_10Cases_A7_skm2.yaml &   17GB
  463  2021-06-20 09:01:08 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210620_SurfaceSubnetQ96_10Cases_A11_skm2.yaml &  17GB
==============================================
Now running below Test:
  440  2021-06-19 17:32:42 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210619_SurfaceSubnetQ64_10Cases_A_skm2.yaml &  17GB
  441  2021-06-19 17:33:44 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210619_SurfaceSubnetQ64_10Cases_B_skm2.yaml &
  442  2021-06-19 17:33:59 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210619_SurfaceSubnetQ96_10Cases_A_skm2.yaml &
  443  2021-06-19 17:34:07 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210619_SurfaceSubnetQ96_10Cases_B_skm2.yaml &
  444  2021-06-19 17:34:19 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210619_SurfaceSubnetQ128_10Cases_A_skm2.yaml &
  445  2021-06-19 17:34:25 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210619_SurfaceSubnetQ128_10Cases_B_skm2.yaml &   18GB


After introducing the smoothSurfacesWithPrecision and ajustSurfaceUsingPrecision:
  25 hours/294 epoch = 25*60/294 = 7.14 min/epoch for training


Layer Name and color suggested by Ray:
Ray:

I suggested that we keep these layer names as layer 0, 1, 3, 5, 6, 10, so we don't get confused about all these naming systems



Here are the layers that Dr. Kardon are interested

1. RNFL plot

    --> surface 0, 1

2. GCL-IPL complex plot

    --> surface 1, 3

3. Inner nuclear layer plot

    --> surface 3, 4

4. Outer+inner segments of photoreceptors (excluding RPE or including RPE if this is too hard to segment without RPE)

    --> surface 6, 8

5. Outer plexiform+outer nuclear layer plot

    --> surface 4, 6

6. Total retinal thickness plot

    --> surface 0, 10

7. Outer nuclear layer and all layers after

    --> surface 5, 10



For the RPE en-face view â†’ surface 6, 10





##

Here is the color code range



# Zeiss color map range

layer_info = [{"Name":"RNFL", "Layer":[0,1], "ColorBar":[0,125]},  # Modifed from 350 --> 125; 06/17/2021

              {"Name":"GCIPL", "Layer":[1,3], "ColorBar":[0,225]},

              {"Name":"INL", "Layer":[3,4], "ColorBar":[0,100]},

              {"Name":"OI_Segments", "Layer":[6,8], "ColorBar":[0,75]},

              {"Name":"OPONL", "Layer":[4,6], "ColorBar":[0,250]},

              {"Name":"TR", "Layer":[0,10], "ColorBar":[200,500]},

              {"Name":"ONL_and_Below", "Layer":[5,10], "ColorBar":[100,300]}]





## Function that

## Returns a mimic Zeiss color matching

def create_Zeiss_colorbar():

    cvals = [0, 0.05, 0.25, 0.35, 0.65, 0.8, 0.93, 1]

    colors = ["black", "blue", "cyan", "yellow", "red", "coral", "whitesmoke", "white"]

    norm=plt.Normalize(min(cvals),max(cvals))

    tuples = list(zip(map(norm,cvals), colors))

    cmap = matplotlib.colors.LinearSegmentedColormap.from_list("", tuples)

    return cmap, norm



cmap_z, norm_z = fPlt.create_Zeiss_colorbar()



Example:

fig, ax = plt.subplots(figsize=(4,4))

cf = plt.imshow(median_thickness_map, cmap=cmap_z, norm=norm_z, vmin=cf_min, vmax=cf_max)



cf.set_clim(cf_min, cf_max)





#June 19th, Saturday, 2021
1  learning patience = 20 is better.
2  putting medianFilterSmoothing after loss better.  --ok.
3  median smooth window size = 21 is better.
3  a slight smooth before loss may help with precision.   --done
4  Topo moudule's improvement: use precision to judge to choose above or bottom surface.  --done.
   for example, the spike on surface i will affect surfade i+1, and surface i+2.
   in /raid001/users/hxie1/data/thinRetina/numpy_10cases/log/SurfaceSegNet_Q/expVIP_20210618_SurfaceSubnetQ128_10Cases_D_skm2/testResult/
   PVIP2-4068_Macular_200x200_10-18-2012_12-10-55_OS_sn14463_cube_z_s007_Raw_GT_Predict.png
5  adjust MAD(Median Average Diviation to 2.5)  -- done.

Now running below trainings:
  440  2021-06-19 17:32:42 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210619_SurfaceSubnetQ64_10Cases_A_skm2.yaml &  17GB
  441  2021-06-19 17:33:44 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210619_SurfaceSubnetQ64_10Cases_B_skm2.yaml &
  442  2021-06-19 17:33:59 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210619_SurfaceSubnetQ96_10Cases_A_skm2.yaml &
  443  2021-06-19 17:34:07 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210619_SurfaceSubnetQ96_10Cases_B_skm2.yaml &
  444  2021-06-19 17:34:19 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210619_SurfaceSubnetQ128_10Cases_A_skm2.yaml &
  445  2021-06-19 17:34:25 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210619_SurfaceSubnetQ128_10Cases_B_skm2.yaml &   18GB





Now prepare test below programs:
57204 ?        Rl   1622:24 python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210618_SurfaceSubnetQ64_10Cases_A_skm2.yaml
 57852 ?        Sl   1613:57 python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210618_SurfaceSubnetQ96_10Cases_A_skm2.yaml
 57992 ?        Sl   1593:37 python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210618_SurfaceSubnetQ128_10Cases_A_skm2.yaml
 58101 ?        Rl   1585:18 python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210618_SurfaceSubnetQ128_10Cases_B_skm2.yaml
 58433 ?        Sl   1596:16 python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210618_SurfaceSubnetQ96_10Cases_B_skm2.yaml
 58590 ?        Sl   1618:33 python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210618_SurfaceSubnetQ64_10Cases_B_skm2.yaml
131853 ?        Rl   1085:55 python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210618_SurfaceSubnetQ128_10Cases_C_skm2.yaml
132007 ?        Rl   1087:34 python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210618_SurfaceSubnetQ128_10Cases_D_skm2.yaml


  424  2021-06-19 10:59:38 nohup python3 ./SurfaceSeg_Test.py ../testConfig_VIP/expVIP_20210618_SurfaceSubnetQ64_10Cases_A_skm2.yaml &   muError= 3.74, HD=41;
  425  2021-06-19 10:59:53 nohup python3 ./SurfaceSeg_Test.py ../testConfig_VIP/expVIP_20210618_SurfaceSubnetQ96_10Cases_A_skm2.yaml &   muError=3.77   HD = 61
  426  2021-06-19 11:00:09 nohup python3 ./SurfaceSeg_Test.py ../testConfig_VIP/expVIP_20210618_SurfaceSubnetQ128_10Cases_A_skm2.yaml &  muError=3.75   HD = 79
  427  2021-06-19 11:00:21 nohup python3 ./SurfaceSeg_Test.py ../testConfig_VIP/expVIP_20210618_SurfaceSubnetQ128_10Cases_B_skm2.yaml &  muError=3.64   HD = 93 (best  in this batch)
  428  2021-06-19 11:00:34 nohup python3 ./SurfaceSeg_Test.py ../testConfig_VIP/expVIP_20210618_SurfaceSubnetQ96_10Cases_B_skm2.yaml &   muError=4.11   HD = 111
  429  2021-06-19 11:00:49 nohup python3 ./SurfaceSeg_Test.py ../testConfig_VIP/expVIP_20210618_SurfaceSubnetQ64_10Cases_B_skm2.yaml &   muError=3.90   HD = 75
  430  2021-06-19 11:01:00 nohup python3 ./SurfaceSeg_Test.py ../testConfig_VIP/expVIP_20210618_SurfaceSubnetQ128_10Cases_C_skm2.yaml &  muError=4.06   HD = 31
  431  2021-06-19 11:01:17 nohup python3 ./SurfaceSeg_Test.py ../testConfig_VIP/expVIP_20210618_SurfaceSubnetQ128_10Cases_D_skm2.yaml &  muError=3.82   HD = 96



#June 18th, Friday, 2021
Run  MedianFilterSmoothing versions:
  266  2021-06-18 18:34:19 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210618_SurfaceSubnetQ64_10Cases_A_skm2.yaml &  16G
  268  2021-06-18 18:36:35 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210618_SurfaceSubnetQ96_10Cases_A_skm2.yaml &  17G
  269  2021-06-18 18:36:41 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210618_SurfaceSubnetQ128_10Cases_A_skm2.yaml & 18G
  270  2021-06-18 18:36:47 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210618_SurfaceSubnetQ128_10Cases_B_skm2.yaml &
  271  2021-06-18 18:36:55 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210618_SurfaceSubnetQ96_10Cases_B_skm2.yaml &
  272  2021-06-18 18:37:03 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210618_SurfaceSubnetQ64_10Cases_B_skm2.yaml &

think:
The medianFilter should postprocessing, instead put before Loss.
If putting before loss, the error prediction will lost improvement opportunity as its backgradient disappear.

# medianFilter after loss with windowsize 21.
 289  2021-06-19 00:16:20 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210618_SurfaceSubnetQ128_10Cases_C_skm2.yaml &   18G
 290  2021-06-19 00:16:31 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210618_SurfaceSubnetQ128_10Cases_D_skm2.yaml &   18G




==============================
About the thickness heatmap output

Current we have 6 segmented surfaces (0, 1, 3, 5, 6, 10) with surface names ["ILM", "RNFL-GCL", "IPL-INL", "OPL-HFL", "BMEIS", "OB_RPE"].
What is your ideas for output their thickness heatmap after segmentation? For example,
A output 5 thickness heatmaps from 6 surfaces.
B output the whole retina thickness map between the top surface and the bottom surface.
C Anything else?

Would you please give me your thickness heatmap example in pdf for me to reference for further output?

# initial predicited result
1  good. PVIP2_4083_S013_Raw_GT_Prediction: It looks the prediction is better than ground truth at right upper corner of 2 surface.
2  In expVIP_20210617_SurfaceSubnetQ128_10Cases_B_skm2 result.
   It has spike in some slice, the spike of surface i will lead the spike of surface i+1.
   c=-1/(sqrt(2)*erfcinv(3/2))= 1.4826

====Initial Test result================================
expVIP_20210617_SurfaceSubnetQ32_10Cases_A_skm2:
stdSurfaceError = tensor([0.4200, 1.3549, 1.1116, 0.2938, 0.2124, 0.0159], device='cuda:0')
muSurfaceError = tensor([1.8166, 6.0350, 5.6631, 6.1231, 1.4365, 2.0916], device='cuda:0')
stdError = 2.2550723552703857
muError = 3.86098575592041
hausdorff Distance in pixels = [[41.446075 59.708252 32.708252 45.46498  70.798325 24.3555  ]]

=======================================================
expVIP_20210617_SurfaceSubnetQ64_10Cases_A_skm2:
stdSurfaceError = tensor([0.3303, 1.0405, 0.5636, 0.8235, 0.2273, 0.3663], device='cuda:1')
muSurfaceError = tensor([1.8474, 5.5262, 5.0734, 4.9559, 1.6518, 3.0219], device='cuda:1')
stdError = 1.7093156576156616
muError = 3.6794302463531494
hausdorff Distance in pixels = [[85.55847  78.22513  59.891815 61.44333  61.172333 54.518982]]
pixel number of violating surface-separation constraints: 0

========================================================
expVIP_20210617_SurfaceSubnetQ96_10Cases_A_skm2:
stdSurfaceError = tensor([0.3413, 0.5978, 0.3301, 0.3366, 0.2356, 0.1818], device='cuda:2')
muSurfaceError = tensor([1.7604, 5.7159, 5.1152, 5.0721, 1.5017, 2.5713], device='cuda:2')
stdError = 1.8178144693374634
muError = 3.6227853298187256
hausdorff Distance in pixels = [[70.60849  57.97238  40.63614  29.852936 17.944092 47.01535 ]]
pixel number of violating surface-separation constraints: 0

=======================================================
expVIP_20210617_SurfaceSubnetQ128_10Cases_A_skm2:
stdSurfaceError = tensor([0.2571, 0.6296, 0.7542, 0.9361, 0.1512, 0.1145], device='cuda:3')
muSurfaceError = tensor([1.8171, 5.8194, 5.3940, 5.1244, 1.6977, 2.8741], device='cuda:3')
stdError = 1.8366254568099976
muError = 3.787794589996338
hausdorff Distance in pixels = [[11.2256775 33.97307   32.227722  35.49765   21.374695  62.377167 ]]
pixel number of violating surface-separation constraints: 0

========================================================
expVIP_20210617_SurfaceSubnetQ32_10Cases_B_skm2:
stdSurfaceError = tensor([0.3440, 1.1740, 0.8124, 0.3985, 0.1454, 0.2812], device='cuda:0')
muSurfaceError = tensor([2.1274, 6.3112, 5.1875, 4.9228, 1.8084, 2.9954], device='cuda:0')
stdError = 1.8120994567871094
muError = 3.892133951187134
hausdorff Distance in pixels = [[95.019745 80.35309  56.68643  35.35309  42.99109  62.04956 ]]
pixel number of violating surface-separation constraints: 0

=======================================================
expVIP_20210617_SurfaceSubnetQ64_10Cases_B_skm2: (second best)
stdSurfaceError = tensor([0.3086, 0.3070, 1.0111, 0.4816, 0.3008, 0.2844], device='cuda:1')
muSurfaceError = tensor([1.8607, 5.8555, 5.2226, 4.9455, 1.5389, 2.3094], device='cuda:1')
stdError = 1.871992826461792
muError = 3.622117757797241
hausdorff Distance in pixels = [[76.24527  59.911957 42.24527  24.97818  32.24463  42.613953]]
pixel number of violating surface-separation constraints: 0

========================================================
expVIP_20210617_SurfaceSubnetQ96_10Cases_B_skm2:
stdSurfaceError = tensor([0.3795, 0.8918, 0.3502, 1.1913, 0.1290, 0.0049], device='cuda:4')
muSurfaceError = tensor([1.9020, 5.6497, 5.3540, 5.2461, 1.5536, 2.7111], device='cuda:4')
stdError = 1.8579832315444946
muError = 3.7360854148864746
hausdorff Distance in pixels = [[145.68288   55.66217   39.66217   33.73552   34.473175  59.21814 ]]
pixel number of violating surface-separation constraints: 0

=======================================================
expVIP_20210617_SurfaceSubnetQ128_10Cases_B_skm2: (best)
stdSurfaceError = tensor([0.3970, 0.0290, 1.1339, 0.5597, 0.2954, 0.0079], device='cuda:5')
muSurfaceError = tensor([1.7762, 5.9154, 4.9997, 4.9378, 1.4898, 2.5318], device='cuda:5')
stdError = 1.8563084602355957
muError = 3.608466386795044
hausdorff Distance in pixels = [[589.6748  576.6748  562.34155 536.6748  511.67484 487.34152]]
pixel number of violating surface-separation constraints: 0
========================================================


========================================================

=======================================================


========================================================

# June 17th, Thursday, 2021
Prepare the training script on thinRetina project:
1  config xml file.   --done.
2  training scrirpt.  --done
3  test script.       --done
4  check the writexml file details.  --done.
4  consider different config: segHead width: try 32, 64, 96, 128   --done.

reinstall pytorch 1.8.1 on June 17th, 2021
conda install pytorch==1.8.1 torchvision torchaudio cudatoolkit=11.1 -c pytorch -c nvidia

programs are training:
June 17th, 19:20 launch training:
 71786 pts/0    Rl    19:18 python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210617_SurfaceSubnetQ32_10Cases_A_skm2.yaml     15GB
 130004 pts/0    Sl     1:48 python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210617_SurfaceSubnetQ32_10Cases_B_skm2.yaml
 72367 pts/0    Rl    10:34 python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210617_SurfaceSubnetQ64_10Cases_A_skm2.yaml     16GB
  73093 pts/0    Rl     9:29 python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210617_SurfaceSubnetQ64_10Cases_B_skm2.yaml
 72505 pts/0    Rl    13:34 python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210617_SurfaceSubnetQ96_10Cases_A_skm2.yaml      17GB
 129806 pts/0    Rl     2:34 python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210617_SurfaceSubnetQ96_10Cases_B_skm2.yaml
 72671 pts/0    Rl    12:44 python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210617_SurfaceSubnetQ128_10Cases_A_skm2.yaml     18GB
129696 pts/0    Sl     2:40 python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210617_SurfaceSubnetQ128_10Cases_B_skm2.yaml

training speed at 2.5min/epoch.

June 18th, 10:20 launch training:  finished Test!
132445 pts/0    Sl     1:02 python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210618_SurfaceSubnetQ192_10Cases_A_skm2.yaml    20G
132720 pts/0    Sl     0:39 python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210618_SurfaceSubnetQ256_10Cases_A_skm2.yaml    23G

Test need only 6GB GPU memory.

# Jun 16th, Wednesday, 2021
Meeting with Ray.
1  check the quality of rawGT;
2  what is your thinking about the prediction:
   A  which portion in the surface do you care more about?
   B  what is the manifestation of OCT for glaucoma patients?

Meeting time: 10am -10:40 am June 16th, Wednesday, 2021
Attendee:  Jui Kai, Hui
Topic: Preparation for the thin retina project.
Minutes:
1  Glaucoma patients normally have a thin RNFL. But thin RNFL does not mean a glaucoma.
   Common OCT RNFL thickness near fovea is like a donut shape, while a thin RNFL or a broken donut means some damages on the OCT layers.
2  VIP = Variability In Perimetry Study.
   In the Iowa Variability in Perimetry (VIP) Study, 120 glaucoma subjects and 60 normals were tested every six months for 4 years.

3  From Thursday, Hui wil work on the training script for this thin retina 10 patients.
   Ray can prepare some new independent test cases for verifying the result of our training network.
4  In this project, we need to consider to output all thickness map for all segmentation layer.





# June 12th, Satursday, 2021
Convert all data into
1 packed Numpy array in training and validation.
2 ouput all images with raw and GT.

conda list:
conda list --revisions   # list history version.
conda install --revision N  #  If you want to revert to a previous revision

matplotlib 3.3.4 has segment fault problem. You must use matplotlib 3.4.2

Notes for input data tidy:
0  convert Ray's special raw and xml format into standard BxHxW for images and BxSxW format for surfaces.
1  extracted 6 surfaces (0, 1, 3, 5, 6, 10)
   their surface names: ["ILM", "RNFL-GCL", "IPL-INL", "OPL-HFL", "BMEIS", "OB_RPE"]
2  convert all 1024x512 images and surfaces into 1024x200 size.
3  flip all OS eyes into OD eyes;
4  a slight smooth over the ground truth.
5  make sure all surfaces not interleave.




# June 11th, Friday, 2021
Notes:
1  Ray's raw data dimension:  200x200x1024, where #Bscans x  PenetrationDepth x #Ascans.
2  surface number: 6;
3  ray's trace with _ray

ProProcessing:
0  convert Ray's special raw and xml format to stardard BxHxW for image and BxSxW format for surface.
1  OCT may have different dimension size, we need to scale down the bigger ones into one same size.
2  flip all OS eyes into OD eyes;
3  a slight smooth the ground truth before using:
    A "very gentle" 3D smoothing process (or thin-plate-spline) should be applied to reduce the manual tracing artifact
    Check the smoothing results again in the images to make sure they still look reasonable
4  Make sure the top surface of GCIPL (i.e., surface_1) is NOT above ILM (surface_0)
5  Try to read the OCT image and match the surfaces in your own system

data augmentation:
1  do not flip withd direction, as the nasal and temporal direction is not symmetric in OD/OS eye.

Question:
1  what is rate for control and glaucoma coase in current 10 patients?
   Current 10 patients are all glocoma.
2  current 10 data has same data orientation.

Dicusss with Ray at 13:00-14:00, Friday, June 11th, 2021
1  current Ray's axial order is 200x1024x200, where 1024 is penetration depth.
   Ray's flip the data in its Width and Height direction.
2  Refer Ray's writer code to figure out Ray's image orientation.
3  CapeCoeMacularCubeRawData may contain ONH scan, the scan near cup place:
    It has almost same dimension with fovea OCT volume scan.
    It may has data in hexidecimal format. We can read it and estimate its dimension.


xml file:
/home/sheen/temp/PVIP2-4074_Macular_200x200_11-7-2013_8-14-8_OD_sn26558_cube_z/PVIP2-4074_Macular_200x200_11-7-2013_8-14-8_OD_sn26558_cube_z_Surfaces_Iowa_Ray.xml

In Ray's format: x = W, y = S, z = H.
Zeiss image resolution: BxHxW(200x1024x200): 30.150749um x 1.955034um x 30.150749um
Zeisss image resolution:BxHxW(128x1024x512): 47.244091um x 1.955034um x 11.741680um

Bscan image 1024x512 will reduce to 1024x200.
Its surface ground truth 11x512 will reduce to 11x200,:

directly define a scale matrix of size [W1=512,W2=200]:
1  before normalization, each column sum = W1/W2, each row sum = 1;
2  After normalization, each column sum = 1;


define a 500x200 matrix, col1= [1,1,0.5,0,0,...]^T, col2=[0,0,0,0,0.5,1,1,0,0,... ], and col1 and col2 down shift 10 rows,copy
[1
 1
 0.5 0.5
      1
      1
        1
        1
        0.5 0.5
              1
              1
             ......]*(1/2.5)

1  construct M matrix of size 512x200;
3  use np.matmul support batch matrix muliplication get new image and surface result.


Ray Note:
Check Surface 0, 1, 3, 5, 6, 10 in the surface xml file
See the surface/layer definition in the figure
My tracing: at the end of the xml filename with "_Ray"
Graph search: the regular filename

needing surface index [0, 1, 3, 5, 6, 10]
its surface names: ["ILM", "RNFL-GCL", "IPL-INL", "OPL-HFL", "BMEIS", "OB_RPE"]
all 11 surface names:
['ILM (ILM)', 'RNFL-GCL (RNFL-GCL)', 'GCL-IPL (GCL-IPL)', 'IPL-INL (IPL-INL)', 'INL-OPL (INL-OPL)',
'OPL-Henles fiber layer (OPL-HFL)', 'Boundary of myoid and ellipsoid of inner segments (BMEIS)', 'IS/OS junction (IS/OSJ)',
'Inner boundary of OPR (IB_OPR)', 'Inner boundary of RPE (IB_RPE)', 'Outer boundary of RPE (OB_RPE)']


After extraction, surface dimension: (128, 6, 512)
<scan_characteristics>
        <manufacturer>Carl Zeiss Meditec, Inc.</manufacturer>
        <size>
            <unit>voxel</unit>
            <x>200</x>
            <y>200</y>
            <z>1024</z>
        </size>
        <voxel_size>
            <unit>um</unit>
            <x>30.150749</x>
            <y>30.150749</y>
            <z>1.955034</z>
        </voxel_size>
        <laterality>NA</laterality>
        <center_type>NA</center_type>

<scan_characteristics>
        <manufacturer>Carl Zeiss Meditec, Inc.</manufacturer>
        <size>
            <unit>voxel</unit>
            <x>512</x>
            <y>128</y>
            <z>1024</z>
        </size>
        <voxel_size>
            <unit>um</unit>
            <x>11.741680</x>
            <y>47.244091</y>
            <z>1.955034</z>
        </voxel_size>
        <laterality>NA</laterality>
        <center_type>NA</center_type>
    </scan_characteristics>



#June 10th, Thursday, 2021
below images may have problems:
Current OCT volume axis order: Slice x Height x Width.


# June 9th, Wednesday, 2021
Progress of Converting CirrusHDOCT Dicom files:
1  all image format, pdf can be extracted out.
2  rawData and Measurements can not bee read as its pixel_array is not available, maybe their protocol is private with the manufacture.
   Therefore pydicom can not decode its data.

There are some remaining issues:
1  how to distinguish LSO, fundus image, png.
2  It looks Rui can dump some raw format.

Meeting time: 10am -11:30 am June 9th, Wednesday, 2021
Attendee:  Jui Kai, Hui
Topic: Cirrus HD-OCT raw data, and segmentation project.
Minutes:
For Cirrus HD-OCT data extraction:
   A  think possible technologies to explore the CapeCode Raw data.   --done
   B  use code tag, output the fundus and SLO 2D image (664x512) with meaning names;  --done
   C  output filenames need to record time for repeated cases.   --done.
For thin retina segmentation:
   A  merge 5 graph search result + 5 Ray corrected result. 8 for training, 2 for validation.
   B  Input image has different sizes, so we need to downsample the high resolution images and ground truth into a smaller size.

Now the Dicom reader program is ready:
1  It can output all OCT volume, SLO, Fundus, and analysis pdf report files with meaningful file names.
2  For CapeCod Raw data, as it is manufacturer-inside private tag data, we can not read it. Please refer to further explanation below.
3  Before using this program, you need to install GDCM, Pillow, CharLS, pdlibjpeg python packages needed by pydicom.
4  I tested it in 3 dicom files you shared. Maybe other cases need special tag, please let me know. I can modify it.

Python code:\\garvinlab.storage.iibi.uiowa.edu/garvinlab_prof_wu/code/readCirrusHDOCTDicom.py
              or attached.

CapeCodeRawData are all belong to Private tag data, which is for manufacturer-inside private using for device data management and self-diagnosis.
So all CapeCodRawData have no any protocols explanation in the "Zeiss DICOM Conformance Statement" guide book. It is intentional to make these raw data private, instead public.
Except we sign a NDA with Zeiss and Zeiss would like to cooperate with us in its further device research and development, I don't think we can get its CapeCodeRawData interface protocol.
Trying, even knowledgeable-guess, is not a solution to decode CapeCod protocol.

Other search about Cape Cod:
Cape Cod is a geographic cape extending into the Atlantic Ocean from the southeastern corner of mainland Massachusetts.
CAPE COD: Cirrus Study Repeatability and Reproducibility of RNFL Thickness and Macular thickness measurements of Cirrus Phot and Cirrus Model 4000 in subjects with Retinal Disease.
The National Glaucoma Symposium will not be held as a live event on Cape Cod in 2021.

# Jun 8th, 2021
share dir:

\\garvinlab.storage.iibi.uiowa.edu\garvinlab_prof_wu


# June 8th, Dicom convert:
Summary:

Â·         Basically, my program can access Zeiss' dicom files and read the tags in these files
Â·         However, there so many types of files in their system and the not all the tags can be found in all the files.
Â·         Currently, I rename the files to the format that human can read rather than their internal coding system
Â·         For some image files, I still can't directly access the pixel values. I will work with Hui and see how to deal with them.
Â·         Following are the files that I can convert [and access the data]:

o    .PDF
Â·         Cirrus_OU_ONH and RNFL OU Analysis.pdf
Â·         Guided Progression Analysis.pdf
Â·         Macular Thickness Analysis.pdf
Â·         OU Ganglion Cell OU Analysis.pdf
Â·         HD 5 Line Raster.pdf
Â·         HD 21 Line.pdf
Â·         HD Radial.pdf
Â·         Visual Field.pdf
Â·         GOLDMANN VISUAL FIELDM.pdf
Â·         COMBINED_REPORT_24-2_RNFL.pdf
Â·         GPAL3F.pdf
Â·         GPA_SUMMARY_SITA_STANDARD.pdf
Â·         SFA.pdf
Â·         All_Color_Fundus_Photo.pdf

o    .PNG
Â·         LSO.png [Line Scanning Ophthalmoscope]
Â·         ColorFundus.png

o    .RAW
Â·         Macular-Cube-200x200.raw
Â·         HD-5-Line-Raster.raw
Â·         5-Line-Raster.raw
Â·         RASTER_RADIAL.raw
Â·         RASTER_21_LINES.raw


Â·         Following are the format that I need to work with Hui and see if we can figure out [otherwise, we may need help from Zeiss] [maybe for some of them, we have .pdf and these are just their raw data format.]
o    HfaVisualFieldRawData
o    HfaPerimetryOphthalmicPhotography8BitImage
o    CapeCodGuidedProgressionAnalysisRawData
o    HfaOphthalmicVisualFieldStaticPerimetryMeasurements
o    CapeCodOpticDiscCubeRawData
o    CapeCodOpticDiscAnalysisRawData
o    CapeCodMacularCubeAnalysisRawData
o    CapeCodMacularCubeRawData


# June 2nd, Wednesday, 2021
Meeting time: 10am -10:40 am June 2nd, Wednesday, 2021
Attendee:  Jui Kai, Hui
Topic: About the thin retina segmentation
Minutes:
1  After getting the initial ground truth corrected by Ray from graph search result, we need to do:
   A rescaling image to uniform dimension;
   B flip all OS eyes into OD eyes;
   C a slight smooth the ground truth before using.
2  Note: in the deep learning augmentation, do not use flip as the nasal and temporal direction is not symmetric in OD/OS eye.

Ray's comments:
Notes for manual tracing:
Surface 0, 1, 3, 6, 10 in the surface xml file â†’ I will add surface 5 soon
My tracing: at the end of the xml filename with "_Ray"
Graph search: the regular filename
Try to read the OCT image and match the surfaces in your own system

A "very gentle" 3D smoothing process (or thin-plate-spline) should be applied to reduce the manual tracing artifact
Check the smoothing results again in the images to make sure they still look reasonable
Make sure the top surface of GCIPL (i.e., surface_1) is NOT above ILM (surface_0)

I also added some scans with acceptable graph search results
Flip the OS to the OD orientation
It's acceptable (doesn't have to) that the ILM and GCIPL surfaces touch each other at the fovea
It's also acceptable that ILM and top GCIPL surface very close to each other



# May 26th, Wednesday, 2021
Meeting time: 10am -10:40 am May 26th, Wednesday, 2021
Attendee:  Jui Kai, Hui
Topic: About Dicom converter and ground truth.
Minutes:
1  For the Cirrus HD-OCT 6000 instrument, we need to decode all Dicom information to mhd/raw format or pdf, not just the OCT volume.
   There are some risks that the manufacture may encrypt the dicom data in order to sell its value-added software.
   We will try to decode the format. Hui will do this in the first week of June.
2  Ray will generate the ground truth of 5 patients for the VIP OCT data in the first week of June.
   HUi will use the 5 ground truth to generate 25 initial ground truth by deep learning network, and then Ray will manually modify it.
3  The current OCT viewer needs to add support multi-Bscan browse function.  Hui will help Ray to modify it.




# May 22nd, Saturday, 2021
1  Use Slicer on X11 forwarding. use ssh -X instead of ssh -Y option.  --done.
2  convert Dicom to Nrrd.
3  write a script of Nrrd read program.
4  connect vpn.healthcare.uiowa.edu.

/home/hxie1/data/Ophthalmology/3Dicom/Test/Orig_Output_from_Zeiss/01082671/2017-02-13   : Macular cube 200x200_2   




# May 21th, Friday, 2021
Dicom file analysis:
1  there are 3 patient Dicom.
2  Each patient has 4-5 visit records in different dates.
3  Each date has 4 volumes OCT volumes, but these 4 OCT volumes has same content. (We may need to save one volue, need to confirm?)
4  OCT volume size: 200x1024x200 in #AScans x PenetrationDepth x #Bscans format.
5  Convert each date record as a Raw file or Nrrd file?
6  Save a volume or a series separate Bscan?







# May 19th, Wednesday, 2021
Meeting time: 10am -10:40 am May 19th, Wednesday, 2021
Attendee:  Jui Kai, Hui
Topic: About BMO prediction and VAE project
Minutes:
1  The project using VAE to detect BMO:
    A  It has 3 surfaces each B-scan, 3 segmented B-scan per patient, total has 100+ patients.
    B  Segmentation of Less-one pixel accuracy is not very important as ground truth self may has errors bigger than one pixel.
       A reasonable result even with 3-5 pixels error is more important.
       Ray: Yes, a reliable segmentation globally is the focus here; so far, these layers are more important:
       RNFL, GCIPL, RPE complex, maybe also include the lower bounding surface of the OPL [i.e., Surface: 0, 1, 3, 5, 6, 10]

    C  For the manual segmentation tool, we need further improve its UI function for easier using.
    D  After the improving manual segmentation tools, a NewYork doctor may help us to get more ground truth.
2  For the thin retina project:
    A  Jui will offer segmentation ground truth for 5 patients.
    B  Basing on this 5 patient ground truth, we will use an initial segmentation network to generate more ground truth for further manual correction.
    C  Getting the thickness percent of diseased patients vs normal patients is more important publication.
3  Jui will give some Dicom images with irregular axis orientation to Hui, and then Hui help convert them into raw format for further use.


# May 12th, Wednesday, 2021
Meeting time: 10am -11am May 12th, Wednesday, 2021
Attendee:  Jui Kai, Hui
Topic: About BMO prediction and VAE project
Minutes:
1  BMO prediction project:
   We can first use 2D Bscans as input to predict the middle-broken low boundaries of RPE complex.
   The 2 opening points of BMO are usually corresponding around the swelling peak on ILM, which can give some information to help prediction.
   Each patient may have 3 Bscans for our data.
2  Use VAE to detect segmentation map.
   The output of VAE is not the recovery image as the traditional VAE, but the low dimension surface segmentation.
   The final goal of this project is to manipulate the latent vector to get different surface shape, which expresses the disease manifestations.

1 In the thin RNFL case, there is still some boundary information of low boundary of the thin RNFL.
2 Some time, the Ophthalmologist needs to use other Bscan information to infer the surface boundary of the current Bscan.
3 The dataset for glaucoma:
  diseased cases: about 25, control case: about 25,   with size of 200x200x1024, where X: #Ascans, Y:#Bscans, Z, Penetration depth.
  number of surfaces: about 5.
  OCT may have different dimension size, we need to unify them into one same size.
4 further thinking: Use volume OCT image with VAE to detect Bruch membrane opening (BMO).


#May 11th, research VAE
1  Generative Adversarial Networks (GANs) and Variational Autoencoders (VAEs) arr both generative models.
   a VAE is an autoencoder whose encodings distribution is regularised during the training in order to
   ensure that its latent space has good properties allowing us to generate some new data.

autoencoders cannot be used to generate new data and will introduce Variational Autoencoders that are
 regularised versions of autoencoders making the generative process possible.

Encoder extracts/compresses feature into encoded space or latent space,
 which is a kind of loosy dimensionality reduction.

 the autoencoder is solely trained to encode and decode
  with as few loss as possible, no matter how the latent space is organised.

  satisfying this way the expected continuity and completeness conditions.
  Naturally, as for any regularisation term, this comes at the price of a higher reconstruction error
   on the training data




#May 5th, Wednesday, 2021:
Meeting time: 10am -11am May 5th, Wednesday, 2021
Attendee:  Jui Kai, Hui
Topic: about the OCT segmentation tool.
Minutes:
1 In the thin RNFL case, there is still some boundary information of low boundary of the thin RNFL.
2 Some time, the Ophthalmologist needs to use other Bscan information to infer the surface boundary of the current Bscan.
3 The dataset for glaucoma:
  diseased cases: about 25, control case: about 25,   with size of 200x200x1024, where X: #Ascans, Y:#Bscans, Z, Penetration depth.
  number of surfaces: about 5.
  OCT may have different dimension size, we need to unify them into one same size.
4 further thinking: Use volume OCT image with VAE to detect Bruch membrane opening (BMO).


# April 29th,Thursday, 2021:
Questions needing discussions:
1  I want to know the knowledge and logic from the OCT image which leads you to determine this is a thin RNFL, and the surface RNFL/GCL is very close to or overlaps with the surface ILM.
   If we can express this knowledge and logic as a model or constraint into our network, it may get better accuracy and a more valuable paper.

2   And what are other characteristics of this special disease OCT images?

3   A possible way is to involve a prior knowledge about the normal subject range:
    If this is a case, do we need to add normal/control OCT images with ground truth to help network
    distinguish normal and disease OCT Images.


# April 28th, Wednesday, 2021


Meeting: Wu, Ray, Hui
Details of the segmentation method, including setting up ground truth, network structure, ect..
IRB
Working load/hours/updates
Potential conferences that we can aim for


# Ray email on April 23rd, 2021:
Current issue:
â€¢ Currently, the layer segmentation is done by the graph-search algorithm. For most of the healthy
subjects, the macular scans can be segmented correctly. However, for some glaucoma subjects,
due to damage of the optic nerve, the retinal nerve fiber layer (RNFL) and ganglion cell + inner
plexiform layer (GCIPL) start to get thinning [please see the figures above]. Due to the graph-
search inter-surface constrains, the algorithm has a good chance to miss the "invisible" RNFL and
sees the thinning GCIPL as a part of the unreal thick RNFL. Consequently, the GCIPL segmentation
outcome gets to push down to another layer.

Goal:
â€¢ We first would like to develop a relatively straightforward deep-learning-based tool to overcome
this segmentation problem for these thin retinas. We hope that the deep learning neural network
can label interested layers correctly and robustly. To make this problem more manageable, we
currently only needs to segment a few layers/surfaces that contains the key information that we
want to measure [e.g., the GCIPL, the internal limiting membrane (ILM), the lower surface of the
outer plexiform layer and the RPE complex. Furthermore, we would like the developing deep
neural network could have the ability to output a projected-view pixel-based layer segmentation
confidence map. So, for a large amount of scan processing, we could only focus on a small portion
of images that need attention for quality control.