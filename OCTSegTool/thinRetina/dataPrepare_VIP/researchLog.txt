#July 7th, Wednesday, 2021:
Test different TPS smoothing:
 1028  2021-07-07 13:14:26 nohup python3 ./SurfaceSeg_Test.py ../testConfig_VIP/expVIP_20210707_SurfaceSubnetQ96_13Cases_3M3C_A_skm2.yaml &
 Surface muError ± std:
2.74±0.67	6.28±0.62	6.08±0.54	4.52±0.41	2.21±1.00	2.95±0.69
muError ± std: 4.13±1.75
Hausdorff Distance in pixels = [[94.62335  34.318085 53.472107 33.89804  17.14444  17.554321]]

 1029  2021-07-07 13:14:31 nohup python3 ./SurfaceSeg_Test.py ../testConfig_VIP/expVIP_20210707_SurfaceSubnetQ96_13Cases_3M3C_B_skm2.yaml &
Surface muError ± std:
2.73±0.67	6.27±0.62	6.07±0.54	4.52±0.41	2.22±1.00	2.95±0.69
muError ± std: 4.13±1.75
Hausdorff Distance in pixels = [[93.91702  34.069    53.06534  33.92282  17.122772 17.543152]]

 1030  2021-07-07 13:14:36 nohup python3 ./SurfaceSeg_Test.py ../testConfig_VIP/expVIP_20210707_SurfaceSubnetQ96_13Cases_3M3C_C_skm2.yaml &
 Surface muError ± std:
2.73±0.66	6.27±0.62	6.07±0.54	4.51±0.41	2.22±1.01	2.95±0.69
muError ± std: 4.12±1.74
Hausdorff Distance in pixels = [[93.25528  33.742126 52.73117  33.948486 17.102905 17.534271]]


 1031  2021-07-07 13:14:41 nohup python3 ./SurfaceSeg_Test.py ../testConfig_VIP/expVIP_20210707_SurfaceSubnetQ96_13Cases_3M3C_D_skm2.yaml &
 Surface muError ± std:
2.72±0.66	6.27±0.62	6.06±0.54	4.51±0.41	2.22±1.01	2.95±0.69
muError ± std: 4.12±1.74
Hausdorff Distance in pixels = [[92.60251  33.43091  52.426514 33.97473  17.08487  17.52713 ]]


 1032  2021-07-07 13:14:45 nohup python3 ./SurfaceSeg_Test.py ../testConfig_VIP/expVIP_20210707_SurfaceSubnetQ96_13Cases_3M3C_E_skm2.yaml &
 Surface muError ± std:
2.72±0.66	6.26±0.62	6.06±0.54	4.51±0.41	2.22±1.01	2.96±0.69
muError ± std: 4.12±1.74
Hausdorff Distance in pixels = [[91.966125 33.13333  52.14615  34.001312 17.068604 17.521362]]


 1033  2021-07-07 13:14:49 nohup python3 ./SurfaceSeg_Test.py ../testConfig_VIP/expVIP_20210707_SurfaceSubnetQ96_13Cases_3M3C_F_skm2.yaml &
 Surface muError ± std:
2.72±0.66	6.26±0.62	6.06±0.54	4.51±0.41	2.22±1.01	2.96±0.69
muError ± std: 4.12±1.74
Hausdorff Distance in pixels = [[91.34973  32.84793  51.88611  34.028076 17.053925 17.516693]]


 1034  2021-07-07 13:14:56 nohup python3 ./SurfaceSeg_Test.py ../testConfig_VIP/expVIP_20210707_SurfaceSubnetQ96_13Cases_3M3C_G_skm2.yaml &
 Surface muError ± std:
2.72±0.66	6.26±0.62	6.05±0.54	4.51±0.41	2.23±1.01	2.96±0.69
muError ± std: 4.12±1.74
Hausdorff Distance in pixels = [[90.75488  32.573547 51.643402 34.05493  17.04065  17.51294 ]]


 1035  2021-07-07 13:15:01 nohup python3 ./SurfaceSeg_Test.py ../testConfig_VIP/expVIP_20210707_SurfaceSubnetQ96_13Cases_3M3C_H_skm2.yaml &  TPSSmoothing=2.1
 Surface muError ± std:
2.72±0.66	6.26±0.61	6.05±0.54	4.51±0.41	2.23±1.01	2.96±0.69
muError ± std: 4.12±1.74
Hausdorff Distance in pixels = [[90.181885 32.309204 51.41562  34.081818 17.028656 17.509949]]





Meeting time: 10am -11:10 am July 7th, Wednesday, 2021
Attendee:  Jui Kai, Hui
Topic: Discussion on test result on the 13 glaucoma cases.
Minutes:
1  current method uses 3 smoothed continuous Bscans and corresponding 3 CLAHE Bscans as input.
2  TPS may not strictly stick the control points, and it may allow some deviation distance to the control points values.
   This will allieviate the spike prediction.
3  1000 control points is too big? we may consider to use 600 points.
4  For 512x128 original images, final output result needs to resize back.
5  Put the original raw files into xml directory.
6  after a good segmentation result, we need to consider to output thickness map.

Current best result: expVIP_20210705_SurfaceSubnetQ96_13Cases_3M3C_skm2.yaml  &   muError ± std: 4.13±1.75   BEST.
===============Formal Output Result ===========
patientIDList =['PVIP2-4093_Macular_200x200_8-28-2013_12-3-48_OS_sn26990_cube_z_B200', 'PVIP2-4089_Macular_512x128_3-30-2011_10-5-50_OS_sn17026_cube_z_B128', 'PVIP2-4095_Macular_200x200_3-27-2012_10-17-17_OD_sn18398_cube_z_B200']
Surface muError ± std:
2.74±0.67	6.28±0.62	6.08±0.54	4.52±0.41	2.21±1.00	2.95±0.69
muError ± std: 4.13±1.75
Hausdorff Distance in pixels = [[94.62335  34.318085 53.472107 33.89804  17.14444  17.554321]]
pixel number of violating surface-separation constraints: 0


After BW surface medianFilter and Smoothing, re-Test Q128_iibi007 programs on Test set:
  510  nohup python3 ./SurfaceSeg_Test.py ../testConfig_VIP/expVIP_20210705_SurfaceSubnetQ128_13Cases_3M2S_iibi007.yaml &    muError ± std: 5.05±3.10

  511  nohup python3 ./SurfaceSeg_Test.py ../testConfig_VIP/expVIP_20210705_SurfaceSubnetQ128_13Cases_3C2S_iibi007.yaml &    muError ± std: 4.23±1.96

  512  nohup python3 ./SurfaceSeg_Test.py ../testConfig_VIP/expVIP_20210705_SurfaceSubnetQ128_13Cases_3M3C2S_iibi007.yaml &  muError ± std: 5.09±2.88

  513  nohup python3 ./SurfaceSeg_Test.py ../testConfig_VIP/expVIP_20210705_SurfaceSubnetQ128_13Cases_3M3C_iibi007.yaml &    muError ± std: 4.35±2.08

 1002  2021-07-07 09:45:41 nohup python3 ./SurfaceSeg_Test.py ../testConfig_VIP/expVIP_20210705_SurfaceSubnetQ96_13Cases_3M_skm2.yaml  &   muError ± std: 4.50±1.88

 1003  2021-07-07 09:45:51 nohup python3 ./SurfaceSeg_Test.py ../testConfig_VIP/expVIP_20210705_SurfaceSubnetQ96_13Cases_3C_skm2.yaml  &   muError ± std: 6.91±4.75

 1004  2021-07-07 09:46:04 nohup python3 ./SurfaceSeg_Test.py ../testConfig_VIP/expVIP_20210705_SurfaceSubnetQ96_13Cases_3C2S_skm2.yaml  &   muError ± std: 5.69±4.20

 1005  2021-07-07 09:46:13 nohup python3 ./SurfaceSeg_Test.py ../testConfig_VIP/expVIP_20210705_SurfaceSubnetQ96_13Cases_3M2S_skm2.yaml  &   muError ± std: 4.91±2.75

 1006  2021-07-07 09:46:21 nohup python3 ./SurfaceSeg_Test.py ../testConfig_VIP/expVIP_20210705_SurfaceSubnetQ96_13Cases_3M3C2S_skm2.yaml  &  muError ± std: 5.17±2.18

 1007  2021-07-07 09:46:31 nohup python3 ./SurfaceSeg_Test.py ../testConfig_VIP/expVIP_20210705_SurfaceSubnetQ96_13Cases_3M3C_skm2.yaml  &   muError ± std: 4.13±1.75   BEST.

 1008  2021-07-07 09:47:23 nohup python3 ./SurfaceSeg_Test.py ../testConfig_VIP/expVIP_20210705_SurfaceSubnetQ128_13Cases_3M_skm2.yaml  &   muError ± std: 5.12±3.11


 1009  2021-07-07 09:47:30 nohup python3 ./SurfaceSeg_Test.py ../testConfig_VIP/expVIP_20210705_SurfaceSubnetQ128_13Cases_3C_skm2.yaml  &   muError ± std: 5.92±4.32





with 5x5 BWsurface median filter: expVIP_20210705_SurfaceSubnetQ96_13Cases_3M3C_skm2
testOutputDir:/raid001/users/hxie1/data/thinRetina/numpy_13cases/log/SurfaceSegNet_Q/expVIP_20210705_SurfaceSubnetQ96_13Cases_3M3C_skm2/testResult/test
=============== End of Config  ===========


=======net running parameters=========
B,S,H,W = (528, 6, 1024, 200)
Test time: 55.17128348350525 seconds.
net.m_runParametersDict:
	validationLoss:1.632839071750641
	epoch:62
	errorMean:4.019517421722412
	learningRate:0.05


===============Formal Output Result ===========
patientIDList =['PVIP2-4093_Macular_200x200_8-28-2013_12-3-48_OS_sn26990_cube_z_B200', 'PVIP2-4089_Macular_512x128_3-30-2011_10-5-50_OS_sn17026_cube_z_B128', 'PVIP2-4095_Macular_200x200_3-27-2012_10-17-17_OD_sn18398_cube_z_B200']
Surface muError ± std:
2.73±0.67	6.28±0.62	6.07±0.54	4.52±0.41	2.21±1.00	2.95±0.69
muError ± std: 4.13±1.75
Hausdorff Distance in pixels = [[94.66498  34.613647 48.364105 33.89804  17.14444  17.554321]]
pixel number of violating surface-separation constraints: 0



#July 6th, Tuesday, 2021:
ThinRetina: prediction result of using 3 smoothed slice and 3 CLAHE slices
dir: /garvinlab/thinRetina/expVIP_20210705_SurfaceSubnetQ96_13Cases_3M3C_skm2_testResult
training: 8 volumes; validation: 2 volumes; test: 3 volumes.

Inintial analysis:
1  Experiments tried 3M, 3C, 3M3C, 3M2S, 3C2S, 3M3C2S different input configs.
   Here, M: smoothed slices; C: CLAHE slices; S: Bscan and Ascan index slices.
2  Experiments shows adding Bscan and Ascan index didn't improvement result.
3  The best result used 3 smoothed slices and 3 CLAHE slices.
4  The visualization result at garvinlab/thinRetina/expVIP_20210705_SurfaceSubnetQ96_13Cases_3M3C_skm2_testResult/images
5  Tomorrow we can review these result together and discuss the improvement direction.

Best Test result: expVIP_20210705_SurfaceSubnetQ96_13Cases_3M3C_skm2
testOutputDir:/raid001/users/hxie1/data/thinRetina/numpy_13cases/log/SurfaceSegNet_Q/expVIP_20210705_SurfaceSubnetQ96_13Cases_3M3C_skm2/testResult/test
=============== End of Config  ===========


=======net running parameters=========
B,S,H,W = (528, 6, 1024, 200)
Test time: 55.28162360191345 seconds.
net.m_runParametersDict:
	validationLoss:1.632839071750641
	epoch:62
	errorMean:4.019517421722412
	learningRate:0.05


===============Formal Output Result ===========
patientIDList =['PVIP2-4093_Macular_200x200_8-28-2013_12-3-48_OS_sn26990_cube_z_B200', 'PVIP2-4089_Macular_512x128_3-30-2011_10-5-50_OS_sn17026_cube_z_B128', 'PVIP2-4095_Macular_200x200_3-27-2012_10-17-17_OD_sn18398_cube_z_B200']
Surface muError ± std:
2.90±0.91	6.39±0.57	6.28±0.68	4.54±0.32	2.03±0.93	2.86±0.59
muError ± std: 4.17±1.84
Hausdorff Distance in pixels = [[161.81023   61.91208   52.365326  32.823425  15.786072  13.276428]]
pixel number of violating surface-separation constraints: 0








=================================
Validation result On July 6th 15:52                                                                                                     validation     ValidationError
1000  2021-07-05 14:27:23 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210705_SurfaceSubnetQ96_13Cases_3M3C2S_skm2.yaml &  epoch 29, meanError=4.19 um
1001  2021-07-05 14:27:34 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210705_SurfaceSubnetQ96_13Cases_3M2S_skm2.yaml &  epoch 37, meanError=4.24 um
1002  2021-07-05 14:27:46 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210705_SurfaceSubnetQ96_13Cases_3C_skm2.yaml &  epoch 26, meanError=4.84 um
1003  2021-07-05 14:27:57 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210705_SurfaceSubnetQ96_13Cases_3C2S_skm2.yaml &  epoch 46 meanError=3.91 um
1004  2021-07-05 14:28:06 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210705_SurfaceSubnetQ128_13Cases_3M_skm2.yaml &          22           4.04um
1005  2021-07-05 14:28:16 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210705_SurfaceSubnetQ128_13Cases_3C_skm2.yaml &          60           3.93um
1006  2021-07-05 14:28:27 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210705_SurfaceSubnetQ96_13Cases_3M_skm2.yaml &  epoch 54, meanError=4.4um
1007  2021-07-05 14:28:37 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210705_SurfaceSubnetQ96_13Cases_3M3C_skm2.yaml &       62           4.02 um

527  nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210705_SurfaceSubnetQ128_13Cases_3M3C_iibi007.yaml &               21              4.01um
528  nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210705_SurfaceSubnetQ128_13Cases_3M3C2S_iibi007.yaml &             27              4.236um
529  nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210705_SurfaceSubnetQ128_13Cases_3M2S_iibi007.yaml &               36              4.21um
530  nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210705_SurfaceSubnetQ128_13Cases_3C2S_iibi007.yaml &               38              3.99um

Analysis:
1   if data has un-aligned error with ground truth(in other words, data is mismatch with groundtruth). It may be arise validation error jump up!
2   For segHead=128, 3C give the best result.
    For segHead=96,  3C2S give the best result.
3   prepare test:
    For segHead=96,  expVIP_20210705_SurfaceSubnetQ96_13Cases_3M3C_skm2.yaml got best result.
    For segHead=128, expVIP_20210705_SurfaceSubnetQ128_13Cases_3C2S_iibi007.yaml got best result.
4  consider the validation and test set, expVIP_20210705_SurfaceSubnetQ96_13Cases_3M3C_skm2.yaml got best.



506  nohup python3 ./SurfaceSeg_Test.py ../testConfig_VIP/expVIP_20210705_SurfaceSubnetQ128_13Cases_3C2S_iibi007.yaml &
Surface muError ± std:
3.16±1.23	6.80±1.64	6.14±1.14	4.40±0.86	2.84±1.53	2.85±0.59
muError ± std: 4.36±2.00
Hausdorff Distance in pixels = [[155.47137  180.25293  180.25293   55.12863   21.492165  32.19763 ]]
pixel number of violating surface-separation constraints: 538
slice number of violating surface-separation constraints: 79


507  nohup python3 ./SurfaceSeg_Test.py ../testConfig_VIP/expVIP_20210705_SurfaceSubnetQ128_13Cases_3M2S_iibi007.yaml &
Surface muError ± std:
4.16±2.53	8.99±3.81	7.05±0.65	4.78±0.67	2.47±0.82	2.94±0.80
muError ± std: 5.07±3.02
Hausdorff Distance in pixels = [[132.74173  145.72864   85.954926  45.643127  50.504578  78.964966]]
pixel number of violating surface-separation constraints: 480
slice number of violating surface-separation constraints: 65


508  nohup python3 ./SurfaceSeg_Test.py ../testConfig_VIP/expVIP_20210705_SurfaceSubnetQ128_13Cases_3M3C2S_iibi007.yaml &
Surface muError ± std:
2.93±0.90	9.03±2.78	7.95±0.66	5.58±0.66	2.06±0.74	3.50±1.04
muError ± std: 5.17±2.92
Hausdorff Distance in pixels = [[134.61533   74.63693   99.51666   99.852325  17.48227   16.314194]]
pixel number of violating surface-separation constraints: 382
slice number of violating surface-separation constraints: 38


509  nohup python3 ./SurfaceSeg_Test.py ../testConfig_VIP/expVIP_20210705_SurfaceSubnetQ128_13Cases_3M3C_iibi007.yaml &
Surface muError ± std:
3.29±1.21	6.96±1.72	6.17±0.80	5.05±1.22	2.35±1.08	2.76±0.76
muError ± std: 4.43±2.10
Hausdorff Distance in pixels = [[108.75569   59.57962   34.135437  49.273804  17.511871  32.339417]]
pixel number of violating surface-separation constraints: 95
slice number of violating surface-separation constraints: 36


 1006  2021-07-06 16:07:10 nohup python3 ./SurfaceSeg_Test.py ../testConfig_VIP/expVIP_20210705_SurfaceSubnetQ128_13Cases_3M_skm2.yaml &
 Surface muError ± std:
3.07±0.76	8.71±2.96	7.81±1.60	6.35±2.26	2.16±0.95	2.76±0.67
muError ± std: 5.14±3.12
Hausdorff Distance in pixels = [[119.71562  100.82657   64.380585  95.81357   15.284729  15.252045]]
pixel number of violating surface-separation constraints: 677
slice number of violating surface-separation constraints: 97


 1007  2021-07-06 16:07:15 nohup python3 ./SurfaceSeg_Test.py ../testConfig_VIP/expVIP_20210705_SurfaceSubnetQ128_13Cases_3C_skm2.yaml &
Surface muError ± std:
7.33±7.01	11.59±7.93	9.11±3.56	5.63±1.04	2.66±1.66	3.25±0.89
muError ± std: 6.60±5.61
Hausdorff Distance in pixels = [[256.66132  279.2267   272.0573   127.746     69.222595  30.294373]]
pixel number of violating surface-separation constraints: 877
slice number of violating surface-separation constraints: 90

 1014  2021-07-06 16:09:06 nohup python3 ./SurfaceSeg_Test.py ../testConfig_VIP/expVIP_20210705_SurfaceSubnetQ96_13Cases_3M_skm2.yaml &
 Surface muError ± std:
2.78±0.30	6.68±0.28	7.47±1.11	5.16±0.45	3.12±1.36	2.69±0.58
muError ± std: 4.65±2.07
Hausdorff Distance in pixels = [[112.07965  115.470276 140.67386   57.600433  51.123352  18.488861]]
pixel number of violating surface-separation constraints: 1440
slice number of violating surface-separation constraints: 109


 1015  2021-07-06 16:09:14 nohup python3 ./SurfaceSeg_Test.py ../testConfig_VIP/expVIP_20210705_SurfaceSubnetQ96_13Cases_3C_skm2.yaml &
 Surface muError ± std:
4.88±2.89	10.24±4.63	12.89±4.37	8.34±2.53	2.91±1.86	3.10±0.98
muError ± std: 7.06±4.88
Hausdorff Distance in pixels = [[134.18394  125.81911  157.05367  121.33557   22.409607  14.665695]]
pixel number of violating surface-separation constraints: 682
slice number of violating surface-separation constraints: 69


 1016  2021-07-06 16:09:22 nohup python3 ./SurfaceSeg_Test.py ../testConfig_VIP/expVIP_20210705_SurfaceSubnetQ96_13Cases_3C2S_skm2.yaml &
 Surface muError ± std:
5.85±4.96	10.68±6.01	7.65±1.61	5.58±0.58	2.29±1.18	2.91±0.74
muError ± std: 5.83±4.35
Hausdorff Distance in pixels = [[248.15622  272.41846  134.07211   41.79367   19.711304  15.971283]]
pixel number of violating surface-separation constraints: 872
slice number of violating surface-separation constraints: 83


 1017  2021-07-06 16:09:31 nohup python3 ./SurfaceSeg_Test.py ../testConfig_VIP/expVIP_20210705_SurfaceSubnetQ96_13Cases_3M2S_skm2.yaml &
 Surface muError ± std:
3.60±2.01	6.78±0.89	9.35±2.30	5.15±1.08	2.29±1.25	3.01±0.66
muError ± std: 5.03±2.85
Hausdorff Distance in pixels = [[166.98978   56.805084  74.50253   99.66321   80.273315  16.556519]]
pixel number of violating surface-separation constraints: 1228
slice number of violating surface-separation constraints: 83


 1018  2021-07-06 16:09:40 nohup python3 ./SurfaceSeg_Test.py ../testConfig_VIP/expVIP_20210705_SurfaceSubnetQ96_13Cases_3M3C2S_skm2.yaml &
Surface muError ± std:
4.81±2.10	7.48±0.73	7.31±0.61	5.51±0.68	2.94±1.51	3.14±0.82
muError ± std: 5.20±2.16
Hausdorff Distance in pixels = [[140.62566   69.608154  39.32544   54.47      40.985962  16.459808]]
pixel number of violating surface-separation constraints: 1222
slice number of violating surface-separation constraints: 149


 1019  2021-07-06 16:09:46 nohup python3 ./SurfaceSeg_Test.py ../testConfig_VIP/expVIP_20210705_SurfaceSubnetQ96_13Cases_3M3C_skm2.yaml &
Surface muError ± std:
2.85±0.68	6.58±0.53	6.60±0.80	4.64±0.42	2.21±1.03	2.97±0.68
muError ± std: 4.31±1.91
Hausdorff Distance in pixels = [[154.33438   97.43851  137.8135    33.1362    19.136642  15.956696]]
pixel number of violating surface-separation constraints: 670
slice number of violating surface-separation constraints: 68






#July 5th, Monday, 2021

relauch thinRetina training:
1000  2021-07-05 14:27:23 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210705_SurfaceSubnetQ96_13Cases_3M3C2S_skm2.yaml &
 1001  2021-07-05 14:27:34 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210705_SurfaceSubnetQ96_13Cases_3M2S_skm2.yaml &
 1002  2021-07-05 14:27:46 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210705_SurfaceSubnetQ96_13Cases_3C_skm2.yaml &
 1003  2021-07-05 14:27:57 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210705_SurfaceSubnetQ96_13Cases_3C2S_skm2.yaml &
 1004  2021-07-05 14:28:06 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210705_SurfaceSubnetQ128_13Cases_3M_skm2.yaml &
 1005  2021-07-05 14:28:16 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210705_SurfaceSubnetQ128_13Cases_3C_skm2.yaml &
 1006  2021-07-05 14:28:27 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210705_SurfaceSubnetQ96_13Cases_3M_skm2.yaml &
 1007  2021-07-05 14:28:37 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210705_SurfaceSubnetQ96_13Cases_3M3C_skm2.yaml &

527  nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210705_SurfaceSubnetQ128_13Cases_3M3C_iibi007.yaml &
  528  nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210705_SurfaceSubnetQ128_13Cases_3M3C2S_iibi007.yaml &
  529  nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210705_SurfaceSubnetQ128_13Cases_3M2S_iibi007.yaml &
  530  nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210705_SurfaceSubnetQ128_13Cases_3C2S_iibi007.yaml &



All below experiments, as without clone in dataloder, its data were contaminated.
Check training result of 3M3C2S and its combinations:
  537  nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210701_SurfaceSubnetQ128_13Cases_3C2S_iibi007.yaml &   validation error jump. validation meanerror=160um.
  538  nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210701_SurfaceSubnetQ128_13Cases_3M2S_iibi007.yaml &   validation error jump. validation meanerror=160um.
  539  nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210701_SurfaceSubnetQ128_13Cases_3M3C_iibi007.yaml &   validation meanError=4.57um at epoch 41.
  540  nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210701_SurfaceSubnetQ128_13Cases_3M3C2S_iibi007.yaml &  validation meanError=4.233um at epoch 53.

  921  2021-07-01 17:05:16 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210701_SurfaceSubnetQ96_13Cases_3M_skm2.yaml &  validation error jump.
  922  2021-07-01 17:17:02 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210701_SurfaceSubnetQ96_13Cases_3C_skm2.yaml &  validation error jump.
  923  2021-07-01 17:17:14 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210701_SurfaceSubnetQ96_13Cases_3M2S_skm2.yaml &  validation error jump.
  924  2021-07-01 17:17:24 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210701_SurfaceSubnetQ96_13Cases_3C2S_skm2.yaml &  validation error jump.  validationError=160um.
  925  2021-07-01 17:17:38 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210701_SurfaceSubnetQ96_13Cases_3M3C_skm2.yaml &  validation meanError=4.141um at epoch 72.
  926  2021-07-01 17:17:49 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210701_SurfaceSubnetQ96_13Cases_3M3C2S_skm2.yaml &  validation meanError=4.367um at epoch 67.
  927  2021-07-01 17:18:11 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210701_SurfaceSubnetQ128_13Cases_3M_skm2.yaml &     validation error jump.
  928  2021-07-01 17:18:25 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210701_SurfaceSubnetQ128_13Cases_3C_skm2.yaml &    validation error jump.


Analysis on Validation error:
1  3M3C and 3M3C2S both are ok for Q96 and Q128. While other 3M or 3C all are diverge.
   More channels make training less diverge.
2  One possible reason of training diverge is that too high learning rate.
   More input channels make program easy to train???





# July 1st, Thursday, 2021
Run training for 8 channel inputs(3 smoothed+3 Clahe + 2 space):
909  2021-07-01 13:12:37 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210630_SurfaceSubnetQ96_13Cases_A_skm2.yaml &
911  2021-07-01 13:23:12 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210701_SurfaceSubnetQ128_13Cases_B_skm2.yaml &

Above 2 experiment are killed for below new experiments.

about 4 min/epoch in training speed.

Experiment design: M:sMoothed images, C: CLAHE images, S: Space slices.
1  3 smoothed: 3M
2  3 CLAHE:    3C
3  3 smoothed + 3 CLAHE:  3M3C
4  3 smoothed + 2 Space:  3M2S
5  3 CLAHE    + 2 Space:  3C2S
6  3 smoothed + 3 CLAHE + 2 space: 3M3C2S

And SegHeadWidth: 96 or 128.
17:00, below 12 experiments are running:
  921  2021-07-01 17:05:16 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210701_SurfaceSubnetQ96_13Cases_3M_skm2.yaml &
  922  2021-07-01 17:17:02 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210701_SurfaceSubnetQ96_13Cases_3C_skm2.yaml &
  923  2021-07-01 17:17:14 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210701_SurfaceSubnetQ96_13Cases_3M2S_skm2.yaml &
  924  2021-07-01 17:17:24 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210701_SurfaceSubnetQ96_13Cases_3C2S_skm2.yaml &
  925  2021-07-01 17:17:38 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210701_SurfaceSubnetQ96_13Cases_3M3C_skm2.yaml &
  926  2021-07-01 17:17:49 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210701_SurfaceSubnetQ96_13Cases_3M3C2S_skm2.yaml &
  927  2021-07-01 17:18:11 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210701_SurfaceSubnetQ128_13Cases_3M_skm2.yaml &
  928  2021-07-01 17:18:25 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210701_SurfaceSubnetQ128_13Cases_3C_skm2.yaml &

  537  nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210701_SurfaceSubnetQ128_13Cases_3C2S_iibi007.yaml &
  538  nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210701_SurfaceSubnetQ128_13Cases_3M2S_iibi007.yaml &
  539  nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210701_SurfaceSubnetQ128_13Cases_3M3C_iibi007.yaml &
  540  nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210701_SurfaceSubnetQ128_13Cases_3M3C2S_iibi007.yaml &








# June 30th, Wednesday, 2021
Meeting time: 10am -11:50 am June 30th, Wednesday, 2021
Attendee:  Jui Kai, Hui
Topic: Discussion on initial CLAHE images.
Minutes:
1  fixed  an error that loaded images should be converted into float before using.   --done
2  use 6 channels image(smoothed continues 3 Bscan, and their corresponding CLAHE images);   --done
3  plus 2 space location channels indicate B-scan location and A-scan location, total 8 channel inputs.  --done.





# June 29th, Tuesday, 2021
For the 3D height sample:
choose N random points from a BxW surface images, in order to make denser sample near fovea.
row[0:B/4]: choices N/8 points.
row[B/4: B/2]:choices 3N/8 points.
row[B/4: B*3/4]: sample 3N/8 points.
row[B*3/4: B] : sample N/8 points.

Task decomposition:
1  The output xml segmentation file of OS case should flip back to original OS direction.   --done

2  research  3D-height sampling rate thin-plate spline:  --done

3  we can consider to do the 3D-height sampling rate thin-plate spline on the ground truth and segmentation result. --done for groundtruth
   same parameters should apply to both ground truth and segmentation result.                                       ---done for prediction.

4  For input raw images:
   A. First, Average 3 B-scans as  the middle Bscans of 3 as input, to erase the noise of raw images and the spike the segmentation result.  --done
   B. Second, Use CLAHE (Contrast Limited Adaptive Histogram Equalization) method to increase the contrast of smoothed Bscan.   --done
      skimage.exposure.equalize_adapthist(image, kernel_size=None, clip_limit=0.01, nbins=256)
      Contrast Limited Adaptive Histogram Equalization (CLAHE).

   C. After, Images need to do normalization.  --done

5  May consider to input continuous B-scans as RGB channel to input to network, and then check the ground truth of the middle of 3.
   The top and bottom bscan use a repeat as 3-Bscan input.  --done. 3 smoothed image +3 claheImages.

6  Gradient channel may just use the penetration gradient one channel, instead of many gradient channels.  --ignore.

7  a new dataset class for thin retina project.  --done

8  change current rawImage into unsmoothed one.   --done, numpy_10cases




# June 28th, Monday, 2021
About 3D height sample rate thin-plate-spline (TPS) smoothing.
1  random sample about 1000 points from original BxW surface.
   A.  sample points near fovea region may occupy 25%, denser than the surround region.
   B   use a fixed random seed to make sure sample points fixed for a same ground truth;
   C   decide fovea, in the central region point where the thickness between surface 0 and surface 5 miminum;
   D   segmentation result also need to use TPS to make result smooth in whole surface.
   E   neighbor=None as we use all control points.
   F   use random.seed(int) to make a repeatable random experiments.
2  Ray's idea: from some OCT layer, its enface image may show neural fiber.


Fovea central point maybe: (b,w)=(100, 100)
Fovea region:  topleft= (50,50), rightbottom=[150,150], occupying whole BxW about 1/4.


============================

Task for thin retina improvment:
1  The output xml segmentation file of OS case should flip back to original OS direction.

2  research  3D-height sampling rate thin-plate spline:  Thin plate splines (TPS) are a spline-based technique for data interpolation and smoothing.
    https://en.wikipedia.org/wiki/Thin_plate_spline
   The thin plate spline method is often used to ﬁt data in high di-mensions.
   Standard thin plate splines require the solution of a denselinear system of equations whose size increases
   with the number of data points and can be expensive when used on large data sets.
   advantages:
   It produces smooth surfaces, which are infinitely differentiable.
    There are no free parameters that need manual tuning.
    It has closed-form solutions for both warping and parameter estimation.
    There is a physical explanation for its energy function.

    Splines are radial basis functions. In scipy terms, you want scipy.interpolate.Rbf.
    I'd recommend using function="linear" or function="thin_plate" over cubic splines, but cubic is available as well.
    (Cubic splines will exacerbate problems with "overshooting" compared to linear or thin-plate splines.)

    scipy.interpolate.RBFInterpolator(y, d, neighbors=None, smoothing=0.0, kernel='thin_plate_spline', epsilon=None, degree=None)   ---done

3  we can consider to do the 3D-height sampling rate thin-plate spline on the ground truth and segmentation result.
   same parameter should apply to both ground truth and segmentation result.

4  For input raw images:
   A. First, Average 3 B-scans as  the middle Bscans of 3 as input, to erase the noise of raw images and the spike the segmentation result.
   B. Second, Use CLAHE (Contrast Limited Adaptive Histogram Equalization) method to increase the contrast of smoothed Bscan.
   C. After, Images need to do normalization.

5  May consider to input continuous B-scans as RGB channel to input to network, and then check the ground truth of the middle of 3.
   The top and bottom bscan use a repeat as 3-Bscan input.

6  Gradient channel may just use the penetration gradient one channel, instead of many gradient channels.

7  a new dataset class for thin retina project

8  change current rawImage into unsmoothed one.






# Jun23th, Wenday, 2021
Meeting with Ray, possbile discussion points:
1   how is the initial segmentation quality?
2   do you think what is possible improvement?
3   I will launch new test set of 3 patient on Thursday.
4   further work?
5   Paper submission is good.
    OMIA(https://sites.google.com/view/omia8/home, https://omia.grand-challenge.org/Home/)
    submission deadline: July 9th.
    Jul 24      Notification of OMIA8 decisions


Meeting time: 10am -11:25 am June 23th, Wednesday, 2021
Attendee:  Jui Kai, Hui
Topic: Discussion on initial segmentation result on the 10 glaucoma cases.
Minutes:
1  The output xml segmentation file of OS case should flip back to original OS direction.
2  we can consider to do the 3D-height sampling rate thin-plate spline on the ground truth and segmentation result.
   same parameter should apply to both ground truth and segmentation result.
3  For input raw images:
   A. First, Average 3 B-scans as  the middle Bscans of 3 as input, to erase the noise of raw images and the spike the segmentation result.
   B. Second, Use CLAHE (Contrast Limited Adaptive Histogram Equalization) method to increase the contrast of smoothed Bscan.
   C. After, Images need to do normalization.
4  May consider to input continuous B-scans as RGB channel to input to network, and then check the ground truth of the middle of 3.
   The top and bottom bscan use a repeat as 3-Bscan input.
5  Gradient channel may just use the penetration gradient one channel, instead of many gradient channels.
6  Less-one-pixel accuracy is not important, as the intra-error of 2 experts may be bigger than one pixel,
   and the 2-time segmentation results of one expert may be bigger than one-pixel.  A robust result is more important.
7  Using regional segmentation loss may help improve robustness of segmentation, if it would not improve one-pixel accuracy.






# June 22th, Tuesday, 2021:
  500  2021-06-21 22:27:10 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210621_SurfaceSubnetQ96_10Cases_B_skm2.yaml &   muError=4.05, maxHD=69
  501  2021-06-21 22:27:17 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210621_SurfaceSubnetQ96_10Cases_C_skm2.yaml &   muError=3.71, maxHD = 65
  502  2021-06-21 22:27:23 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210621_SurfaceSubnetQ96_10Cases_E_skm2.yaml &   muError=4.02, maxHD = 74 , 1 validate constraint.
  503  2021-06-21 22:27:29 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210621_SurfaceSubnetQ96_10Cases_F_skm2.yaml &   muError=3.94, maxHD = 68m  83 pixels validate constraint.
  504  2021-06-21 22:27:38 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210621_SurfaceSubnetQ128_10Cases_B_skm2.yaml &  muError=3.97, maxHD = 61,   69 pixels validate constraint
  505  2021-06-21 22:27:43 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210621_SurfaceSubnetQ128_10Cases_C_skm2.yaml &  muError=3.97, maxHD = 75.  10 pixels validate constraints.
  506  2021-06-21 22:27:48 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210621_SurfaceSubnetQ128_10Cases_E_skm2.yaml &  muError=4.10, maxHD = 91.  19 pixels validate constraints.
  507  2021-06-21 22:27:54 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210621_SurfaceSubnetQ128_10Cases_F_skm2.yaml &  muError=3.68, maxHD =74,   9 pixels validate constraints.

The best result: expVIP_20210621_SurfaceSubnetQ96_10Cases_C_skm2.yaml

The initial validation result of thinRetina project.

Dataset: training 8 patients, validate on the 2 patients. All patients are glaucoma cases.
         InputSize: 1024x200 for each B-scan.
         Patient volume has 2 kinds of size: 200x1024x200 or 128x1024x200 in #Bscan x PenetrationHeight x #Ascan dimension
         Penetration pixel physical size: 1.955 um/pixel
         surface number: 6
         surface names: ["ILM", "RNFL-GCL", "IPL-INL", "OPL-HFL", "BMEIS", "OB_RPE"].


Result:
1   All raw/GT/Prediction visualization of the validated 2 patients: //garvinlab/thinRetina/expVIP_20210621_SurfaceSubnetQ96_10Cases_C_skm2/images/
2   quantity result on the validation data:
    patientIDList =['PVIP2-4068_Macular_200x200_10-18-2012_12-10-55_OS_sn14463_cube_z', 'PVIP2-4083_Macular_200x200_10-24-2012_10-24-46_OS_sn14353_cube_z']
    stdSurfaceError = tensor([0.2852, 0.3435, 0.8223, 0.2081, 0.1183, 0.1554], device='cuda:1')
    muSurfaceError = tensor([1.8456, 5.4753, 5.6793, 5.3225, 1.6251, 2.3658], device='cuda:1')
    stdError = 1.8926666975021362
    muError = 3.7189223766326904  (mean absolute surface distance error(MASD, um))
    Hausdorff Distance in pixels = [[23.239044 27.6427   28.632294 42.18402  39.45883  65.79611 ]]
    Pixel number of violating surface-separation constraints: 0
3   Notes: This VIP data is different with JHU MS and Duke AMD data as it has just 200 Ascans and all surface are bumpy wave shape, and all are glaucoma cases without control group.
           This VIP data does not has the flat surfaces at both ends, which will help reduce the MASD error on volume dimension.
4   attachment are 2 middle Bscan for each patient for your quick preview.


# June 21th, Monday,2021
Initial Test result:
  510  nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210620_SurfaceSubnetQ128_10Cases_B3_iibi007.yaml &    18G      meanError = 3.96  maxHD = 118
  511  nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210620_SurfaceSubnetQ128_10Cases_B7_iibi007.yaml &             meanError = 4.25  maxHD = 51    3 validate constraints.
  512  nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210620_SurfaceSubnetQ128_10Cases_B9_iibi007.yaml &             meanError = 3.90  maxHD = 97
  516  nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210620_SurfaceSubnetQ128_10Cases_B11_iibi007.yaml &   18G      meanError = 3.99  maxHD = 58

  462  2021-06-20 09:00:58 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210620_SurfaceSubnetQ96_10Cases_A7_skm2.yaml &   17GB   meanError=4.00 maxHD=64
  463  2021-06-20 09:01:08 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210620_SurfaceSubnetQ96_10Cases_A11_skm2.yaml &  17GB   meanError=3.94 maxHD=70

  440  2021-06-19 17:32:42 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210619_SurfaceSubnetQ64_10Cases_A_skm2.yaml &  17GB     meanError=4.10  maxHD=56
  441  2021-06-19 17:33:44 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210619_SurfaceSubnetQ64_10Cases_B_skm2.yaml &           meanError=3.95  maxHD=63
  442  2021-06-19 17:33:59 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210619_SurfaceSubnetQ96_10Cases_A_skm2.yaml &           meanError=4.16  maxHD=98
  443  2021-06-19 17:34:07 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210619_SurfaceSubnetQ96_10Cases_B_skm2.yaml &           meanError=3.88  maxHD=51  (best)
  444  2021-06-19 17:34:19 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210619_SurfaceSubnetQ128_10Cases_A_skm2.yaml &          meanError=3.83  maxHD = 109
  445  2021-06-19 17:34:25 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210619_SurfaceSubnetQ128_10Cases_B_skm2.yaml &   18GB   meanError=3.92  maxHD = 57


It looks the best result with considering HD is:  testConfig_VIP/expVIP_20210619_SurfaceSubnetQ96_10Cases_B_skm2.
The whole looks good, but at right ends, there are some horizontal short line section, which is reason of overkilling of adjusting.

Use new factor=3.0 for outlier, and switch on/off the smoothingwithprecision:
  500  2021-06-21 22:27:10 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210621_SurfaceSubnetQ96_10Cases_B_skm2.yaml &
  501  2021-06-21 22:27:17 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210621_SurfaceSubnetQ96_10Cases_C_skm2.yaml &
  502  2021-06-21 22:27:23 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210621_SurfaceSubnetQ96_10Cases_E_skm2.yaml &
  503  2021-06-21 22:27:29 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210621_SurfaceSubnetQ96_10Cases_F_skm2.yaml &
  504  2021-06-21 22:27:38 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210621_SurfaceSubnetQ128_10Cases_B_skm2.yaml &
  505  2021-06-21 22:27:43 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210621_SurfaceSubnetQ128_10Cases_C_skm2.yaml &
  506  2021-06-21 22:27:48 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210621_SurfaceSubnetQ128_10Cases_E_skm2.yaml &
  507  2021-06-21 22:27:54 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210621_SurfaceSubnetQ128_10Cases_F_skm2.yaml &






# June 20th, Sunday, 2021

launch traiing for different precision slide window size at 08:47 am June 20th.
  510  nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210620_SurfaceSubnetQ128_10Cases_B3_iibi007.yaml &    18G
  511  nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210620_SurfaceSubnetQ128_10Cases_B7_iibi007.yaml &
  512  nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210620_SurfaceSubnetQ128_10Cases_B9_iibi007.yaml &
  516  nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210620_SurfaceSubnetQ128_10Cases_B11_iibi007.yaml &   18G

  And their test program has run.

===============================================
Run its test program!
  462  2021-06-20 09:00:58 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210620_SurfaceSubnetQ96_10Cases_A7_skm2.yaml &   17GB
  463  2021-06-20 09:01:08 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210620_SurfaceSubnetQ96_10Cases_A11_skm2.yaml &  17GB
==============================================
Now running below Test:
  440  2021-06-19 17:32:42 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210619_SurfaceSubnetQ64_10Cases_A_skm2.yaml &  17GB
  441  2021-06-19 17:33:44 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210619_SurfaceSubnetQ64_10Cases_B_skm2.yaml &
  442  2021-06-19 17:33:59 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210619_SurfaceSubnetQ96_10Cases_A_skm2.yaml &
  443  2021-06-19 17:34:07 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210619_SurfaceSubnetQ96_10Cases_B_skm2.yaml &
  444  2021-06-19 17:34:19 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210619_SurfaceSubnetQ128_10Cases_A_skm2.yaml &
  445  2021-06-19 17:34:25 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210619_SurfaceSubnetQ128_10Cases_B_skm2.yaml &   18GB


After introducing the smoothSurfacesWithPrecision and ajustSurfaceUsingPrecision:
  25 hours/294 epoch = 25*60/294 = 7.14 min/epoch for training


Layer Name and color suggested by Ray:
Ray:

I suggested that we keep these layer names as layer 0, 1, 3, 5, 6, 10, so we don't get confused about all these naming systems



Here are the layers that Dr. Kardon are interested

1. RNFL plot

    --> surface 0, 1

2. GCL-IPL complex plot

    --> surface 1, 3

3. Inner nuclear layer plot

    --> surface 3, 4

4. Outer+inner segments of photoreceptors (excluding RPE or including RPE if this is too hard to segment without RPE)

    --> surface 6, 8

5. Outer plexiform+outer nuclear layer plot

    --> surface 4, 6

6. Total retinal thickness plot

    --> surface 0, 10

7. Outer nuclear layer and all layers after

    --> surface 5, 10



For the RPE en-face view → surface 6, 10





##

Here is the color code range



# Zeiss color map range

layer_info = [{"Name":"RNFL", "Layer":[0,1], "ColorBar":[0,125]},  # Modifed from 350 --> 125; 06/17/2021

              {"Name":"GCIPL", "Layer":[1,3], "ColorBar":[0,225]},

              {"Name":"INL", "Layer":[3,4], "ColorBar":[0,100]},

              {"Name":"OI_Segments", "Layer":[6,8], "ColorBar":[0,75]},

              {"Name":"OPONL", "Layer":[4,6], "ColorBar":[0,250]},

              {"Name":"TR", "Layer":[0,10], "ColorBar":[200,500]},

              {"Name":"ONL_and_Below", "Layer":[5,10], "ColorBar":[100,300]}]





## Function that

## Returns a mimic Zeiss color matching

def create_Zeiss_colorbar():

    cvals = [0, 0.05, 0.25, 0.35, 0.65, 0.8, 0.93, 1]

    colors = ["black", "blue", "cyan", "yellow", "red", "coral", "whitesmoke", "white"]

    norm=plt.Normalize(min(cvals),max(cvals))

    tuples = list(zip(map(norm,cvals), colors))

    cmap = matplotlib.colors.LinearSegmentedColormap.from_list("", tuples)

    return cmap, norm



cmap_z, norm_z = fPlt.create_Zeiss_colorbar()



Example:

fig, ax = plt.subplots(figsize=(4,4))

cf = plt.imshow(median_thickness_map, cmap=cmap_z, norm=norm_z, vmin=cf_min, vmax=cf_max)



cf.set_clim(cf_min, cf_max)





#June 19th, Saturday, 2021
1  learning patience = 20 is better.
2  putting medianFilterSmoothing after loss better.  --ok.
3  median smooth window size = 21 is better.
3  a slight smooth before loss may help with precision.   --done
4  Topo moudule's improvement: use precision to judge to choose above or bottom surface.  --done.
   for example, the spike on surface i will affect surfade i+1, and surface i+2.
   in /raid001/users/hxie1/data/thinRetina/numpy_10cases/log/SurfaceSegNet_Q/expVIP_20210618_SurfaceSubnetQ128_10Cases_D_skm2/testResult/
   PVIP2-4068_Macular_200x200_10-18-2012_12-10-55_OS_sn14463_cube_z_s007_Raw_GT_Predict.png
5  adjust MAD(Median Average Diviation to 2.5)  -- done.

Now running below trainings:
  440  2021-06-19 17:32:42 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210619_SurfaceSubnetQ64_10Cases_A_skm2.yaml &  17GB
  441  2021-06-19 17:33:44 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210619_SurfaceSubnetQ64_10Cases_B_skm2.yaml &
  442  2021-06-19 17:33:59 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210619_SurfaceSubnetQ96_10Cases_A_skm2.yaml &
  443  2021-06-19 17:34:07 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210619_SurfaceSubnetQ96_10Cases_B_skm2.yaml &
  444  2021-06-19 17:34:19 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210619_SurfaceSubnetQ128_10Cases_A_skm2.yaml &
  445  2021-06-19 17:34:25 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210619_SurfaceSubnetQ128_10Cases_B_skm2.yaml &   18GB





Now prepare test below programs:
57204 ?        Rl   1622:24 python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210618_SurfaceSubnetQ64_10Cases_A_skm2.yaml
 57852 ?        Sl   1613:57 python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210618_SurfaceSubnetQ96_10Cases_A_skm2.yaml
 57992 ?        Sl   1593:37 python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210618_SurfaceSubnetQ128_10Cases_A_skm2.yaml
 58101 ?        Rl   1585:18 python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210618_SurfaceSubnetQ128_10Cases_B_skm2.yaml
 58433 ?        Sl   1596:16 python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210618_SurfaceSubnetQ96_10Cases_B_skm2.yaml
 58590 ?        Sl   1618:33 python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210618_SurfaceSubnetQ64_10Cases_B_skm2.yaml
131853 ?        Rl   1085:55 python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210618_SurfaceSubnetQ128_10Cases_C_skm2.yaml
132007 ?        Rl   1087:34 python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210618_SurfaceSubnetQ128_10Cases_D_skm2.yaml


  424  2021-06-19 10:59:38 nohup python3 ./SurfaceSeg_Test.py ../testConfig_VIP/expVIP_20210618_SurfaceSubnetQ64_10Cases_A_skm2.yaml &   muError= 3.74, HD=41;
  425  2021-06-19 10:59:53 nohup python3 ./SurfaceSeg_Test.py ../testConfig_VIP/expVIP_20210618_SurfaceSubnetQ96_10Cases_A_skm2.yaml &   muError=3.77   HD = 61
  426  2021-06-19 11:00:09 nohup python3 ./SurfaceSeg_Test.py ../testConfig_VIP/expVIP_20210618_SurfaceSubnetQ128_10Cases_A_skm2.yaml &  muError=3.75   HD = 79
  427  2021-06-19 11:00:21 nohup python3 ./SurfaceSeg_Test.py ../testConfig_VIP/expVIP_20210618_SurfaceSubnetQ128_10Cases_B_skm2.yaml &  muError=3.64   HD = 93 (best  in this batch)
  428  2021-06-19 11:00:34 nohup python3 ./SurfaceSeg_Test.py ../testConfig_VIP/expVIP_20210618_SurfaceSubnetQ96_10Cases_B_skm2.yaml &   muError=4.11   HD = 111
  429  2021-06-19 11:00:49 nohup python3 ./SurfaceSeg_Test.py ../testConfig_VIP/expVIP_20210618_SurfaceSubnetQ64_10Cases_B_skm2.yaml &   muError=3.90   HD = 75
  430  2021-06-19 11:01:00 nohup python3 ./SurfaceSeg_Test.py ../testConfig_VIP/expVIP_20210618_SurfaceSubnetQ128_10Cases_C_skm2.yaml &  muError=4.06   HD = 31
  431  2021-06-19 11:01:17 nohup python3 ./SurfaceSeg_Test.py ../testConfig_VIP/expVIP_20210618_SurfaceSubnetQ128_10Cases_D_skm2.yaml &  muError=3.82   HD = 96



#June 18th, Friday, 2021
Run  MedianFilterSmoothing versions:
  266  2021-06-18 18:34:19 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210618_SurfaceSubnetQ64_10Cases_A_skm2.yaml &  16G
  268  2021-06-18 18:36:35 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210618_SurfaceSubnetQ96_10Cases_A_skm2.yaml &  17G
  269  2021-06-18 18:36:41 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210618_SurfaceSubnetQ128_10Cases_A_skm2.yaml & 18G
  270  2021-06-18 18:36:47 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210618_SurfaceSubnetQ128_10Cases_B_skm2.yaml &
  271  2021-06-18 18:36:55 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210618_SurfaceSubnetQ96_10Cases_B_skm2.yaml &
  272  2021-06-18 18:37:03 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210618_SurfaceSubnetQ64_10Cases_B_skm2.yaml &

think:
The medianFilter should postprocessing, instead put before Loss.
If putting before loss, the error prediction will lost improvement opportunity as its backgradient disappear.

# medianFilter after loss with windowsize 21.
 289  2021-06-19 00:16:20 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210618_SurfaceSubnetQ128_10Cases_C_skm2.yaml &   18G
 290  2021-06-19 00:16:31 nohup python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210618_SurfaceSubnetQ128_10Cases_D_skm2.yaml &   18G




==============================
About the thickness heatmap output

Current we have 6 segmented surfaces (0, 1, 3, 5, 6, 10) with surface names ["ILM", "RNFL-GCL", "IPL-INL", "OPL-HFL", "BMEIS", "OB_RPE"].
What is your ideas for output their thickness heatmap after segmentation? For example,
A output 5 thickness heatmaps from 6 surfaces.
B output the whole retina thickness map between the top surface and the bottom surface.
C Anything else?

Would you please give me your thickness heatmap example in pdf for me to reference for further output?

# initial predicited result
1  good. PVIP2_4083_S013_Raw_GT_Prediction: It looks the prediction is better than ground truth at right upper corner of 2 surface.
2  In expVIP_20210617_SurfaceSubnetQ128_10Cases_B_skm2 result.
   It has spike in some slice, the spike of surface i will lead the spike of surface i+1.
   c=-1/(sqrt(2)*erfcinv(3/2))= 1.4826

====Initial Test result================================
expVIP_20210617_SurfaceSubnetQ32_10Cases_A_skm2:
stdSurfaceError = tensor([0.4200, 1.3549, 1.1116, 0.2938, 0.2124, 0.0159], device='cuda:0')
muSurfaceError = tensor([1.8166, 6.0350, 5.6631, 6.1231, 1.4365, 2.0916], device='cuda:0')
stdError = 2.2550723552703857
muError = 3.86098575592041
hausdorff Distance in pixels = [[41.446075 59.708252 32.708252 45.46498  70.798325 24.3555  ]]

=======================================================
expVIP_20210617_SurfaceSubnetQ64_10Cases_A_skm2:
stdSurfaceError = tensor([0.3303, 1.0405, 0.5636, 0.8235, 0.2273, 0.3663], device='cuda:1')
muSurfaceError = tensor([1.8474, 5.5262, 5.0734, 4.9559, 1.6518, 3.0219], device='cuda:1')
stdError = 1.7093156576156616
muError = 3.6794302463531494
hausdorff Distance in pixels = [[85.55847  78.22513  59.891815 61.44333  61.172333 54.518982]]
pixel number of violating surface-separation constraints: 0

========================================================
expVIP_20210617_SurfaceSubnetQ96_10Cases_A_skm2:
stdSurfaceError = tensor([0.3413, 0.5978, 0.3301, 0.3366, 0.2356, 0.1818], device='cuda:2')
muSurfaceError = tensor([1.7604, 5.7159, 5.1152, 5.0721, 1.5017, 2.5713], device='cuda:2')
stdError = 1.8178144693374634
muError = 3.6227853298187256
hausdorff Distance in pixels = [[70.60849  57.97238  40.63614  29.852936 17.944092 47.01535 ]]
pixel number of violating surface-separation constraints: 0

=======================================================
expVIP_20210617_SurfaceSubnetQ128_10Cases_A_skm2:
stdSurfaceError = tensor([0.2571, 0.6296, 0.7542, 0.9361, 0.1512, 0.1145], device='cuda:3')
muSurfaceError = tensor([1.8171, 5.8194, 5.3940, 5.1244, 1.6977, 2.8741], device='cuda:3')
stdError = 1.8366254568099976
muError = 3.787794589996338
hausdorff Distance in pixels = [[11.2256775 33.97307   32.227722  35.49765   21.374695  62.377167 ]]
pixel number of violating surface-separation constraints: 0

========================================================
expVIP_20210617_SurfaceSubnetQ32_10Cases_B_skm2:
stdSurfaceError = tensor([0.3440, 1.1740, 0.8124, 0.3985, 0.1454, 0.2812], device='cuda:0')
muSurfaceError = tensor([2.1274, 6.3112, 5.1875, 4.9228, 1.8084, 2.9954], device='cuda:0')
stdError = 1.8120994567871094
muError = 3.892133951187134
hausdorff Distance in pixels = [[95.019745 80.35309  56.68643  35.35309  42.99109  62.04956 ]]
pixel number of violating surface-separation constraints: 0

=======================================================
expVIP_20210617_SurfaceSubnetQ64_10Cases_B_skm2: (second best)
stdSurfaceError = tensor([0.3086, 0.3070, 1.0111, 0.4816, 0.3008, 0.2844], device='cuda:1')
muSurfaceError = tensor([1.8607, 5.8555, 5.2226, 4.9455, 1.5389, 2.3094], device='cuda:1')
stdError = 1.871992826461792
muError = 3.622117757797241
hausdorff Distance in pixels = [[76.24527  59.911957 42.24527  24.97818  32.24463  42.613953]]
pixel number of violating surface-separation constraints: 0

========================================================
expVIP_20210617_SurfaceSubnetQ96_10Cases_B_skm2:
stdSurfaceError = tensor([0.3795, 0.8918, 0.3502, 1.1913, 0.1290, 0.0049], device='cuda:4')
muSurfaceError = tensor([1.9020, 5.6497, 5.3540, 5.2461, 1.5536, 2.7111], device='cuda:4')
stdError = 1.8579832315444946
muError = 3.7360854148864746
hausdorff Distance in pixels = [[145.68288   55.66217   39.66217   33.73552   34.473175  59.21814 ]]
pixel number of violating surface-separation constraints: 0

=======================================================
expVIP_20210617_SurfaceSubnetQ128_10Cases_B_skm2: (best)
stdSurfaceError = tensor([0.3970, 0.0290, 1.1339, 0.5597, 0.2954, 0.0079], device='cuda:5')
muSurfaceError = tensor([1.7762, 5.9154, 4.9997, 4.9378, 1.4898, 2.5318], device='cuda:5')
stdError = 1.8563084602355957
muError = 3.608466386795044
hausdorff Distance in pixels = [[589.6748  576.6748  562.34155 536.6748  511.67484 487.34152]]
pixel number of violating surface-separation constraints: 0
========================================================


========================================================

=======================================================


========================================================

# June 17th, Thursday, 2021
Prepare the training script on thinRetina project:
1  config xml file.   --done.
2  training scrirpt.  --done
3  test script.       --done
4  check the writexml file details.  --done.
4  consider different config: segHead width: try 32, 64, 96, 128   --done.

reinstall pytorch 1.8.1 on June 17th, 2021
conda install pytorch==1.8.1 torchvision torchaudio cudatoolkit=11.1 -c pytorch -c nvidia

programs are training:
June 17th, 19:20 launch training:
 71786 pts/0    Rl    19:18 python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210617_SurfaceSubnetQ32_10Cases_A_skm2.yaml     15GB
 130004 pts/0    Sl     1:48 python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210617_SurfaceSubnetQ32_10Cases_B_skm2.yaml
 72367 pts/0    Rl    10:34 python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210617_SurfaceSubnetQ64_10Cases_A_skm2.yaml     16GB
  73093 pts/0    Rl     9:29 python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210617_SurfaceSubnetQ64_10Cases_B_skm2.yaml
 72505 pts/0    Rl    13:34 python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210617_SurfaceSubnetQ96_10Cases_A_skm2.yaml      17GB
 129806 pts/0    Rl     2:34 python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210617_SurfaceSubnetQ96_10Cases_B_skm2.yaml
 72671 pts/0    Rl    12:44 python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210617_SurfaceSubnetQ128_10Cases_A_skm2.yaml     18GB
129696 pts/0    Sl     2:40 python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210617_SurfaceSubnetQ128_10Cases_B_skm2.yaml

training speed at 2.5min/epoch.

June 18th, 10:20 launch training:  finished Test!
132445 pts/0    Sl     1:02 python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210618_SurfaceSubnetQ192_10Cases_A_skm2.yaml    20G
132720 pts/0    Sl     0:39 python3 ./SurfaceSeg_Train.py ../testConfig_VIP/expVIP_20210618_SurfaceSubnetQ256_10Cases_A_skm2.yaml    23G

Test need only 6GB GPU memory.

# Jun 16th, Wednesday, 2021
Meeting with Ray.
1  check the quality of rawGT;
2  what is your thinking about the prediction:
   A  which portion in the surface do you care more about?
   B  what is the manifestation of OCT for glaucoma patients?

Meeting time: 10am -10:40 am June 16th, Wednesday, 2021
Attendee:  Jui Kai, Hui
Topic: Preparation for the thin retina project.
Minutes:
1  Glaucoma patients normally have a thin RNFL. But thin RNFL does not mean a glaucoma.
   Common OCT RNFL thickness near fovea is like a donut shape, while a thin RNFL or a broken donut means some damages on the OCT layers.
2  VIP = Variability In Perimetry Study.
   In the Iowa Variability in Perimetry (VIP) Study, 120 glaucoma subjects and 60 normals were tested every six months for 4 years.

3  From Thursday, Hui wil work on the training script for this thin retina 10 patients.
   Ray can prepare some new independent test cases for verifying the result of our training network.
4  In this project, we need to consider to output all thickness map for all segmentation layer.





# June 12th, Satursday, 2021
Convert all data into
1 packed Numpy array in training and validation.
2 ouput all images with raw and GT.

conda list:
conda list --revisions   # list history version.
conda install --revision N  #  If you want to revert to a previous revision

matplotlib 3.3.4 has segment fault problem. You must use matplotlib 3.4.2

Notes for input data tidy:
0  convert Ray's special raw and xml format into standard BxHxW for images and BxSxW format for surfaces.
1  extracted 6 surfaces (0, 1, 3, 5, 6, 10)
   their surface names: ["ILM", "RNFL-GCL", "IPL-INL", "OPL-HFL", "BMEIS", "OB_RPE"]
2  convert all 1024x512 images and surfaces into 1024x200 size.
3  flip all OS eyes into OD eyes;
4  a slight smooth over the ground truth.
5  make sure all surfaces not interleave.




# June 11th, Friday, 2021
Notes:
1  Ray's raw data dimension:  200x200x1024, where #Bscans x  PenetrationDepth x #Ascans.
2  surface number: 6;
3  ray's trace with _ray

ProProcessing:
0  convert Ray's special raw and xml format to stardard BxHxW for image and BxSxW format for surface.
1  OCT may have different dimension size, we need to scale down the bigger ones into one same size.
2  flip all OS eyes into OD eyes;
3  a slight smooth the ground truth before using:
    A "very gentle" 3D smoothing process (or thin-plate-spline) should be applied to reduce the manual tracing artifact
    Check the smoothing results again in the images to make sure they still look reasonable
4  Make sure the top surface of GCIPL (i.e., surface_1) is NOT above ILM (surface_0)
5  Try to read the OCT image and match the surfaces in your own system

data augmentation:
1  do not flip withd direction, as the nasal and temporal direction is not symmetric in OD/OS eye.

Question:
1  what is rate for control and glaucoma coase in current 10 patients?
   Current 10 patients are all glocoma.
2  current 10 data has same data orientation.

Dicusss with Ray at 13:00-14:00, Friday, June 11th, 2021
1  current Ray's axial order is 200x1024x200, where 1024 is penetration depth.
   Ray's flip the data in its Width and Height direction.
2  Refer Ray's writer code to figure out Ray's image orientation.
3  CapeCoeMacularCubeRawData may contain ONH scan, the scan near cup place:
    It has almost same dimension with fovea OCT volume scan.
    It may has data in hexidecimal format. We can read it and estimate its dimension.


xml file:
/home/sheen/temp/PVIP2-4074_Macular_200x200_11-7-2013_8-14-8_OD_sn26558_cube_z/PVIP2-4074_Macular_200x200_11-7-2013_8-14-8_OD_sn26558_cube_z_Surfaces_Iowa_Ray.xml

In Ray's format: x = W, y = S, z = H.
Zeiss image resolution: BxHxW(200x1024x200): 30.150749um x 1.955034um x 30.150749um
Zeisss image resolution:BxHxW(128x1024x512): 47.244091um x 1.955034um x 11.741680um

Bscan image 1024x512 will reduce to 1024x200.
Its surface ground truth 11x512 will reduce to 11x200,:

directly define a scale matrix of size [W1=512,W2=200]:
1  before normalization, each column sum = W1/W2, each row sum = 1;
2  After normalization, each column sum = 1;


define a 500x200 matrix, col1= [1,1,0.5,0,0,...]^T, col2=[0,0,0,0,0.5,1,1,0,0,... ], and col1 and col2 down shift 10 rows,copy
[1
 1
 0.5 0.5
      1
      1
        1
        1
        0.5 0.5
              1
              1
             ......]*(1/2.5)

1  construct M matrix of size 512x200;
3  use np.matmul support batch matrix muliplication get new image and surface result.


Ray Note:
Check Surface 0, 1, 3, 5, 6, 10 in the surface xml file
See the surface/layer definition in the figure
My tracing: at the end of the xml filename with "_Ray"
Graph search: the regular filename

needing surface index [0, 1, 3, 5, 6, 10]
its surface names: ["ILM", "RNFL-GCL", "IPL-INL", "OPL-HFL", "BMEIS", "OB_RPE"]
all 11 surface names:
['ILM (ILM)', 'RNFL-GCL (RNFL-GCL)', 'GCL-IPL (GCL-IPL)', 'IPL-INL (IPL-INL)', 'INL-OPL (INL-OPL)',
'OPL-Henles fiber layer (OPL-HFL)', 'Boundary of myoid and ellipsoid of inner segments (BMEIS)', 'IS/OS junction (IS/OSJ)',
'Inner boundary of OPR (IB_OPR)', 'Inner boundary of RPE (IB_RPE)', 'Outer boundary of RPE (OB_RPE)']


After extraction, surface dimension: (128, 6, 512)
<scan_characteristics>
        <manufacturer>Carl Zeiss Meditec, Inc.</manufacturer>
        <size>
            <unit>voxel</unit>
            <x>200</x>
            <y>200</y>
            <z>1024</z>
        </size>
        <voxel_size>
            <unit>um</unit>
            <x>30.150749</x>
            <y>30.150749</y>
            <z>1.955034</z>
        </voxel_size>
        <laterality>NA</laterality>
        <center_type>NA</center_type>

<scan_characteristics>
        <manufacturer>Carl Zeiss Meditec, Inc.</manufacturer>
        <size>
            <unit>voxel</unit>
            <x>512</x>
            <y>128</y>
            <z>1024</z>
        </size>
        <voxel_size>
            <unit>um</unit>
            <x>11.741680</x>
            <y>47.244091</y>
            <z>1.955034</z>
        </voxel_size>
        <laterality>NA</laterality>
        <center_type>NA</center_type>
    </scan_characteristics>



#June 10th, Thursday, 2021
below images may have problems:
Current OCT volume axis order: Slice x Height x Width.


# June 9th, Wednesday, 2021
Progress of Converting CirrusHDOCT Dicom files:
1  all image format, pdf can be extracted out.
2  rawData and Measurements can not bee read as its pixel_array is not available, maybe their protocol is private with the manufacture.
   Therefore pydicom can not decode its data.

There are some remaining issues:
1  how to distinguish LSO, fundus image, png.
2  It looks Rui can dump some raw format.

Meeting time: 10am -11:30 am June 9th, Wednesday, 2021
Attendee:  Jui Kai, Hui
Topic: Cirrus HD-OCT raw data, and segmentation project.
Minutes:
For Cirrus HD-OCT data extraction:
   A  think possible technologies to explore the CapeCode Raw data.   --done
   B  use code tag, output the fundus and SLO 2D image (664x512) with meaning names;  --done
   C  output filenames need to record time for repeated cases.   --done.
For thin retina segmentation:
   A  merge 5 graph search result + 5 Ray corrected result. 8 for training, 2 for validation.
   B  Input image has different sizes, so we need to downsample the high resolution images and ground truth into a smaller size.

Now the Dicom reader program is ready:
1  It can output all OCT volume, SLO, Fundus, and analysis pdf report files with meaningful file names.
2  For CapeCod Raw data, as it is manufacturer-inside private tag data, we can not read it. Please refer to further explanation below.
3  Before using this program, you need to install GDCM, Pillow, CharLS, pdlibjpeg python packages needed by pydicom.
4  I tested it in 3 dicom files you shared. Maybe other cases need special tag, please let me know. I can modify it.

Python code:\\garvinlab.storage.iibi.uiowa.edu/garvinlab_prof_wu/code/readCirrusHDOCTDicom.py
              or attached.

CapeCodeRawData are all belong to Private tag data, which is for manufacturer-inside private using for device data management and self-diagnosis.
So all CapeCodRawData have no any protocols explanation in the "Zeiss DICOM Conformance Statement" guide book. It is intentional to make these raw data private, instead public.
Except we sign a NDA with Zeiss and Zeiss would like to cooperate with us in its further device research and development, I don't think we can get its CapeCodeRawData interface protocol.
Trying, even knowledgeable-guess, is not a solution to decode CapeCod protocol.

Other search about Cape Cod:
Cape Cod is a geographic cape extending into the Atlantic Ocean from the southeastern corner of mainland Massachusetts.
CAPE COD: Cirrus Study Repeatability and Reproducibility of RNFL Thickness and Macular thickness measurements of Cirrus Phot and Cirrus Model 4000 in subjects with Retinal Disease.
The National Glaucoma Symposium will not be held as a live event on Cape Cod in 2021.

# Jun 8th, 2021
share dir:

\\garvinlab.storage.iibi.uiowa.edu\garvinlab_prof_wu


# June 8th, Dicom convert:
Summary:

·         Basically, my program can access Zeiss' dicom files and read the tags in these files
·         However, there so many types of files in their system and the not all the tags can be found in all the files.
·         Currently, I rename the files to the format that human can read rather than their internal coding system
·         For some image files, I still can't directly access the pixel values. I will work with Hui and see how to deal with them.
·         Following are the files that I can convert [and access the data]:

o    .PDF
·         Cirrus_OU_ONH and RNFL OU Analysis.pdf
·         Guided Progression Analysis.pdf
·         Macular Thickness Analysis.pdf
·         OU Ganglion Cell OU Analysis.pdf
·         HD 5 Line Raster.pdf
·         HD 21 Line.pdf
·         HD Radial.pdf
·         Visual Field.pdf
·         GOLDMANN VISUAL FIELDM.pdf
·         COMBINED_REPORT_24-2_RNFL.pdf
·         GPAL3F.pdf
·         GPA_SUMMARY_SITA_STANDARD.pdf
·         SFA.pdf
·         All_Color_Fundus_Photo.pdf

o    .PNG
·         LSO.png [Line Scanning Ophthalmoscope]
·         ColorFundus.png

o    .RAW
·         Macular-Cube-200x200.raw
·         HD-5-Line-Raster.raw
·         5-Line-Raster.raw
·         RASTER_RADIAL.raw
·         RASTER_21_LINES.raw


·         Following are the format that I need to work with Hui and see if we can figure out [otherwise, we may need help from Zeiss] [maybe for some of them, we have .pdf and these are just their raw data format.]
o    HfaVisualFieldRawData
o    HfaPerimetryOphthalmicPhotography8BitImage
o    CapeCodGuidedProgressionAnalysisRawData
o    HfaOphthalmicVisualFieldStaticPerimetryMeasurements
o    CapeCodOpticDiscCubeRawData
o    CapeCodOpticDiscAnalysisRawData
o    CapeCodMacularCubeAnalysisRawData
o    CapeCodMacularCubeRawData


# June 2nd, Wednesday, 2021
Meeting time: 10am -10:40 am June 2nd, Wednesday, 2021
Attendee:  Jui Kai, Hui
Topic: About the thin retina segmentation
Minutes:
1  After getting the initial ground truth corrected by Ray from graph search result, we need to do:
   A rescaling image to uniform dimension;
   B flip all OS eyes into OD eyes;
   C a slight smooth the ground truth before using.
2  Note: in the deep learning augmentation, do not use flip as the nasal and temporal direction is not symmetric in OD/OS eye.

Ray's comments:
Notes for manual tracing:
Surface 0, 1, 3, 6, 10 in the surface xml file → I will add surface 5 soon
My tracing: at the end of the xml filename with "_Ray"
Graph search: the regular filename
Try to read the OCT image and match the surfaces in your own system

A "very gentle" 3D smoothing process (or thin-plate-spline) should be applied to reduce the manual tracing artifact
Check the smoothing results again in the images to make sure they still look reasonable
Make sure the top surface of GCIPL (i.e., surface_1) is NOT above ILM (surface_0)

I also added some scans with acceptable graph search results
Flip the OS to the OD orientation
It's acceptable (doesn't have to) that the ILM and GCIPL surfaces touch each other at the fovea
It's also acceptable that ILM and top GCIPL surface very close to each other



# May 26th, Wednesday, 2021
Meeting time: 10am -10:40 am May 26th, Wednesday, 2021
Attendee:  Jui Kai, Hui
Topic: About Dicom converter and ground truth.
Minutes:
1  For the Cirrus HD-OCT 6000 instrument, we need to decode all Dicom information to mhd/raw format or pdf, not just the OCT volume.
   There are some risks that the manufacture may encrypt the dicom data in order to sell its value-added software.
   We will try to decode the format. Hui will do this in the first week of June.
2  Ray will generate the ground truth of 5 patients for the VIP OCT data in the first week of June.
   HUi will use the 5 ground truth to generate 25 initial ground truth by deep learning network, and then Ray will manually modify it.
3  The current OCT viewer needs to add support multi-Bscan browse function.  Hui will help Ray to modify it.




# May 22nd, Saturday, 2021
1  Use Slicer on X11 forwarding. use ssh -X instead of ssh -Y option.  --done.
2  convert Dicom to Nrrd.
3  write a script of Nrrd read program.
4  connect vpn.healthcare.uiowa.edu.

/home/hxie1/data/Ophthalmology/3Dicom/Test/Orig_Output_from_Zeiss/01082671/2017-02-13   : Macular cube 200x200_2   




# May 21th, Friday, 2021
Dicom file analysis:
1  there are 3 patient Dicom.
2  Each patient has 4-5 visit records in different dates.
3  Each date has 4 volumes OCT volumes, but these 4 OCT volumes has same content. (We may need to save one volue, need to confirm?)
4  OCT volume size: 200x1024x200 in #AScans x PenetrationDepth x #Bscans format.
5  Convert each date record as a Raw file or Nrrd file?
6  Save a volume or a series separate Bscan?







# May 19th, Wednesday, 2021
Meeting time: 10am -10:40 am May 19th, Wednesday, 2021
Attendee:  Jui Kai, Hui
Topic: About BMO prediction and VAE project
Minutes:
1  The project using VAE to detect BMO:
    A  It has 3 surfaces each B-scan, 3 segmented B-scan per patient, total has 100+ patients.
    B  Segmentation of Less-one pixel accuracy is not very important as ground truth self may has errors bigger than one pixel.
       A reasonable result even with 3-5 pixels error is more important.
       Ray: Yes, a reliable segmentation globally is the focus here; so far, these layers are more important:
       RNFL, GCIPL, RPE complex, maybe also include the lower bounding surface of the OPL [i.e., Surface: 0, 1, 3, 5, 6, 10]

    C  For the manual segmentation tool, we need further improve its UI function for easier using.
    D  After the improving manual segmentation tools, a NewYork doctor may help us to get more ground truth.
2  For the thin retina project:
    A  Jui will offer segmentation ground truth for 5 patients.
    B  Basing on this 5 patient ground truth, we will use an initial segmentation network to generate more ground truth for further manual correction.
    C  Getting the thickness percent of diseased patients vs normal patients is more important publication.
3  Jui will give some Dicom images with irregular axis orientation to Hui, and then Hui help convert them into raw format for further use.


# May 12th, Wednesday, 2021
Meeting time: 10am -11am May 12th, Wednesday, 2021
Attendee:  Jui Kai, Hui
Topic: About BMO prediction and VAE project
Minutes:
1  BMO prediction project:
   We can first use 2D Bscans as input to predict the middle-broken low boundaries of RPE complex.
   The 2 opening points of BMO are usually corresponding around the swelling peak on ILM, which can give some information to help prediction.
   Each patient may have 3 Bscans for our data.
2  Use VAE to detect segmentation map.
   The output of VAE is not the recovery image as the traditional VAE, but the low dimension surface segmentation.
   The final goal of this project is to manipulate the latent vector to get different surface shape, which expresses the disease manifestations.

1 In the thin RNFL case, there is still some boundary information of low boundary of the thin RNFL.
2 Some time, the Ophthalmologist needs to use other Bscan information to infer the surface boundary of the current Bscan.
3 The dataset for glaucoma:
  diseased cases: about 25, control case: about 25,   with size of 200x200x1024, where X: #Ascans, Y:#Bscans, Z, Penetration depth.
  number of surfaces: about 5.
  OCT may have different dimension size, we need to unify them into one same size.
4 further thinking: Use volume OCT image with VAE to detect Bruch membrane opening (BMO).


#May 11th, research VAE
1  Generative Adversarial Networks (GANs) and Variational Autoencoders (VAEs) arr both generative models.
   a VAE is an autoencoder whose encodings distribution is regularised during the training in order to
   ensure that its latent space has good properties allowing us to generate some new data.

autoencoders cannot be used to generate new data and will introduce Variational Autoencoders that are
 regularised versions of autoencoders making the generative process possible.

Encoder extracts/compresses feature into encoded space or latent space,
 which is a kind of loosy dimensionality reduction.

 the autoencoder is solely trained to encode and decode
  with as few loss as possible, no matter how the latent space is organised.

  satisfying this way the expected continuity and completeness conditions.
  Naturally, as for any regularisation term, this comes at the price of a higher reconstruction error
   on the training data




#May 5th, Wednesday, 2021:
Meeting time: 10am -11am May 5th, Wednesday, 2021
Attendee:  Jui Kai, Hui
Topic: about the OCT segmentation tool.
Minutes:
1 In the thin RNFL case, there is still some boundary information of low boundary of the thin RNFL.
2 Some time, the Ophthalmologist needs to use other Bscan information to infer the surface boundary of the current Bscan.
3 The dataset for glaucoma:
  diseased cases: about 25, control case: about 25,   with size of 200x200x1024, where X: #Ascans, Y:#Bscans, Z, Penetration depth.
  number of surfaces: about 5.
  OCT may have different dimension size, we need to unify them into one same size.
4 further thinking: Use volume OCT image with VAE to detect Bruch membrane opening (BMO).


# April 29th,Thursday, 2021:
Questions needing discussions:
1  I want to know the knowledge and logic from the OCT image which leads you to determine this is a thin RNFL, and the surface RNFL/GCL is very close to or overlaps with the surface ILM.
   If we can express this knowledge and logic as a model or constraint into our network, it may get better accuracy and a more valuable paper.

2   And what are other characteristics of this special disease OCT images?

3   A possible way is to involve a prior knowledge about the normal subject range:
    If this is a case, do we need to add normal/control OCT images with ground truth to help network
    distinguish normal and disease OCT Images.


# April 28th, Wednesday, 2021


Meeting: Wu, Ray, Hui
Details of the segmentation method, including setting up ground truth, network structure, ect..
IRB
Working load/hours/updates
Potential conferences that we can aim for


# Ray email on April 23rd, 2021:
Current issue:
• Currently, the layer segmentation is done by the graph-search algorithm. For most of the healthy
subjects, the macular scans can be segmented correctly. However, for some glaucoma subjects,
due to damage of the optic nerve, the retinal nerve fiber layer (RNFL) and ganglion cell + inner
plexiform layer (GCIPL) start to get thinning [please see the figures above]. Due to the graph-
search inter-surface constrains, the algorithm has a good chance to miss the "invisible" RNFL and
sees the thinning GCIPL as a part of the unreal thick RNFL. Consequently, the GCIPL segmentation
outcome gets to push down to another layer.

Goal:
• We first would like to develop a relatively straightforward deep-learning-based tool to overcome
this segmentation problem for these thin retinas. We hope that the deep learning neural network
can label interested layers correctly and robustly. To make this problem more manageable, we
currently only needs to segment a few layers/surfaces that contains the key information that we
want to measure [e.g., the GCIPL, the internal limiting membrane (ILM), the lower surface of the
outer plexiform layer and the RPE complex. Furthermore, we would like the developing deep
neural network could have the ability to output a projected-view pixel-based layer segmentation
confidence map. So, for a large amount of scan processing, we could only focus on a small portion
of images that need attention for quality control.