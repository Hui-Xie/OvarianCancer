#Feb 23rd, Tuesday, 2021:
Discuss with professor:
1  output a comprenhensive slide about HBP prediction, about radiomics design, implementation, and result.
2  research loss function.
3  HBP prediction go forward:
   A transfer learning.
   B combine thinkness, clinical data, radiomics to predict HBP.

======================
Design transfer learning:
1  volume data: /home/hxie1/data/BES_3K/W512NumpyVolumes/volumes   --ready.
2  generate the segmented 3D retina using xml, and normalization;  --done.
   original volume pixel value in [0, 255],
   All pre-trained models expect input images normalized in the same way,
   i.e. mini-batches of 3-channel RGB images of shape (3 x H x W), where H and W are expected to be at least 224.
   The images have to be loaded in to a range of [0, 1]
   and then normalized using mean = [0.485, 0.456, 0.406] and std = [0.229, 0.224, 0.225], which are the mean and stddev of ImageNet.
   We should compute the mean and std of each channels of 31 channels of OCT images.
   cat outputLog_20210224_174528.txt
total 6499 xml files.
output segmented and normalized retina regions from surface 0 to surface9.
Now all masks have been generated in /home/hxie1/data/BES_3K/W512NumpyVolumes/log/SurfacesNet/expBES3K_20201126A_genXml/testResult/volume3D_s0tos9_indexSpace/masks
meanBscans = [0.05199834 0.05284249 0.0532695  0.0537375  0.05438357 0.0549899
 0.0558392  0.05696388 0.05825874 0.0598245  0.06093201 0.06143699
 0.06085205 0.05910843 0.05703062 0.05591611 0.05711094 0.05924026
 0.06057586 0.06111015 0.06090984 0.0599876  0.05905826 0.05801464
 0.05705912 0.056168   0.05544387 0.05496442 0.05464729 0.05429021
 0.0540758 ]
stdBscans = [0.14800051 0.14917299 0.14980883 0.1504818  0.15139771 0.15180002
 0.15233731 0.15314984 0.15386566 0.15500712 0.15508947 0.15453244
 0.15276628 0.15002041 0.14744838 0.14581831 0.14734901 0.14996752
 0.15186637 0.15354847 0.15457117 0.15440928 0.15420679 0.15358165
 0.15280802 0.15198185 0.15122363 0.1508052  0.15057934 0.15009072
 0.14986088]

2  check pretrained network in Pytorch; --done
3  research how to change and input layer width and copy pretrained parameters;   --done
4  use the radiomics 10-fold CV data.       -- ready.
5  code network:
   A  yaml config file.
   B  dataLoad.
   C  dataTransfer.
   D  training main program.
   E  5-crop test program.




# Feb 22nd, Monday, 2021:
Research transfer learning:
Transfer learning is a machine learning method where a model developed for a task is reused as the starting point for a model on a second task.
Transfer learning only works in deep learning if the model features learned from the first task are general.
features are more generic in early layers and more original-dataset-specific in later layers.
Transfer learning is an optimization, a shortcut to saving time or getting better performance.
Transfer learning can be used to accelerate the training of neural networks as either a weight initialization scheme or feature extraction method.
Weight Initialization: This may be useful when the first related problem has a lot more labeled data than the problem of interest
                       and the similarity in the structure of the problem may be useful in both contexts.  It can use big learning rate.
Feature extraction:    only new layers after the reused layers may be trained to interpret their output.  It needs small learning rate.

Because these days, it is standard practice to use Transfer Learning to make use of pre-trained models instead of training a brand new model from scratch.

Note:
1 pretrained ImageNet NN generally uses normalized input;
2 an excellent post: https://www.azavea.com/blog/2019/08/30/transfer-learning-from-rgb-to-multi-band-imagery/
3 replicate RGB to 31 channels, then we have 2 methods to go further
  A . 31 channels values after the first RGB layer add together, which may scale up the value;
  B . use 1x1 conv to project 31 channels  to 3 channel, then feed into RGB channel layer.
4 ImageNet input image normalization in which dimension?
   Answer: normalization on the RGB channel dimension.
   If the gradient is big, you should reduce the learning rate.
   However you usually have different gradient magnitudes in a same batch.
   Normalizing the image to smaller pixel values is a cheap price to pay while making easier to tune an optimal learning rate for input images.


# Feb 20th, Saturday, 2021:
Use transfer learning to train 3D segmented retina for HBP(Hypertension)
Background:
1  Yesterday when I was summarizing previous experiments on HBP for a comprehensive report, I found that our MobileNetV3 experiment got 63% validation accuracy.
   It is not too bad comparing with logistic regression, radiomics on thickness input; (Please refer the attached 3 excel sheets.)
2  Our a lot of experiment shows that thickness is not powerful enough to predict HBP with a statistical significant accuracy.
   There may be an association between thickness of some layers and HBP, but this association is not powerful enough to predict HBP with a a statistical significant accuracy.
   There is a possible way to reposition our current research into a association analysis between OCT thickness and HBP, instead of HBP prediction. (This needs two professors' decision.)
3  Reducing the size of input space though features selection is a way to  reduce over-fitting;
   When it is not enough, transfer learning is also a way to reduce over-fitting, as transfer learning uses a trained network on a huge dataset.
   In some sense, transfer learning uses a huge data data as an initial network training.
4  In concept, engineered features using radiomics is equivalent with automatic feature selection using several neural layers.
   So the radiomics website (https://www.radiomics.io/) parallels both engineered features and deep learning as its radiomics methodologies.

A new idea: Use transfer learning to train 3D segmented retina for HBP(Hypertension)
1  Next week, when we wait for 3D retina radiomics generating. I am planning to try a new idea.
2  Method of the new idea:
   A. Input: 31x496x512 in pixel space, where 31 is the number of B-scans.
   B. Use segmented mask to exclude non-retina region, e.g. vitreous body and choroid etc, getting 31x496x512 filtered volume.
   C. Random crop the filtered 3D volume into 31x448x448 as data augmentation.
   D. halve size in X and Y direction to scale down to 31x224x224.
   E. 31 as channels, 31x224x224 input to a trained network: ResNext or MobielNet-v3 with replicated channel parameters from RGB to 31 channels.
   F. Fine-tune whole network parameters.
   G. Test time uses 5-crop probabilities average to get the final test accuracy.
   H. Its possible further improvement:
      may consider to add clinical information before the final FC layer.
3  Advantages of this method:
   A  implicitly augment training data through a pretrained network.
   B  reduce over-fitting.
   C  use segmented 3D retina features, reducing the vitreous body etc noise information.
   D  automatic features selection.
4  Disvantages of this method:
   Replicating pretrained RGB 3-channel parameters to 31 channels may change the pretrained and optimized network status.
   The feature values in the feature map of layer 0 after 31 channels may change into 10 times of the feature values of original RGB pretrained network.
   Maybe a normalization in input 31 channel may help. It needs further research on this detail.
5  Will the result be better?
   I don't know. It needs experiments to verify it. I just estimate it may be better.

If you have any comments or further suggestions, please feel free to let me know.


#Feb 19th, Friday, 2021:
Prepare slide for a comprehensive report:
1  project introduction





#Feb 19th, Friday, 2021:
Prepare slide for a comprehensive report:
1  project introduction

#Feb 19th, Friday, 2021:
Prepare slide for a comprehensive report:
1  project introduction
2  data in hand
3  experiments for prediction:
   Date, input, #samples, data[0,1] rate, method, result, notes
   A  whole OCT image + deep learning
   B  middle OCT slice + deep learning
   C  SVM
   D  Random Forests
   F  Logistic Regrssion
   G  Radiomics + Logistic Regression

4  Data Analysis:
   intensity
   thickness
   texture(radiomics)
5  further suggestion:
    1  thickness and HBP has some association;
    2  but thickness is not powerfull enough to predict HBP with a statistical significant accuracy;
    3  reposition this project into association analysis between thickness and HBP.





# Feb 09th, Tuesday, 2021:
1  look into Leixin's paper, check its 3D formula;
2  traditional method needs to do cross validation for comparing with deep learning;
3  MICCAI paper talk only focus on MICCAI paper;

Further OD/OS input network result:
1  after reduce 1 layer, network still get over-fitting. Its test result didn't improve.
   One reason is that OD/OS dual eye input increases input width from 29(OD eye with feature selection) to 172(both eye without feature selection).
2  Continue to reduce network to single layer.
3  started radiomics.

exp: expOCT_172Ftr_ODOS_HyT_20210209D_2Head_10CV_0
1  Network: ((162->20)+(10->10))->1:  only one neural after just 2 heads. It is almost a single layer network.
2  get 63.35% average accuracy of 10-fold crossing validation.
   It is similar with exp:expOCT_41Ftr_HyT_20210130_10CV_?.yaml, which got 63.76% average accuracy of 10-fold crossing validation.


exp: expOCT_172Ftr_ODOS_HyT_20210209D_2Head_10CV_0
	Network: 1
	Threshold =0.5
CVFold	Accuracy  TPR	TNR
CV0	    0.6842	0.7009	0.6626
CV1	    0.6157	0.5981	0.6385
CV2	    0.6789	0.6822	0.6746
CV3	    0.6578	0.5607	0.7813
CV4	    0.5978	0.6415	0.5421
CV5	    0.656	0.5849	0.7469
CV6	    0.6402	0.6603	0.6144
CV7	    0.5767	0.5188	0.6506
CV8	    0.6137	0.5188	0.7349
CV9	    0.6137	0.6698	0.5421
Average	0.6335	0.6136	0.6588








# Feb 08th, Monday, 2021:
The OD/OS dual input network result:
Summary:
1 input: OD/OS thickness 81*2 + clinical features 10.
2 For single-head input(where clinical data without normalization), got 10-fold CV average acc of 60%.
  current network is (172,40,20,1) fully-connected width. It has some over-fitting.
  Need further to reduce network width.
3 For dual-head input, where clinical data normalization separate from thickness data, gots 10-fold CV average acc of 60%.
  current network is ((162->20)+(10->10))->20->20->1) fully-connected width. it has over-fitting.
  Need further to reduce network width.
4 The layer thickness information is not powerful to predict hypertension.

Further work:
1 reduce above 2 networks' layer and width to reduce over-fitting.
2 start radiomics research;

please refer 10-fold CV resutl:
 /home/sheen/projects/DeepLearningSeg/OCT2SysDisease/network_172Ftr_ODOS_10CV/testConfig/172Ftrs2HBP_10CV_TestResult_20210208.ods





# Feb 05th, Friday, 2021:
About using OD/OS features. It is updated thinking from Feb 2nd.
=============================================
Use non-sysmmetric thickness of OD/OS:
1  Input: 81x2 thicknesses + 10 clinical features
3  training sample number: about 1500 patients.
4  network structure:
   81thicknessOD--|
   81thicknessOS--| ========(FC)=======>10--|
        10 clinical ======(1x1Conv)====>9 --|==(FC)=>1

   parameters: (162+1)*10+ 9*2+ (19+1)*1 = 1668.
   parameters/obsereration: 1668/1500 = 1.11
   training sample/input space:  1500/(162+9) = 8.77
5  if no overfitting, add the 10 (after 1st FC) to bigger;

Work for OD/OS both eyes input:
1  mkdir of dataDir;   --done.
/home/hxie1/data/BES_3K/W512NumpyVolumes/log/SurfacesNet/expBES3K_20201126A_genXml/testResult/thickness9Sector_9x9_ODOS_162Ftrs_10CV
2  rebuild GTs dir for data set ID:  --done
/home/hxie1/data/BES_3K/GTs/162Ftrs_ODOS_10CV
3  dataLoader support 2 input data;  --done
4  main train/test need moify input interface;  --cancel
5  new network;  --done
6  modify train and test with  a fixed threshold of 0.5   --done.


=============================================
# Feb 05th, Friday, 2021:
Summary:
1   Please refer to 2 screenshots below:
    ODS files:
    /home/sheen/projects/DeepLearningSeg/OCT2SysDisease/network_41Ftr_10CV/testConfig/41Ftrs2HBP_10CV_TestResult.ods
    /home/sheen/projects/DeepLearningSeg/OCT2SysDisease/network_29Ftr_OD_10CV/testConfig/29Ftrs2HBP_10CV_TestResult_20210204.ods

2   OD network gets an accuracy of 62%, while OD/OS network gets an accuracy of 63%.
     A possible reason is that OD/OS network has 2 times training sample number than the OD network.
3   Single-head OD network gets an accuracy of 62%, while dual-head OD network gets an accuracy of 55%.
     It verified our initial judgement that normalization between clinical feature and thickness hurts the clinical features' dominant capability.
4   Our logistic regression on pure clinical features on the whole dataset can get an accuracy of 66%, which can be regarded as a training accuracy on logistic regression.
     I estimate its test accuracy is less than 60%.
5   Our logistic regression on pure thickness features on the whole dataset can get an accuracy of 60%, which can be regarded as a training accuracy on logistic regression.
     I estimate its test accuracy is about 50%.

Further plan:
1   Use both OD/OS thickness input and clinical feature to predict hypertension, hoping their OD/OS thickness difference may help.
2   Radiomics.



# Feb 03rd, Wednesday, 2021:
29 features(19 thicknesses + 10 clinical features) pure OD networks for 10-fold CV are running:
1 Clinical features using backward sequential variable selection by AIC in logistic regression chose 10 features;
2 OD thickness features using backward sequential variable selection by AIC in logistic regression chose 19 features;
3 Using 19+10 features with OD eyes regenerated 10-fold crossing validation IDs for pure OD eyes:
  There exist some patients(['2750', '358']) having only OS eye images.
4 Assemble 10+19 features to feed a deep learning network.
5 Now networks are training. On Thursday we will get its result;

# use OD single eye to predict:
1 use AIC to do thickness variable selection on OD eye only;   --done, 19 features
2 use AIC to clinical variable selection against hypertension only;  --done, 10 features
3 redo 10 fold ID for OD image with 29 features: ---done, at ~/data/BES_3K/GTs/29Ftrs_OD_10CV/
4 assembly thickness on OD and clinical feature to deep learning network;  --done
5 network structure:
  19thicknessOD--| ========(FC)=======>10 --|
      10 clinical  ======(1x1Conv)====>10 --|==(FC...)=>1   --done
6 clinical feature should do 1x1 conv before assembling with thickness features.  --done.

Experiments:
1  expOCT_29Ftr_OD_HyT_20210203_10CV_0: 20-20-1 network
===============================================
CVFold	Accuracy TPR	TNR
CV0	    0.5468	0.7777	0.2499
CV1	    0.4973	0.6203	0.3373
CV2	    0.5706	0.7777	0.3012
CV3	    0.5549	0.287	0.9036
CV4	    0.5863	0.6111	0.5542
CV5	    0.5497	0.574	0.518
CV6	    0.5235	0.6944	0.3012
CV7	    0.4607	0.2129	0.7831
CV8	    0.5602	0.6944	0.3855
CV9	    0.6	    0.7476	0.4096
Average	0.5450	0.5997	0.4744
===============================================
1 all result used the threshold of maximizing sum in validation data.
2 all result are on the test folds
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
2  expOCT_29Ftr_OD_HyT_20210203B_10CV_0: 40-20-1 network
===============================================
CVFold	Accuracy  TPR	TNR
CV0	    0.625	0.7685	0.4404
CV1	    0.5235	0.3796	0.7108
CV2	    0.5706	0.7407	0.3493
CV3	    0.534	0.5925	0.4578
CV4	    0.5706	0.5092	0.6506
CV5	    0.5811	0.6944	0.4337
CV6	    0.534	0.4907	0.5903
CV7	    0.5497	0.4999	0.6144
CV8	    0.5287	0.4166	0.6746
CV9	    0.5473	0.6915	0.3614
Average	0.5565	0.5784	0.5283
===============================================
1 all result used the threshold of maximizing sum in validation data.
2 all result are on the test folds
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Analysis:
1  pure OD network get a lower accuracy(55%) than the OD/OS network (63%):
2  possible reasons and improvements:
   A  the two-input-head design may hurt the clinical features' dominant capability over thickness features,
      as by logistic regression experiment that clinical features show better prediction capability of hypertension than thickness features.
3  A improved single-head network is training, I will check its result on Friday morning.






================================================
Feature selection on clinical features:
cat output_20210203_104219.txt
Experiment: expOCT_SeqBackwardFS_Clinical_20210203
nonExistIDList of OD in training:
 ['2750']
nonExistIDList of OD in validation:
 ['358']

== Sequential backward feature selection w.r.t. HBP ==============
After deleting empty-value patients, it remains 1908 patients.
Initial input features before feature selection:
['gender', 'Age', 'IOP', 'AxialLength', 'Smoke', 'Pulse', 'Drink', 'Glucose', 'CRPL', 'Cholesterol', 'Triglyceride', 'BMI', 'WaistHipRate', 'LDLoverHDL']

============program is in sequential backward feature selection, please wait......==============
number of features: 14;	aic=2364.3730367373782;	ACC(cutoff0.5)=0.6588050314465409
number of features: 13;	aic=2362.3741319641535;	ACC(cutoff0.5)=0.6588050314465409
number of features: 12;	aic=2360.4883506760025;	ACC(cutoff0.5)=0.6588050314465409
number of features: 11;	aic=2359.34477568439;	ACC(cutoff0.5)=0.660377358490566
number of features: 10;	aic=2358.4009903061515;	ACC(cutoff0.5)=0.6561844863731656
========================End of sequential backward feature selection======================
Selected features with min AIC:
minAIC = 2358.4009903061515
selected features: ['Age', 'IOP', 'AxialLength', 'Pulse', 'Drink', 'Glucose', 'Cholesterol', 'Triglyceride', 'BMI', 'LDLoverHDL']
selected feature indexes: [1, 2, 3, 5, 6, 7, 9, 10, 11, 13]
clinicalFeatureColIndex: [3, 4, 5, 11, 12, 13, 15, 18, 19, 21]  in fullLabelTable index.

                           Logit Regression Results
==============================================================================
Dep. Variable:                      y   No. Observations:                 1908
Model:                          Logit   Df Residuals:                     1898
Method:                           MLE   Df Model:                            9
Date:                Wed, 03 Feb 2021   Pseudo R-squ.:                  0.1048
Time:                        10:42:25   Log-Likelihood:                -1169.2
converged:                       True   LL-Null:                       -1306.1
Covariance Type:            nonrobust   LLR p-value:                 9.302e-54
==============================================================================
                 coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------
x1             0.0632      0.006     10.656      0.000       0.052       0.075
x2             0.0737      0.019      3.884      0.000       0.037       0.111
x3            -0.3070      0.030    -10.352      0.000      -0.365      -0.249
x4            -0.0197      0.005     -3.935      0.000      -0.029      -0.010
x5             0.0684      0.039      1.762      0.078      -0.008       0.144
x6             0.0966      0.039      2.497      0.013       0.021       0.172
x7            -0.1138      0.061     -1.855      0.064      -0.234       0.006
x8             0.1309      0.051      2.587      0.010       0.032       0.230
x9             0.1488      0.014     10.265      0.000       0.120       0.177
x10           -0.1145      0.072     -1.587      0.113      -0.256       0.027
==============================================================================
Accuracy of using ['Age', 'IOP', 'AxialLength', 'Pulse', 'Drink', 'Glucose', 'Cholesterol', 'Triglyceride', 'BMI', 'LDLoverHDL']
 to predict hypertension with cutoff 0.5: 0.6561844863731656
With a different cut off with max(ACC+TPR+TNR):
{'threshold': 0.511, 'ACC': 0.6619496855345912, 'TPR': 0.7432808155630837, 'TNR': 0.5560916767122305, 'Sum': 1.9613221778099055}
Where:
x1 = Age
x2 = IOP
x3 = AxialLength
x4 = Pulse
x5 = Drink
x6 = Glucose
x7 = Cholesterol
x8 = Triglyceride
x9 = BMI
x10 = LDLoverHDL
=============================================================
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
==================================================================
Feature selection on OD thickness:

Experiment: expOCT_SeqBackwardFS_ODThickness_20210203

== Sequential backward feature selection w.r.t. HBP ==============
After deleting empty-value patients, it remains 1910 patients.
Initial input features before feature selection:
['L0_S0', 'L0_S1', 'L0_S2', 'L0_S3', 'L0_S4', 'L0_S5', 'L0_S6', 'L0_S7', 'L0_S8', 'L1_S0', 'L1_S1', 'L1_S2', 'L1_S3', 'L1_S4', 'L1_S5', 'L1_S6', 'L1_S7', 'L1_S8', 'L2_S0', 'L2_S1', 'L2_S2', 'L2_S3', 'L2_S4', 'L2_S5', 'L2_S6', 'L2_S7', 'L2_S8', 'L3_S0', 'L3_S1', 'L3_S2', 'L3_S3', 'L3_S4', 'L3_S5', 'L3_S6', 'L3_S7', 'L3_S8', 'L4_S0', 'L4_S1', 'L4_S2', 'L4_S3', 'L4_S4', 'L4_S5', 'L4_S6', 'L4_S7', 'L4_S8', 'L5_S0', 'L5_S1', 'L5_S2', 'L5_S3', 'L5_S4', 'L5_S5', 'L5_S6', 'L5_S7', 'L5_S8', 'L6_S0', 'L6_S1', 'L6_S2', 'L6_S3', 'L6_S4', 'L6_S5', 'L6_S6', 'L6_S7', 'L6_S8', 'L7_S0', 'L7_S1', 'L7_S2', 'L7_S3', 'L7_S4', 'L7_S5', 'L7_S6', 'L7_S7', 'L7_S8', 'L8_S0', 'L8_S1', 'L8_S2', 'L8_S3', 'L8_S4', 'L8_S5', 'L8_S6', 'L8_S7', 'L8_S8']

============program is in sequential backward feature selection, please wait......==============
number of features: 81;	aic=2649.4422062884523;	ACC(cutoff0.5)=0.6052356020942409
number of features: 80;	aic=2647.4422079808182;	ACC(cutoff0.5)=0.6052356020942409
number of features: 79;	aic=2645.4422324641087;	ACC(cutoff0.5)=0.6052356020942409
number of features: 78;	aic=2643.444274207918;	ACC(cutoff0.5)=0.6047120418848168
number of features: 77;	aic=2641.447971379788;	ACC(cutoff0.5)=0.6052356020942409
number of features: 76;	aic=2639.4543661283196;	ACC(cutoff0.5)=0.6057591623036649
number of features: 75;	aic=2637.4655560388273;	ACC(cutoff0.5)=0.6068062827225131
number of features: 74;	aic=2635.4812882284186;	ACC(cutoff0.5)=0.6068062827225131
number of features: 73;	aic=2633.4996670629257;	ACC(cutoff0.5)=0.6073298429319371
number of features: 72;	aic=2631.523947564773;	ACC(cutoff0.5)=0.6068062827225131
number of features: 71;	aic=2629.5511962080936;	ACC(cutoff0.5)=0.6089005235602094
number of features: 70;	aic=2627.576862287271;	ACC(cutoff0.5)=0.6089005235602094
number of features: 69;	aic=2625.608911683589;	ACC(cutoff0.5)=0.6109947643979058
number of features: 68;	aic=2623.6443752311798;	ACC(cutoff0.5)=0.6099476439790575
number of features: 67;	aic=2621.6917053817856;	ACC(cutoff0.5)=0.6089005235602094
number of features: 66;	aic=2619.767891187339;	ACC(cutoff0.5)=0.6104712041884817
number of features: 65;	aic=2617.894499633804;	ACC(cutoff0.5)=0.6094240837696335
number of features: 64;	aic=2615.976792041648;	ACC(cutoff0.5)=0.6052356020942409
number of features: 63;	aic=2614.1266226437892;	ACC(cutoff0.5)=0.6089005235602094
number of features: 62;	aic=2612.2848062652465;	ACC(cutoff0.5)=0.6094240837696335
number of features: 61;	aic=2610.451738225158;	ACC(cutoff0.5)=0.6094240837696335
number of features: 60;	aic=2608.625156207668;	ACC(cutoff0.5)=0.6083769633507854
number of features: 59;	aic=2606.805423083163;	ACC(cutoff0.5)=0.6094240837696335
number of features: 58;	aic=2604.971077947933;	ACC(cutoff0.5)=0.606282722513089
number of features: 57;	aic=2603.2413397962982;	ACC(cutoff0.5)=0.6047120418848168
number of features: 56;	aic=2601.4838943308873;	ACC(cutoff0.5)=0.6047120418848168
number of features: 55;	aic=2599.7922818071347;	ACC(cutoff0.5)=0.6052356020942409
number of features: 54;	aic=2597.974668898574;	ACC(cutoff0.5)=0.6031413612565445
number of features: 53;	aic=2596.39236771995;	ACC(cutoff0.5)=0.612565445026178
number of features: 52;	aic=2594.8101973041016;	ACC(cutoff0.5)=0.6104712041884817
number of features: 51;	aic=2593.293767461292;	ACC(cutoff0.5)=0.6157068062827226
number of features: 50;	aic=2591.748852231868;	ACC(cutoff0.5)=0.6115183246073298
number of features: 49;	aic=2590.037707066468;	ACC(cutoff0.5)=0.6104712041884817
number of features: 48;	aic=2588.4691832313083;	ACC(cutoff0.5)=0.6078534031413613
number of features: 47;	aic=2586.695576234728;	ACC(cutoff0.5)=0.6078534031413613
number of features: 46;	aic=2584.916640318633;	ACC(cutoff0.5)=0.6083769633507854
number of features: 45;	aic=2583.3939819662996;	ACC(cutoff0.5)=0.6078534031413613
number of features: 44;	aic=2582.0732063379087;	ACC(cutoff0.5)=0.6031413612565445
number of features: 43;	aic=2580.593543540755;	ACC(cutoff0.5)=0.6020942408376964
number of features: 42;	aic=2579.3304148431753;	ACC(cutoff0.5)=0.6041884816753926
number of features: 41;	aic=2577.806842527586;	ACC(cutoff0.5)=0.6052356020942409
number of features: 40;	aic=2576.6502115396097;	ACC(cutoff0.5)=0.6078534031413613
number of features: 39;	aic=2575.0525232676146;	ACC(cutoff0.5)=0.6104712041884817
number of features: 38;	aic=2573.9101675721176;	ACC(cutoff0.5)=0.6073298429319371
number of features: 37;	aic=2572.5937469027112;	ACC(cutoff0.5)=0.6047120418848168
number of features: 36;	aic=2571.9355794486646;	ACC(cutoff0.5)=0.606282722513089
number of features: 35;	aic=2571.1995774138786;	ACC(cutoff0.5)=0.6094240837696335
number of features: 34;	aic=2570.6512478907334;	ACC(cutoff0.5)=0.6109947643979058
number of features: 33;	aic=2569.9508496550375;	ACC(cutoff0.5)=0.6094240837696335
number of features: 32;	aic=2569.0960900360565;	ACC(cutoff0.5)=0.6078534031413613
number of features: 31;	aic=2568.264799257626;	ACC(cutoff0.5)=0.6094240837696335
number of features: 30;	aic=2567.913035409491;	ACC(cutoff0.5)=0.6068062827225131
number of features: 29;	aic=2567.1930450111713;	ACC(cutoff0.5)=0.6089005235602094
number of features: 28;	aic=2565.555018942871;	ACC(cutoff0.5)=0.6078534031413613
number of features: 27;	aic=2565.3257755544128;	ACC(cutoff0.5)=0.6020942408376964
number of features: 26;	aic=2564.498618477544;	ACC(cutoff0.5)=0.6010471204188481
number of features: 25;	aic=2564.071862367904;	ACC(cutoff0.5)=0.6020942408376964
number of features: 24;	aic=2562.7365254858905;	ACC(cutoff0.5)=0.5984293193717277
number of features: 23;	aic=2561.31795539813;	ACC(cutoff0.5)=0.6015706806282722
number of features: 22;	aic=2561.0572955709486;	ACC(cutoff0.5)=0.6078534031413613
number of features: 21;	aic=2560.4647671126922;	ACC(cutoff0.5)=0.6020942408376964
number of features: 20;	aic=2559.550514082446;	ACC(cutoff0.5)=0.5958115183246073
number of features: 19;	aic=2558.86673645954;	ACC(cutoff0.5)=0.5973821989528796
========================End of sequential backward feature selection======================
Selected features with min AIC:
minAIC = 2558.86673645954
selected features: ['L0_S1', 'L0_S4', 'L0_S7', 'L1_S2', 'L1_S4', 'L2_S2', 'L3_S1', 'L3_S2', 'L3_S5', 'L4_S4', 'L4_S8', 'L5_S3', 'L5_S4', 'L5_S7', 'L6_S0', 'L6_S1', 'L7_S4', 'L7_S8', 'L8_S0']
selected feature indexes: [1, 4, 7, 11, 13, 20, 28, 29, 32, 40, 44, 48, 49, 52, 54, 55, 67, 71, 72]

                           Logit Regression Results
==============================================================================
Dep. Variable:                      y   No. Observations:                 1910
Model:                          Logit   Df Residuals:                     1891
Method:                           MLE   Df Model:                           18
Date:                Wed, 03 Feb 2021   Pseudo R-squ.:                 0.03619
Time:                        11:19:11   Log-Likelihood:                -1260.4
converged:                       True   LL-Null:                       -1307.8
Covariance Type:            nonrobust   LLR p-value:                 2.080e-12
==============================================================================
                 coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------
x1            -0.0639      0.021     -3.085      0.002      -0.105      -0.023
x2             0.0279      0.019      1.484      0.138      -0.009       0.065
x3             0.0485      0.026      1.838      0.066      -0.003       0.100
x4             0.0292      0.016      1.824      0.068      -0.002       0.061
x5            -0.0325      0.015     -2.178      0.029      -0.062      -0.003
x6             0.0327      0.017      1.979      0.048       0.000       0.065
x7             0.0965      0.045      2.142      0.032       0.008       0.185
x8            -0.1105      0.042     -2.630      0.009      -0.193      -0.028
x9            -0.0966      0.039     -2.467      0.014      -0.173      -0.020
x10           -0.0368      0.023     -1.592      0.111      -0.082       0.009
x11            0.1173      0.036      3.254      0.001       0.047       0.188
x12            0.0452      0.019      2.403      0.016       0.008       0.082
x13            0.0320      0.014      2.341      0.019       0.005       0.059
x14           -0.0749      0.021     -3.594      0.000      -0.116      -0.034
x15            0.1129      0.072      1.573      0.116      -0.028       0.254
x16           -0.1461      0.074     -1.982      0.047      -0.291      -0.002
x17           -0.1155      0.037     -3.147      0.002      -0.187      -0.044
x18            0.0727      0.032      2.291      0.022       0.010       0.135
x19            0.0769      0.032      2.380      0.017       0.014       0.140
==============================================================================
Accuracy of using ['L0_S1', 'L0_S4', 'L0_S7', 'L1_S2', 'L1_S4', 'L2_S2', 'L3_S1', 'L3_S2', 'L3_S5', 'L4_S4', 'L4_S8', 'L5_S3', 'L5_S4', 'L5_S7', 'L6_S0', 'L6_S1', 'L7_S4', 'L7_S8', 'L8_S0']
 to predict hypertension with cutoff 0.5: 0.5973821989528796
With a different cut off with max(ACC+TPR+TNR):
{'threshold': 0.583, 'ACC': 0.5963350785340314, 'TPR': 0.5097312326180748, 'TNR': 0.7087845968627101, 'Sum': 1.8148509080148165}
Where:
x1 = L0_S1
x2 = L0_S4
x3 = L0_S7
x4 = L1_S2
x5 = L1_S4
x6 = L2_S2
x7 = L3_S1
x8 = L3_S2
x9 = L3_S5
x10 = L4_S4
x11 = L4_S8
x12 = L5_S3
x13 = L5_S4
x14 = L5_S7
x15 = L6_S0
x16 = L6_S1
x17 = L7_S4
x18 = L7_S8
x19 = L8_S0
===================================================================




#Feb 02nd, Tuesday, 2021:
=======================
Use non-sysmmetric thickness of OD/OS:
1  current: 31 thickness + 10 clinical features;
2  plan: 81x2 thickness + 9 clinical feature
3  training sample number: 1520 patients.
4  network structure:
   81thicknessOD--|
   81thicknessOS--| ========(FC)=======>10--|
        9 clinical  ======(1x1Conv)====>9 --|==(FC)=>1

   parameters: (162+1)*10+ 9*2+ (19+1)*1 = 1668.
   parameters/obsereration: 1668/1520 = 1.097
   training sample/input space:  1520/(162+9) = 8.89
5  if no overfitting, add the 10 (after 1st FC) to bigger;

Work for OD/OS both eyes input:
1  mkdir of dataDir;
2  dataLoader support 2 input data;
3  main train/test need moify input inerface;
4  new network;
5  rebuild GTs dir for data set ID;


# check data CV0:
in CV: 0/10: test: 193 patients;  validation: 191 patients;  training: 1528 patients; without repeated ID.
in code:
training dataset_10CV_0: NVolumes=3040
validation dataset_10CV_0: NVolumes=382
test dataset_10CV_0: NVolumes=386

It means in training data of CV0, some patitent only has single eye data.
1  some patitent has 3 eye data:e.g. ID= 773
2  some pateints have one eye data: ID= 719

Meeting with professor:
1  Tongren data has no OS ground truth, we need to check the quality of OS; to get further or not?
2  read Tianbao's paper;
3  arrange a meeting with professor Wang, afer spring festival;


Check OS segmentation quality:
As training data has no OS images:

python3 displayJPG_SegXML_BES3K.py /home/hxie1/data/BES_3K/raw/2093_OS_14923_Volume /home/hxie1/data/BES_3K/W512NumpyVolumes/log/SurfacesNet/expBES3K_20201126A_genXml/testResult/xml/2093_OS_14923_Volume_Sequence_Surfaces_Prediction.xml /home/hxie1/data/temp/2093_OS_seg
python3 displayJPG_SegXML_BES3K.py /home/hxie1/data/BES_3K/raw/2093_OD_14918_Volume /home/hxie1/data/BES_3K/W512NumpyVolumes/log/SurfacesNet/expBES3K_20201126A_genXml/testResult/xml/2093_OD_14918_Volume_Sequence_Surfaces_Prediction.xml /home/hxie1/data/temp/2093_OD_seg

About the segmentation quality of OS:

Notes:
1  our training data of segmentation network are all OD eyes with ground truth.
2  We used the above trained network to segmentation both OD/OS volumes of BES_3K data.
3  In human eye, the segmenatation result quality of OS eyes looks almost same good with OD eyes;
   Please refer to the attachment of random choose example patient 2093.
   Reason: As surface patterns in OCT of OD/OS eyes have no significant difference;
4  Further plan:
   A  use OD eye only to redo single eye hypertension prediction of 10 fold crossing validation;
   B  use OS/OD eyes to utilize the difference of OD/OS eyes to predict hypertension;
5  Professor Wu, what is your suggestion?
   Do A?  and discard B;
   or Do A, and then do B;
   or Do B?
   Professor answer: do both.

# use OD single eye to predict:
1 use AIC to do thickness variable selection on OD eye only;   --done, 19 features
2 use AIC to clinical variable selection against hypertension only;  --done, 10 features
3 redo 10 fold ID for OD image with 29 features: ---done, at ~/data/BES_3K/GTs/29Ftrs_OD_10CV/
4 assembly thickness on OD and clincial feature to deep learning network;  --done
5 network structure:
  19thicknessOD--| ========(FC)=======>10 --|
      10 clinical  ======(1x1Conv)====>10 --|==(FC...)=>1   --done

6  clincial feature should do 1x1 conv before assembling with thickness features.  --done.

# Feb 01st, Monday, 2021:
Hyptension 10-fold crossing validation result:

=====================================================================
                DataSet in 10-fold crossing validation
=====================================================================
                Num       0_Proportion          1_Proportion
training,       3040,     0.43684208393096924,  0.5631579160690308
validation,     382,      0.4371727705001831,   0.5628272294998169
test,           386,      0.4352331757545471,   0.5647668242454529
=====================================================================
Note:
1  The num of data set counts OD/OS as diferrent case;

==========================================
       10-fold crossing validation(lr=0.01)
==========================================
CVFold	    Accuracy	TPR	    TNR
CV0	        0.6373	    0.899	0.2976
CV1	        0.5994	    0.6558	0.5269
CV2	        0.6701	    0.7793	0.5301
CV3	        0.6411	    0.5915	0.7048
CV4	        0.6902	    0.7441	0.6204
CV5	        0.6263	    0.5514	0.7228
CV6	        0.6263	    0.5841	0.6807
CV7	        0.5958	    0.6883	0.4759
CV8	        0.6631	    0.556	0.8012
CV9	        0.6263	    0.7616	0.4518
Average	    0.6376	    0.6811	0.5812
===========================================
Notes:
1 all result on test fold used the threshold of maximizing sum(ACC+TPR+TNR) in validation fold.
2 all result are on the test fold
3 all 10-fold crossing validation use lr=0.01 with experiment of  expOCT_41Ftr_HyT_20210130_10CV_?.yaml;
4 input is 31 thicknesses +10 clinical features chosen by logistics regression and backward variable selection;

Analysis:
1  Using OD/OS of a same patient and choosing big probability as final 0/1 result may further improve final 0/1 result;
   as I observed that OD/OS are not symmetric in thickness for a same patient.



==========================================
       10-fold crossing validation(lr=0.001)
==========================================
CVFold	Accuracy	TPR	TNR
CV0	    0.6295	0.8165	0.3869
CV1	    0.568	0.8744	0.1736
CV2	    0.5488	0.6525	0.4156
CV3	    0.5329	0.3286	0.7951
CV4	    0.6299	0.7116	0.524
CV5	    0.5657	0.8084	0.253
CV6	    0.6026	0.5747	0.6385
CV7	    0.5223	0.5627	0.4698
CV8	    0.5078	0.299	0.7771
CV9	    0.6184	0.7943	0.3915
Average	0.5726	0.6423	0.4825
===========================================
Notes:
1 all result on test fold used the threshold of maximizing sum(ACC+TPR+TNR) in validation fold.
2 all result are on the test fold
3 all 10-fold crossing validation use lr=0.001 with experiment of  expOCT_41Ftr_HyT_20210130B_10CV_?.yaml;
4 input is 31 thicknesses +10 clinical features chosen by logistics regression and backward variable selection;

================================
	LearningRate=0.05
================================
CVFold	    Accuracy	TPR	TNR
CV0	        0.6735	0.6651	0.6845
CV1	        0.6099	0.6883	0.5089
CV2	        0.6279	0.7464	0.4759
CV3	        0.6279	0.5774	0.6927
CV4	        0.6797	0.7488	0.5903
CV5	        0.6526	0.6168	0.6987
CV6	        0.5868	0.5373	0.6506
CV7	        0.5826	0.6325	0.518
CV8	        0.6289	0.542	0.7409
CV9	        0.6263	0.813	0.3855
Average	    0.6296	0.6568	0.5946
=================================

Notes:
1 all result used the threshold of maximizing sum in validation data.
2 all result are on the test fold
3 experiment name: expOCT_41Ftr_HyT_20210201_10CV_?.yaml



# Jan 30th, Saturday, 2021
Prepare 10-fold cross validation for 41-feature network:
1  at dir=/home/hxie1/data/BES_3K/W512NumpyVolumes/log/SurfacesNet/expBES3K_20201126A_genXml/testResult
   make a new dir: thickness9Sector_9x9_41Ftrs_10CV    --done
2  at GT directory, make a new dir: 41Ftr_10CV
   store 10-fold training, validation, test ID      --done.
3  dataload classe, according to k-fold to read ID, and save ID path with k-fold; --done
4  write a srcipt to divide data;  --done.

each fold needs GPU memory: 660MB.

expOCT_41Ftr_HyT_20210130_10CV_0.yaml: lr=0.01

expOCT_41Ftr_HyT_20210130B_10CV_0.yaml: lr=0.001









# Jan 28th, Thursay, 2021
Test result of using reduced 41 features (31 thicknesses+ 10 clinical features) to predict hypertension:
=================================================================================================================================================
                                                  Experiment result on validation and test data:
                                          Below experiments all use lr=0.01, lrPatient=6, fcWidths=[40, 20,1].
=================================================================================================================================================
ExperimentName                                  ValidACC  ValidTPR  ValidTNR  TestACC  TestTPR  TestTNR     Note
expOCT_9x9Sector_biochemical_2HyT_20210120A_FC  0.6943    0.80      0.56      0.6164   0.6866   0.5224      81 thickness + 9 clinical features.
expOCT_41Ftr_HyT_20210126B_FC                   0.7010    0.7403    0.65      0.6128   0.6658   0.5397      31 thickness + 10 clinical features.
expOCT_41Ftr_HyT_20210127A_FC_switchValidTest   0.6169    0.5096    0.7649    0.6952   0.7377   0.6399      31 thickness + 10 clinical features,
                                                                                                            switch validation and test data
==================================================================================================================================================
In above table, Valid means validationData.
==================================================================================================================================================

Analysis:
1  Experiment used backward step-wise feature selection basing on AIC to get 41 features from original 95 features;
2  After experiment 20201027A switch validation data and test data from previous experiments, it lead to its validation result almost switches with its test result.
   In other words, after switch, testAcc get 0.6952. It shows testAcc is depend on specific test data set.
   In the future, we need to do a 6-fold cross validation to evaluate model's accuracy.
3  Comparing two 41-feature input experiments with the previous 90-feature experiment,
   0.7010+0.6128 > 0.6943+0.6164,   and 0.6169+0.6952 > 0.6943+0.6164
   It shows 41-feature input gets a little better than 90-feature input.
4  In literature, the benefits of reducing irrelevant redundant features:
    A  reduce multi-colinearity;
    B  improve fit accuracy, and decrease over-fitting;
    C  remove irrelevant noise features;
5  Current 41-feature and 91-feature networks are still easy to overfitting. If we just add learning rate to 0.1, its validation loss will increase while train loss goes down quickly.
   It shows that training data has some significant features related with output, but these features can not generalize well in validation data.
   In othe words, we may have not found significant and can-generalize-well features with respect to output.
   Or the thickness and clinical features are not powerful enough to predict hypertension.
6  Further plan:
   A  search radiomics features, feature selection,  and then add into input to deep learning network.









# Jan 27th, Wednesday, 2021:
41 features test:

expOCT_41Ftr_HyT_20210127A_FC_switchValidTest: lr=0.01, lrPatient=6, fcWidths=[40, 20,1]
training data set: NVolumes=2401
validation data set: NVolumes=718
test data set: NVolumes=689
	train_Td_Acc_TPR_TNR_Sum:{'threshold': 0.589, 'ACC': 0.616991643454039, 'TPR': 0.5096153846031343, 'TNR': 0.7649006622263278, 'Sum': 1.8915076902835013}

=======Test Result on test data with threshold of 0.589=========
	ACC:0.6618287373004355
	TPR:0.5809768637382782
	TNR:0.766666666641111
	Sum:2.0094722676798247

=======Test Result on test data with threshold of 0.5 =========
	ACC:0.6952104499274311
	TPR:0.7377892030658666
	TNR:0.6399999999786666
	Sum:2.0729996529719643



expOCT_41Ftr_HyT_20210127B_FC_switchValidTest: lr=0.1, lrPatient=12, fcWidths=[40, 20,1]
training data set: NVolumes=2401
validation data set: NVolumes=718
test data set: NVolumes=689

    Overfitting by observing validation loss without decreasing.

	train_Td_Acc_TPR_TNR_Sum:{'threshold': 0.025, 'ACC': 0.6323119777158774, 'TPR': 0.6370192307539178, 'TNR': 0.6258278145488136, 'Sum': 1.8951590230186088}

=======Test Result on test data with threshold of 0.025=========
	ACC:0.6298984034833092
	TPR:0.6606683804457412
	TNR:0.5899999999803334
	Sum:1.8805667839093836

=======Test Result on test data with threshold of 0.5 =========
	ACC:0.4426705370101596
	TPR:0.038560411310062714
	TNR:0.9666666666344444
	Sum:1.4478976149546667



expOCT_41Ftr_HyT_20210127C_FC: lr=0.1, lrPatient=6, fcWidths=[40, 20,1]
training data set: NVolumes=2401
validation data set: NVolumes=689
test data set: NVolumes=718

Overfitting by observing validation loss without decreasing.
train_Td_Acc_TPR_TNR_Sum:{'threshold': 0.537, 'ACC': 0.6952104499274311, 'TPR': 0.7120822621924915, 'TNR': 0.6733333333108888, 'Sum': 2.0806260454308116}

=======Test Result on test data with threshold of 0.537=========
	ACC:0.5988857938718662
	TPR:0.5937499999857272
	TNR:0.6059602648805973
	Sum:1.7985960587381908

=======Test Result on test data with threshold of 0.5 =========
	ACC:0.6044568245125348
	TPR:0.6394230769077062
	TNR:0.5562913907100565
	Sum:1.8001712921302975



expOCT_41Ftr_HyT_20210127D_FC: lr=0.1, lrPatient=12, fcWidths=[40, 20,1]
training data set: NVolumes=2401
validation data set: NVolumes=689
test data set: NVolumes=718

Overfitting by observing validation loss without decreasing.

	train_Td_Acc_TPR_TNR_Sum:{'threshold': 0.333, 'ACC': 0.6894049346879536, 'TPR': 0.8431876606467047, 'TNR': 0.48999999998366667, 'Sum': 2.022592595318325}

=======Test Result on test data with threshold of 0.333=========
	ACC:0.6197771587743732
	TPR:0.7740384615198548
	TNR:0.4072847681984343
	Sum:1.8011003884926624

=======Test Result on test data with threshold of 0.5 =========
	ACC:0.6030640668523677
	TPR:0.5576923076789017
	TNR:0.6655629138852462
	Sum:1.8263192884165154



# Jan 26th, Tuesday, 2021
Use 41 features(31 thickness +10 clinical) for training:
expOCT_41Ftr_HyT_20210126A_FC: start lr= 0.01, lrPatient=6, fcWidths: [40, 20,1]
    training data set: NVolumes=2401
    validation data set: NVolumes=689
    test data set: NVolumes=718
net.m_runParametersDict:
	validationLoss:0.5483165383338928
	epoch:72
	accuracy_cutoff0.5:0.6850507982583455
	learningRate:0.002097152000000001
	threshold:0.47300000000000003
	train_Td_Acc_TPR_TNR_Sum:{'threshold': 0.47300000000000003, 'ACC': 0.706821480406386, 'TPR': 0.7840616966379419, 'TNR': 0.6066666666464444, 'Sum': 2.0975498436907722}

=======Test Result on test data with threshold of 0.47300000000000003=========
	ACC:0.6072423398328691
	TPR:0.6947115384448387
	TNR:0.4867549668712995
	Sum:1.7887088451490074

=======Test Result on test data with threshold of 0.5 =========
	ACC:0.6086350974930362
	TPR:0.651442307676648
	TNR:0.5496688741539845
	Sum:1.8097462793236687


expOCT_41Ftr_HyT_20210126B_FC:  start lr= 0.01, lrPatient=6, fcWidths: [40, 20,1]
    name origin: expOCT_41Ftr_HyT_20210126A_FC_switchValidTest: (a dir bug data sets didn't switch)
    training data set: NVolumes=2401
    validation data set: NVolumes=689
    test data set: NVolumes=718

net.m_runParametersDict:
	validationLoss:0.5623322129249573
	epoch:40
	accuracy_cutoff0.5:0.6821480406386067
	learningRate:0.008
	threshold:0.531
	train_Td_Acc_TPR_TNR_Sum:{'threshold': 0.531, 'ACC': 0.7010159651669086, 'TPR': 0.740359897153204, 'TNR': 0.6499999999783334, 'Sum': 2.0913758622984457}

=======Test Result on test data with threshold of 0.531=========
	ACC:0.6128133704735376
	TPR:0.6658653845993783
	TNR:0.5397350993198763
	Sum:1.8184138543927921

=======Test Result on test data with threshold of 0.5 =========
	ACC:0.6058495821727019
	TPR:0.7211538461365107
	TNR:0.4470198675348669
	Sum:1.7740232958440794





# Jan 25th, Monday, 2021
Feature selection result using sequential backward feature selection algorithm:
Summary:
1  Input: 9x9 thickness sectors + 14 clinical features = 95 featurs;
2  Used sequential backward features selection according to AIC (Akaike information criterion);
3  Final selected 41 features: 31 thickness features + 10 clinical features:
   This 41 features are the  best features combination by a sequential, not exhaust(impractical in computation), feature search.
4  Clinical features excluded gender, smoke, cholesterol, and CRPL;
   excluding cholesterol is a little surprise, but it is also reasonable as its pvalue is a little big comparing with others.
5  Below ACC change in search process is reasonable, as its change is less than 1%.
6  tomorrow I will use these 41 features to feed into a deep learning network to see his deep learning result;


Experiment: expOCT_SequentialBackwardFS_20210125

== Sequential backward feature selection w.r.t. HBP ==============
After deleting empty-value patients, it remains 3804 patients.
Initial input features before feature selection:
['L0_S0', 'L0_S1', 'L0_S2', 'L0_S3', 'L0_S4', 'L0_S5', 'L0_S6', 'L0_S7', 'L0_S8', 'L1_S0', 'L1_S1', 'L1_S2', 'L1_S3', 'L1_S4', 'L1_S5', 'L1_S6', 'L1_S7', 'L1_S8', 'L2_S0', 'L2_S1',
'L2_S2', 'L2_S3', 'L2_S4', 'L2_S5', 'L2_S6', 'L2_S7', 'L2_S8', 'L3_S0', 'L3_S1', 'L3_S2', 'L3_S3', 'L3_S4', 'L3_S5', 'L3_S6', 'L3_S7', 'L3_S8', 'L4_S0', 'L4_S1', 'L4_S2', 'L4_S3',
'L4_S4', 'L4_S5', 'L4_S6', 'L4_S7', 'L4_S8', 'L5_S0', 'L5_S1', 'L5_S2', 'L5_S3', 'L5_S4', 'L5_S5', 'L5_S6', 'L5_S7', 'L5_S8', 'L6_S0', 'L6_S1', 'L6_S2', 'L6_S3', 'L6_S4', 'L6_S5',
'L6_S6', 'L6_S7', 'L6_S8', 'L7_S0', 'L7_S1', 'L7_S2', 'L7_S3', 'L7_S4', 'L7_S5', 'L7_S6', 'L7_S7', 'L7_S8', 'L8_S0', 'L8_S1', 'L8_S2', 'L8_S3', 'L8_S4', 'L8_S5', 'L8_S6', 'L8_S7',
'L8_S8', 'gender', 'Age', 'IOP', 'AxialLength', 'Smoke', 'Pulse', 'Drink', 'Glucose', 'CRPL', 'Cholesterol', 'Triglyceride', 'BMI', 'WaistHipRate', 'LDLoverHDL']

============program is in sequential backward feature selection, please wait......==============
number of features: 95;	aic=4703.115993941735;	ACC(cutoff0.5)=0.6840168243953733
number of features: 94;	aic=4701.116248603205;	ACC(cutoff0.5)=0.6840168243953733
number of features: 93;	aic=4699.116923172041;	ACC(cutoff0.5)=0.6840168243953733
number of features: 92;	aic=4697.117972411769;	ACC(cutoff0.5)=0.6837539432176656
number of features: 91;	aic=4695.119843124134;	ACC(cutoff0.5)=0.6837539432176656
number of features: 90;	aic=4693.125248965362;	ACC(cutoff0.5)=0.6832281808622502
number of features: 89;	aic=4691.154089600343;	ACC(cutoff0.5)=0.6834910620399579
number of features: 88;	aic=4689.185742904654;	ACC(cutoff0.5)=0.6840168243953733
number of features: 87;	aic=4687.220080347437;	ACC(cutoff0.5)=0.6832281808622502
number of features: 86;	aic=4685.2462006096175;	ACC(cutoff0.5)=0.6829652996845426
number of features: 85;	aic=4683.279165413104;	ACC(cutoff0.5)=0.6829652996845426
number of features: 84;	aic=4681.3199136866415;	ACC(cutoff0.5)=0.6821766561514195
number of features: 83;	aic=4679.378923374291;	ACC(cutoff0.5)=0.6813880126182965
number of features: 82;	aic=4677.438207643816;	ACC(cutoff0.5)=0.6808622502628812
number of features: 81;	aic=4675.507354504261;	ACC(cutoff0.5)=0.6803364879074658
number of features: 80;	aic=4673.576585366525;	ACC(cutoff0.5)=0.6795478443743428
number of features: 79;	aic=4671.6548580133385;	ACC(cutoff0.5)=0.6821766561514195
number of features: 78;	aic=4669.7525602784435;	ACC(cutoff0.5)=0.6821766561514195
number of features: 77;	aic=4667.870870252643;	ACC(cutoff0.5)=0.6819137749737119
number of features: 76;	aic=4665.985840638892;	ACC(cutoff0.5)=0.6824395373291272
number of features: 75;	aic=4664.105726676983;	ACC(cutoff0.5)=0.6824395373291272
number of features: 74;	aic=4662.18500678698;	ACC(cutoff0.5)=0.6827024185068349
number of features: 73;	aic=4660.312011509949;	ACC(cutoff0.5)=0.6816508937960042
number of features: 72;	aic=4658.485155419752;	ACC(cutoff0.5)=0.6813880126182965
number of features: 71;	aic=4656.6765610795355;	ACC(cutoff0.5)=0.6808622502628812
number of features: 70;	aic=4654.981147510332;	ACC(cutoff0.5)=0.6790220820189274
number of features: 69;	aic=4653.258967380402;	ACC(cutoff0.5)=0.6784963196635121
number of features: 68;	aic=4651.563539549977;	ACC(cutoff0.5)=0.6803364879074658
number of features: 67;	aic=4649.862483323349;	ACC(cutoff0.5)=0.6771819137749737
number of features: 66;	aic=4648.157576292952;	ACC(cutoff0.5)=0.6790220820189274
number of features: 65;	aic=4646.346152181433;	ACC(cutoff0.5)=0.6790220820189274
number of features: 64;	aic=4644.8659653596405;	ACC(cutoff0.5)=0.6774447949526814
number of features: 63;	aic=4643.595082141491;	ACC(cutoff0.5)=0.6771819137749737
number of features: 62;	aic=4642.432003530882;	ACC(cutoff0.5)=0.6779705573080967
number of features: 61;	aic=4641.272140801453;	ACC(cutoff0.5)=0.6784963196635121
number of features: 60;	aic=4640.109090310414;	ACC(cutoff0.5)=0.6790220820189274
number of features: 59;	aic=4638.548446264683;	ACC(cutoff0.5)=0.6784963196635121
number of features: 58;	aic=4637.254631759639;	ACC(cutoff0.5)=0.6800736067297581
number of features: 57;	aic=4636.08738784991;	ACC(cutoff0.5)=0.6787592008412198
number of features: 56;	aic=4635.079825073293;	ACC(cutoff0.5)=0.6798107255520505
number of features: 55;	aic=4633.950133345463;	ACC(cutoff0.5)=0.6816508937960042
number of features: 54;	aic=4632.8449930797815;	ACC(cutoff0.5)=0.6813880126182965
number of features: 53;	aic=4631.929920578448;	ACC(cutoff0.5)=0.6813880126182965
number of features: 52;	aic=4630.803072277773;	ACC(cutoff0.5)=0.6784963196635121
number of features: 51;	aic=4630.075797876193;	ACC(cutoff0.5)=0.6795478443743428
number of features: 50;	aic=4629.387838694521;	ACC(cutoff0.5)=0.6803364879074658
number of features: 49;	aic=4628.80049791979;	ACC(cutoff0.5)=0.6790220820189274
number of features: 48;	aic=4628.213351631597;	ACC(cutoff0.5)=0.6766561514195584
number of features: 47;	aic=4627.5928144324125;	ACC(cutoff0.5)=0.6742902208201893
number of features: 46;	aic=4626.567829122094;	ACC(cutoff0.5)=0.676130389064143
number of features: 45;	aic=4625.910927912311;	ACC(cutoff0.5)=0.673764458464774
number of features: 44;	aic=4624.276124954185;	ACC(cutoff0.5)=0.6742902208201893
number of features: 43;	aic=4623.87098491536;	ACC(cutoff0.5)=0.6748159831756047
number of features: 42;	aic=4623.643487225389;	ACC(cutoff0.5)=0.6774447949526814
number of features: 41;	aic=4623.37899409433;	ACC(cutoff0.5)=0.676919032597266
========================End of sequential backward feature selection======================
Selected features with min AIC:
minAIC = 4623.37899409433
selected features: ['L0_S1', 'L0_S3', 'L0_S4', 'L0_S5', 'L1_S1', 'L1_S3', 'L2_S2', 'L2_S3', 'L3_S2', 'L3_S3', 'L3_S7', 'L4_S7', 'L5_S2', 'L5_S3', 'L5_S4', 'L5_S5',
'L5_S6', 'L5_S8', 'L6_S1', 'L6_S3', 'L6_S5', 'L6_S6', 'L6_S7', 'L7_S0', 'L7_S1', 'L7_S4', 'L7_S6', 'L7_S8', 'L8_S5', 'L8_S7', 'L8_S8',
'Age', 'IOP', 'AxialLength', 'Pulse', 'Drink', 'Glucose', 'Triglyceride', 'BMI', 'WaistHipRate', 'LDLoverHDL']
selccted feature indexes: [1, 3, 4, 5, 10, 12, 20, 21, 29, 30, 34, 43, 47, 48, 49, 50, 51, 53, 55, 57, 59, 60, 61, 63, 64, 67, 69, 71, 77, 79, 80, 82, 83, 84, 86, 87, 88, 91, 92, 93, 94]

                           Logit Regression Results
==============================================================================
Dep. Variable:                      y   No. Observations:                 3804
Model:                          Logit   Df Residuals:                     3763
Method:                           MLE   Df Model:                           40
Date:                Mon, 25 Jan 2021   Pseudo R-squ.:                  0.1285
Time:                        17:21:12   Log-Likelihood:                -2270.7
converged:                       True   LL-Null:                       -2605.6
Covariance Type:            nonrobust   LLR p-value:                2.908e-115
==============================================================================
                 coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------
x1            -0.0389      0.016     -2.507      0.012      -0.069      -0.008
x2             0.0257      0.014      1.897      0.058      -0.001       0.052
x3             0.0236      0.012      1.926      0.054      -0.000       0.048
x4             0.0112      0.008      1.492      0.136      -0.004       0.026
x5             0.0327      0.011      3.031      0.002       0.012       0.054
x6            -0.0435      0.012     -3.748      0.000      -0.066      -0.021
x7             0.0322      0.015      2.155      0.031       0.003       0.061
x8            -0.0256      0.016     -1.571      0.116      -0.058       0.006
x9            -0.0786      0.029     -2.748      0.006      -0.135      -0.023
x10            0.1129      0.036      3.173      0.002       0.043       0.183
x11           -0.0901      0.032     -2.835      0.005      -0.152      -0.028
x12            0.0480      0.019      2.518      0.012       0.011       0.085
x13           -0.0164      0.011     -1.428      0.153      -0.039       0.006
x14            0.0245      0.012      2.057      0.040       0.001       0.048
x15            0.0400      0.014      2.807      0.005       0.012       0.068
x16           -0.0300      0.011     -2.776      0.006      -0.051      -0.009
x17            0.0275      0.016      1.698      0.090      -0.004       0.059
x18           -0.0394      0.017     -2.364      0.018      -0.072      -0.007
x19           -0.0733      0.042     -1.762      0.078      -0.155       0.008
x20           -0.1192      0.058     -2.062      0.039      -0.233      -0.006
x21            0.0480      0.027      1.788      0.074      -0.005       0.101
x22           -0.1676      0.043     -3.941      0.000      -0.251      -0.084
x23            0.1291      0.050      2.589      0.010       0.031       0.227
x24            0.0520      0.022      2.413      0.016       0.010       0.094
x25           -0.0516      0.031     -1.674      0.094      -0.112       0.009
x26           -0.1344      0.040     -3.323      0.001      -0.214      -0.055
x27           -0.0865      0.026     -3.369      0.001      -0.137      -0.036
x28            0.1813      0.036      4.973      0.000       0.110       0.253
x29           -0.1327      0.052     -2.563      0.010      -0.234      -0.031
x30           -0.1518      0.046     -3.274      0.001      -0.243      -0.061
x31            0.2126      0.063      3.352      0.001       0.088       0.337
x32            0.0645      0.005     12.325      0.000       0.054       0.075
x33            0.0825      0.014      5.952      0.000       0.055       0.110
x34           -0.1878      0.041     -4.526      0.000      -0.269      -0.106
x35           -0.0167      0.004     -4.544      0.000      -0.024      -0.010
x36            0.0481      0.029      1.654      0.098      -0.009       0.105
x37            0.1001      0.029      3.502      0.000       0.044       0.156
x38            0.1193      0.037      3.257      0.001       0.048       0.191
x39            0.1539      0.012     12.772      0.000       0.130       0.177
x40            1.8278      0.643      2.842      0.004       0.567       3.089
x41           -0.1929      0.047     -4.135      0.000      -0.284      -0.101
==============================================================================
Accuracy of using ['L0_S1', 'L0_S3', 'L0_S4', 'L0_S5', 'L1_S1', 'L1_S3', 'L2_S2', 'L2_S3', 'L3_S2', 'L3_S3', 'L3_S7', 'L4_S7', 'L5_S2', 'L5_S3', 'L5_S4', 'L5_S5', 'L5_S6', 'L5_S8', 'L6_S1', 'L6_S3', 'L6_S5', 'L6_S6', 'L6_S7', 'L7_S0', 'L7_S1', 'L7_S4', 'L7_S6', 'L7_S8', 'L8_S5', 'L8_S7', 'L8_S8', 'Age', 'IOP', 'AxialLength', 'Pulse', 'Drink', 'Glucose', 'Triglyceride', 'BMI', 'WaistHipRate', 'LDLoverHDL']
 to predict hypertension with cutoff 0.5: 0.676919032597266
With a different cut off with max(ACC+TPR+TNR):
{'threshold': 0.5690000000000001, 'ACC': 0.6729758149316509, 'TPR': 0.6564102564071963, 'TNR': 0.6943942133773696, 'Sum': 2.0237802847162167}
Where:
x1 = L0_S1
x2 = L0_S3
x3 = L0_S4
x4 = L0_S5
x5 = L1_S1
x6 = L1_S3
x7 = L2_S2
x8 = L2_S3
x9 = L3_S2
x10 = L3_S3
x11 = L3_S7
x12 = L4_S7
x13 = L5_S2
x14 = L5_S3
x15 = L5_S4
x16 = L5_S5
x17 = L5_S6
x18 = L5_S8
x19 = L6_S1
x20 = L6_S3
x21 = L6_S5
x22 = L6_S6
x23 = L6_S7
x24 = L7_S0
x25 = L7_S1
x26 = L7_S4
x27 = L7_S6
x28 = L7_S8
x29 = L8_S5
x30 = L8_S7
x31 = L8_S8
x32 = Age
x33 = IOP
x34 = AxialLength
x35 = Pulse
x36 = Drink
x37 = Glucose
x38 = Triglyceride
x39 = BMI
x40 = WaistHipRate
x41 = LDLoverHDL




# Jan 23rd, Satursday, 2021:

https://machinelearningmastery.com/probabilistic-model-selection-measures/

The benefits of reducing irrelevant redundant features:
1  reduce multi-colinearity;
2  add fit accuracy, and decrease overfitting;
3  remove irrelevant noise features;


Model selection and AIC:
The benefit of these Akaike information criterion statistics is that they do not require a hold-out test set,
although a limitation is that they do not take the uncertainty of the models into account
and may end-up selecting models that are too simple.

A benefit of probabilistic model selection methods is that a test dataset is not required, meaning that all of
the data can be used to fit the model, and the final model that will be used for prediction in the domain can be scored directly.

The simplest reliable method of model selection involves fitting candidate models on a training set,
tuning them on the validation dataset, and selecting a model that performs the best on the test dataset
according to a chosen metric, such as accuracy or error. A problem with this approach is that it requires a lot of data.

There are many common approaches that may be used for model selection. For example,
in the case of supervised learning, the three most common approaches are:
A Train, Validation, and Test datasets.
B  Resampling Methods.
C  Probabilistic Statistics.

Probabilistic model selection (or “information criteria”) provides an analytical technique for scoring and choosing among candidate models.

AIC = -2/N * LL + 2 * k/N
Where N is the number of examples in the training dataset, LL is the log-likelihood of the model on the training dataset,
 and k is the number of parameters in the model.

The score, as defined above, is minimized, e.g. the model with the lowest AIC is selected

Compared to the BIC method (below), the AIC statistic penalizes complex models less,
meaning that it may put more emphasis on model performance on the training dataset, and, in turn, select more complex models.


stepwise regression for variables selection.

Irrelevant IVs may deceases the fiting accuracy, or overfitting.

Unless the number of candidate variables > sample size (or number of events), use a backward stepwise approach.

Automated variable selection is not meant to replace expert opinion. In fact, important variables judged by background
 knowledge should still be entered in the model even if they are statistically non-significant.

Where automated variable selection is most helpful is in exploratory data analysis especially when working on
new problems not already studied by other researchers (where background knowledge is not available).

This instability is reduced when we have a sample size (or number of events) > 50 per candidate variable.

Forward or backward stepwise variable selection/regression is like SGD, at each step, looking at previous step, and
search current biggest improvement step.

Forward and backward stepwise selection is not guaranteed to give us the best model containing a particular subset of
the p predictors but that's the price to pay in order to avoid overfitting.

OLS in statsmodels for model selection.

https://github.com/AakkashVijayakumar/stepwise-regression

why automatic feature selection:  We want to improve the computational efficiency and
reduce the generalization error of the model by removing irrelevant features or noise.


gender -> thickness -> hyptension
gender -> hypertension




# Jan 22nd, Friday, 2021:
Summary:
1  input: 81-sector thickness + 10 clinical features: ['gender', 'Age', 'IOP', 'AxialLength', 'Pulse', 'Glucose', 'Cholesterol', 'Triglyceride', 'BMI', 'LDLoverHDL']
2  Grid search best config in Random Forest:
   A: decision tree number range: 100-300
   B: feature number range: 10%x91-30%x91
   The best config: 220 decision trees, and 0.2*91 features. It got 67% accuracy on validation data, an 62% accuracy on test data;
3  The disadvantage of Random forest is its unexplainable features, as its final result is the majority vote of N decision trees of random features.
4  This result is almost consistent with our deep learning and logistic regression.
   Now deep learning, SVM, logistic regression, random forest for hypertension all get almost similar results.
   The improvement from 62% to 67-69% on validation data is because of adding clinical features on the thickness data.
5  Further plan:
   A  Use radiomics to search texture features for hypertension:
      Without medical knowledge as a guide, this kind of radiomics feature searching is like looking for a needle in a haystack; It can not guarantee success.
      As hypertension is a cardio-vascular disease, what we are looking now is OCT neural layers, which is more related with nerual degenerative disease;
   or
   B  Change to another disease to try, for example diabetes, cognitive disable, or depression.

Experiment: expOCT_RF2HBP_20210122

== RandomForest using 81+10 features to predict HBP ==============
inputClinical features: ['gender', 'Age', 'IOP', 'AxialLength', 'Pulse', 'Glucose', 'Cholesterol', 'Triglyceride', 'BMI', 'LDLoverHDL']
size of train data set: (2473, 91)
size of validation data set: (700, 91)
size of test data set: (730, 91)
RandomForest: n_estimators=200,  max_features=0.2
Random forest parameters:
{'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 0.2,
'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1,
'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 200, 'n_jobs': None, 'oob_score': False,
'random_state': None, 'verbose': 0, 'warm_start': False}
training score: 1.0
validation score: 0.6442857142857142
test score: 0.6219178082191781

===========================================================Grid search for Random Forest=========================================================
===========================================the element in below table is validationACC_testAcc===================================================
========================================= the float feature indicate proportion of whole feature number==========================================
Estimators\Features,        0.10,   0.12,       0.14,       0.16,       0.18,    0.20,      0.22,       0.24,       0.26,    0.28,      0.30
100,                    0.64_0.59, 0.63_0.59, 0.64_0.60, 0.62_0.61, 0.66_0.61, 0.66_0.60, 0.67_0.62, 0.64_0.61, 0.65_0.62, 0.63_0.61, 0.64_0.61,
120,                    0.64_0.61, 0.64_0.61, 0.64_0.59, 0.64_0.60, 0.64_0.60, 0.64_0.62, 0.64_0.62, 0.63_0.62, 0.64_0.60, 0.65_0.60, 0.65_0.60,
140,                    0.65_0.61, 0.63_0.61, 0.63_0.59, 0.65_0.60, 0.66_0.61, 0.66_0.61, 0.64_0.61, 0.63_0.60, 0.65_0.61, 0.65_0.61, 0.64_0.62,
160,                    0.64_0.61, 0.65_0.61, 0.65_0.62, 0.66_0.59, 0.65_0.62, 0.65_0.60, 0.63_0.60, 0.63_0.62, 0.65_0.62, 0.64_0.61, 0.66_0.61,
180,                    0.65_0.61, 0.64_0.61, 0.67_0.61, 0.64_0.62, 0.65_0.61, 0.64_0.60, 0.65_0.59, 0.65_0.61, 0.64_0.61, 0.65_0.62, 0.66_0.63,
200,                    0.65_0.59, 0.65_0.61, 0.66_0.60, 0.64_0.60, 0.64_0.61, 0.64_0.60, 0.67_0.61, 0.66_0.61, 0.66_0.61, 0.65_0.60, 0.64_0.61,
220,                    0.65_0.61, 0.64_0.62, 0.65_0.60, 0.65_0.61, 0.66_0.60, 0.67_0.62, 0.65_0.63, 0.65_0.60, 0.65_0.60, 0.66_0.61, 0.64_0.61,
240,                    0.64_0.60, 0.64_0.62, 0.66_0.61, 0.64_0.60, 0.64_0.62, 0.65_0.61, 0.64_0.61, 0.65_0.61, 0.65_0.60, 0.65_0.60, 0.66_0.61,
260,                    0.66_0.60, 0.66_0.61, 0.66_0.60, 0.65_0.62, 0.64_0.62, 0.64_0.62, 0.65_0.59, 0.64_0.61, 0.64_0.60, 0.66_0.63, 0.65_0.61,
280,                    0.65_0.62, 0.65_0.61, 0.64_0.61, 0.65_0.60, 0.65_0.61, 0.65_0.61, 0.66_0.62, 0.66_0.62, 0.65_0.60, 0.65_0.61, 0.64_0.61,
300,                    0.66_0.61, 0.65_0.60, 0.63_0.60, 0.65_0.61, 0.66_0.61, 0.64_0.61, 0.64_0.60, 0.65_0.61, 0.66_0.60, 0.64_0.61, 0.65_0.62,
==================================================================================================================================================



# Jan 22nd, Friday, 2021:
1  Use 81 sectors + 10 clinical features: ["gender", ""Age", "IOP", "AxialLength", "Pulse", "Glucose", "Cholesterol", "Triglyceride", "BMI", "LDLoverHDL"];
2  Big learning rate is also possible leading overfitting:
   In deep learning, normally we do not hope training loss decease to zero, as zero training loss means perfect match with training data, which is general over-fitting.
   learning rate acts a regularization item, and small learning rate means more regularization.
3  But too small learning rate also hurt trianing performace.
4  comparing 2 experiment:
   ExpName                                              lr      lrPatient, fcWidths    validationACC   testACC   input
   expOCT_9x9Sector_biochemical_2HyT_20210120A_FC       0.01    6         [40, 20,1]   0.6943          0.6164    81thickness+9clinical without gender
   expOCT_9x9Sector_10Biochemical_2HyT_20210122A_FC     0.01    6         [40, 20,1]   0.6529          0.6096    81thickness+10clinical with gender
5  As gender has bigger p-value, it hurt performance.



expOCT_9x9Sector_10Biochemical_2HyT_20210121A_FC: start lr= 0.1, lrPatient=24, fcWidths: [40, 20,1]
     Overfitting.  Sum=1.832.


expOCT_9x9Sector_10Biochemical_2HyT_20210121A_FC: start lr= 0.1, lrPatient=24, fcWidths: [50, 20,1]
     Overfitting. sum= 1.83

expOCT_9x9Sector_10Biochemical_2HyT_20210121A_FC: start lr= 0.1, lrPatient=24, fcWidths: [50, 30,1]
     Overfitting. sum=1.887. ACC=0.64.


expOCT_9x9Sector_10Biochemical_2HyT_20210122A_FC: start lr= 0.01, lrPatient=6, fcWidths: [40, 20,1]
    this only added age in input comparing with expOCT_9x9Sector_biochemical_2HyT_20210120A_FC, the best result of 9 clinical features without age.
    at epoch 1.076k, ACC =0.6529, Sum=1.959, TPR=0.65, TNR=0.65,  for validation data.
    =======Test Result on test data with threshold of 0.503=========
	ACC:0.6095890410958904
	TPR:0.6818181818018704
	TNR:0.5128205128040763
	Sum:1.8042277357018368


expOCT_9x9Sector_10Biochemical_2HyT_20210122B_FC: start lr= 0.001, lrPatient=12, fcWidths: [40, 20,1]
    at epoch 1.131k, ACC =0.627, Sum=1.834, TPR=0.78, TNR=0.42,  for validation data.
    =======Test Result on test data with threshold of 0.453=========
	ACC:0.5808219178082191
	TPR:0.7846889951965386
	TNR:0.30769230768244576
	Sum:1.6732032206872034


expOCT_9x9Sector_10Biochemical_2HyT_20210122C_FC: start lr= 0.001, lrPatient=6, fcWidths: [40, 20,1]
    at epoch 931, ACC =0.61, Sum=1.775, TPR=0.79, TNR=0.38,  for validation data.
    =======Test Result on test data with threshold of 0.483=========
	ACC:0.5794520547945206
	TPR:0.7583732057234839
	TNR:0.3397435897327005
	Sum:1.6775688502507051


expOCT_9x9Sector_10Biochemical_2HyT_20210122D_FC: start lr= 0.0001, lrPatient=12, fcWidths: [40, 20,1]
    at epoch 736, ACC =0.58, Sum=1.626, TPR=0.90, TNR=0.15,  for validation data.
    =======Test Result on test data with threshold of 0.47100000000000003=========
	ACC:0.5698630136986301
	TPR:0.7631578947185848
	TNR:0.3108974358874712
	Sum:1.643918344304686



# Jan 21st, Thursday, 2021:
Summary:
1  Use 81 sectors + 9 clinical features: ["Age", "IOP", "AxialLength", "Pulse", "Glucose", "Cholesterol", "Triglyceride", "BMI", "LDLoverHDL"];
2  Excluded gender, smoke, drink, CRPL, WaistHipRate features according to the p values of logisitc regression analysis;
3  Increasing biochemical index as input will reduce the availabel data number as missing data:
    training data set: NVolumes=2473
    validation data set: NVolumes=700
    test data set: NVolumes=730
4  Using these 9 clinical features can get validation accuracy 69%, and test accuracy 61.64%;
   It is better than before 81 sectors + 7 clinical features: ["gender", "Age",'IOP', 'AxialLength$',"smoke", "BMI", "WaistHipRate"]
   with validation accuracy 67%, and test accuracy of 60.96%.
5  All these experiment shows the data quality matters. Different data bring different accuracies.
6  Now I am working on random forests methods to check whether it will get better accuracy;

expOCT_9x9Sector_biochemical_2HyT_20210120A_FC: start lr= 0.01, lrPatient=6, fcWidths: [40, 20,1]
 at epoch 55, ACC =0.6943, Sum=2.051, TPR=0.80, TNR=0.56,  for validation data.
=======Test Result on test data with threshold of 0.371=========
	ACC:0.6164383561643836
	TPR:0.6866028707969712
	TNR:0.5224358974191526
	Sum:1.8254771243805075

expOCT_9x9Sector_biochemical_2HyT_20210120B_FC: start lr= 0.01,  lrPatient=6, fcWidths: [50, 30,1]
 at epoch 32, ACC =0.69, Sum=2.056, TPR=0.73, TNR=0.63,  for validation data.
=======Test Result on test data with threshold of 0.521=========
	ACC:0.6041095890410959
	TPR:0.6531100478312653
	TNR:0.53846153844428
	Sum:1.7956811753166413

expOCT_9x9Sector_biochemical_2HyT_20210120C_FC: start lr= 0.01,  lrPatient=6, fcWidths: [30, 20,1]
 at epoch 39, ACC =0.6757, Sum=2.009, TPR=0.73, TNR=0.60,  for validation data.
=======Test Result on test data with threshold of 0.463=========
	ACC:0.5931506849315068
	TPR:0.6363636363484123
	TNR:0.5352564102392546
	Sum:1.7647707315191736


expOCT_9x9Sector_biochemical_2HyT_20210120D_FC: start lr= 0.01,  lrPatient=6, fcWidths: [30, 30, 20,1]
 at epoch 42, ACC =0.6914, Sum=2.043, TPR=0.79, TNR=0.57, for validation data.
=======Test Result on test data with threshold of 0.309=========
	ACC:0.6068493150684932
	TPR:0.691387559792072
	TNR:0.4935897435739234
	Sum:1.7918266184344884


# Jan 20th, Wednesday, 2021:
1  As some patients miss some biochemical index(cholesterol) data, introducing the biochemical index will reduce the number of available data;
2  choose good clincial features, and exclude low-quality features:
    list of x whose pvalue <=0.05
x2=Age, z=14.096921717188435, pvalue=3.966999793137572e-45
x3=IOP, z=5.286857743484339, pvalue=1.2443533288996497e-07
x4=AxialLength, z=-13.413135007273308, pvalue=5.065154183697109e-41
x6=Pulse, z=-5.551521739416451, pvalue=2.8319348958319192e-08
x8=Glucose, z=3.2581298337851825, pvalue=0.0011214908327010097
x10=Cholesterol, z=-2.288740215141951, pvalue=0.0220944509447221
x11=Triglyceride, z=3.6990793476487913, pvalue=0.00021638295043066667
x12=BMI, z=12.255963972141293, pvalue=1.5608220122516097e-34
x14=LDLoverHDL, z=-2.3358503378650624, pvalue=0.019499043033275744

9 clinical features: ["Age", "IOP", "AxialLength", "Pulse", "Glucose", "Cholesterol", "Triglyceride", "BMI", "LDLoverHDL"]

after use 9 clinical features:
training data set: NVolumes=2473
validation data set: NVolumes=700



# Jan 19th, Tuesday, 2021
High cholesterol can lead to the build-up of plaque on the walls of your blood vessels,
which can block your arteries and cause high blood pressure, a stroke, heart disease, or a heart attack.

Task: add cholesterol as a risk factor;

expOCT_9x9Sector_clinnical_2HyT_20210118A_FC:  fcWidths: [120,100,80,60,40, 20,1] , explicit overfitting.

expOCT_9x9Sector_clinnical_2HyT_20210118B_FC:  fcWidths: [60,40, 20,1], 89*60+ 61*40+41*20+21*1 = 8621 parameters
                                               slightly overfitting.

expOCT_9x9Sector_clinnical_2HyT_20210118C_FC:  fcWidths: [40, 20,1] # num of neural in each FC layer # 89*40+41*20+21*1 = 4401 parameters
                                               Good. ACC: 67.6% and Sum: 2.009; TPR 76%. TNR 57%, threshold: 0.4664
=======Test Result on test data with threshold of 0.47100000000000003=========
	ACC:0.6096311475409836
	TPR:0.6684587813500276
	TNR:0.5311004784561938
	Sum:1.809190407347205

=======Test Result on test data with threshold of 0.5 =========
	ACC:0.5983606557377049
	TPR:0.6093189964048509
	TNR:0.583732057402303
	Sum:1.7914117095448587


expOCT_9x9Sector_clinnical_2HyT_20210118D_FC:  fcWidths: [20, 10,1] # num of neural in each FC layer # 89*20+21*10+11*1 = 2001 parameters
                                               a little weak.

Meeting with professor on Jan 19th, 2021:
1  add blood lipid etc network;
2  add radimics and texture into input;
3  backward activatin map analysis;

 high blood pressure (HBP or hypertension):

 High blood cholestrol and HBP: https://www.healthline.com/health/high-cholesterol/treating-with-statins/hypertension#1
 Triglycerides with hypertension:
 https://www.mayoclinic.org/diseases-conditions/high-blood-cholesterol/in-depth/triglycerides/art-20048186#:~:text=Borderline%20high%20%E2%80%94%20150%20to%20199,5.7%20mmol%2FL%20or%20above)

cat output_20210119_191203.txt
Experiment: expOCT_fat2HBP_20210119

=================================================================
Logistic Regression between a clinical variable and hypertension:
Optimization terminated successfully.
         Current function value: 0.691016
         Iterations 3

===============Logistic regression between hypertension and gender===============
                           Logit Regression Results
==============================================================================
Dep. Variable:                      y   No. Observations:                 5559
Model:                          Logit   Df Residuals:                     5558
Method:                           MLE   Df Model:                            0
Date:                Tue, 19 Jan 2021   Pseudo R-squ.:               -0.003242
Time:                        19:12:12   Log-Likelihood:                -3841.4
converged:                       True   LL-Null:                       -3828.9
Covariance Type:            nonrobust   LLR p-value:                       nan
==============================================================================
                 coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------
x1             0.1726      0.036      4.859      0.000       0.103       0.242
==============================================================================
Accuracy of using gender to predict hypertension with cutoff 0.5: 0.5466810577441986
Optimization terminated successfully.
         Current function value: 0.685427
         Iterations 3

===============Logistic regression between hypertension and Age===============
                           Logit Regression Results
==============================================================================
Dep. Variable:                      y   No. Observations:                 5559
Model:                          Logit   Df Residuals:                     5558
Method:                           MLE   Df Model:                            0
Date:                Tue, 19 Jan 2021   Pseudo R-squ.:                0.004871
Time:                        19:12:13   Log-Likelihood:                -3810.3
converged:                       True   LL-Null:                       -3828.9
Covariance Type:            nonrobust   LLR p-value:                       nan
==============================================================================
                 coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------
x1             0.0039      0.000      9.225      0.000       0.003       0.005
==============================================================================
Accuracy of using Age to predict hypertension with cutoff 0.5: 0.5466810577441986
Optimization terminated successfully.
         Current function value: 0.688106
         Iterations 3

===============Logistic regression between hypertension and IOP===============
                           Logit Regression Results
==============================================================================
Dep. Variable:                      y   No. Observations:                 5545
Model:                          Logit   Df Residuals:                     5544
Method:                           MLE   Df Model:                            0
Date:                Tue, 19 Jan 2021   Pseudo R-squ.:               0.0009994
Time:                        19:12:13   Log-Likelihood:                -3815.5
converged:                       True   LL-Null:                       -3819.4
Covariance Type:            nonrobust   LLR p-value:                       nan
==============================================================================
                 coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------
x1             0.0137      0.002      7.455      0.000       0.010       0.017
==============================================================================
Accuracy of using IOP to predict hypertension with cutoff 0.5: 0.5466185752930568
Optimization terminated successfully.
         Current function value: 0.689526
         Iterations 3

===============Logistic regression between hypertension and AxialLength===============
                           Logit Regression Results
==============================================================================
Dep. Variable:                      y   No. Observations:                 5238
Model:                          Logit   Df Residuals:                     5237
Method:                           MLE   Df Model:                            0
Date:                Tue, 19 Jan 2021   Pseudo R-squ.:              -0.0002020
Time:                        19:12:13   Log-Likelihood:                -3611.7
converged:                       True   LL-Null:                       -3611.0
Covariance Type:            nonrobust   LLR p-value:                       nan
==============================================================================
                 coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------
x1             0.0074      0.001      6.148      0.000       0.005       0.010
==============================================================================
Accuracy of using AxialLength to predict hypertension with cutoff 0.5: 0.5433371515845743
Optimization terminated successfully.
         Current function value: 0.688401
         Iterations 4

===============Logistic regression between hypertension and SmokePackYears===============
                           Logit Regression Results
==============================================================================
Dep. Variable:                      y   No. Observations:                 5408
Model:                          Logit   Df Residuals:                     5407
Method:                           MLE   Df Model:                            0
Date:                Tue, 19 Jan 2021   Pseudo R-squ.:               -0.001830
Time:                        19:12:13   Log-Likelihood:                -3722.9
converged:                       True   LL-Null:                       -3716.1
Covariance Type:            nonrobust   LLR p-value:                       nan
==============================================================================
                 coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------
x1             0.0937      0.013      7.024      0.000       0.068       0.120
==============================================================================
Accuracy of using SmokePackYears to predict hypertension with cutoff 0.5: 0.5547337278106509
Optimization terminated successfully.
         Current function value: 0.689190
         Iterations 3

===============Logistic regression between hypertension and Pulse===============
                           Logit Regression Results
==============================================================================
Dep. Variable:                      y   No. Observations:                 5557
Model:                          Logit   Df Residuals:                     5556
Method:                           MLE   Df Model:                            0
Date:                Tue, 19 Jan 2021   Pseudo R-squ.:              -0.0005476
Time:                        19:12:14   Log-Likelihood:                -3829.8
converged:                       True   LL-Null:                       -3827.7
Covariance Type:            nonrobust   LLR p-value:                       nan
==============================================================================
                 coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------
x1             0.0024      0.000      6.617      0.000       0.002       0.003
==============================================================================
Accuracy of using Pulse to predict hypertension with cutoff 0.5: 0.5465179053446104
Optimization terminated successfully.
         Current function value: 0.691870
         Iterations 4

===============Logistic regression between hypertension and Drink_quantity===============
                           Logit Regression Results
==============================================================================
Dep. Variable:                      y   No. Observations:                 5438
Model:                          Logit   Df Residuals:                     5437
Method:                           MLE   Df Model:                            0
Date:                Tue, 19 Jan 2021   Pseudo R-squ.:               -0.006841
Time:                        19:12:14   Log-Likelihood:                -3762.4
converged:                       True   LL-Null:                       -3736.8
Covariance Type:            nonrobust   LLR p-value:                       nan
==============================================================================
                 coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------
x1             0.0747      0.020      3.692      0.000       0.035       0.114
==============================================================================
Accuracy of using Drink_quantity to predict hypertension with cutoff 0.5: 0.5546156675248253
Optimization terminated successfully.
         Current function value: 0.684049
         Iterations 4

===============Logistic regression between hypertension and Glucose===============
                           Logit Regression Results
==============================================================================
Dep. Variable:                      y   No. Observations:                 4137
Model:                          Logit   Df Residuals:                     4136
Method:                           MLE   Df Model:                            0
Date:                Tue, 19 Jan 2021   Pseudo R-squ.:                0.003631
Time:                        19:12:14   Log-Likelihood:                -2829.9
converged:                       True   LL-Null:                       -2840.2
Covariance Type:            nonrobust   LLR p-value:                       nan
==============================================================================
                 coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------
x1             0.0464      0.005      8.617      0.000       0.036       0.057
==============================================================================
Accuracy of using Glucose to predict hypertension with cutoff 0.5: 0.5574087503021513
Optimization terminated successfully.
         Current function value: 0.687405
         Iterations 5

===============Logistic regression between hypertension and CRPL===============
                           Logit Regression Results
==============================================================================
Dep. Variable:                      y   No. Observations:                 4155
Model:                          Logit   Df Residuals:                     4154
Method:                           MLE   Df Model:                            0
Date:                Tue, 19 Jan 2021   Pseudo R-squ.:               -0.001583
Time:                        19:12:15   Log-Likelihood:                -2856.2
converged:                       True   LL-Null:                       -2851.7
Covariance Type:            nonrobust   LLR p-value:                       nan
==============================================================================
                 coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------
x1             0.0685      0.011      6.295      0.000       0.047       0.090
==============================================================================
Accuracy of using CRPL to predict hypertension with cutoff 0.5: 0.5583634175691937
Optimization terminated successfully.
         Current function value: 0.687147
         Iterations 4

===============Logistic regression between hypertension and Cholesterol===============
                           Logit Regression Results
==============================================================================
Dep. Variable:                      y   No. Observations:                 4137
Model:                          Logit   Df Residuals:                     4136
Method:                           MLE   Df Model:                            0
Date:                Tue, 19 Jan 2021   Pseudo R-squ.:              -0.0008831
Time:                        19:12:15   Log-Likelihood:                -2842.7
converged:                       True   LL-Null:                       -2840.2
Covariance Type:            nonrobust   LLR p-value:                       nan
==============================================================================
                 coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------
x1             0.0426      0.006      7.021      0.000       0.031       0.055
==============================================================================
Accuracy of using Cholesterol to predict hypertension with cutoff 0.5: 0.5574087503021513
Optimization terminated successfully.
         Current function value: 0.689229
         Iterations 4

===============Logistic regression between hypertension and HDL===============
                           Logit Regression Results
==============================================================================
Dep. Variable:                      y   No. Observations:                 4137
Model:                          Logit   Df Residuals:                     4136
Method:                           MLE   Df Model:                            0
Date:                Tue, 19 Jan 2021   Pseudo R-squ.:               -0.003915
Time:                        19:12:15   Log-Likelihood:                -2851.3
converged:                       True   LL-Null:                       -2840.2
Covariance Type:            nonrobust   LLR p-value:                       nan
==============================================================================
                 coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------
x1             0.1197      0.021      5.679      0.000       0.078       0.161
==============================================================================
Accuracy of using HDL to predict hypertension with cutoff 0.5: 0.5574087503021513
Optimization terminated successfully.
         Current function value: 0.687200
         Iterations 4

===============Logistic regression between hypertension and LDL===============
                           Logit Regression Results
==============================================================================
Dep. Variable:                      y   No. Observations:                 4137
Model:                          Logit   Df Residuals:                     4136
Method:                           MLE   Df Model:                            0
Date:                Tue, 19 Jan 2021   Pseudo R-squ.:              -0.0009593
Time:                        19:12:15   Log-Likelihood:                -2842.9
converged:                       True   LL-Null:                       -2840.2
Covariance Type:            nonrobust   LLR p-value:                       nan
==============================================================================
                 coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------
x1             0.0629      0.009      6.989      0.000       0.045       0.080
==============================================================================
Accuracy of using LDL to predict hypertension with cutoff 0.5: 0.5574087503021513
Optimization terminated successfully.
         Current function value: 0.682450
         Iterations 4

===============Logistic regression between hypertension and Triglyceride===============
                           Logit Regression Results
==============================================================================
Dep. Variable:                      y   No. Observations:                 4137
Model:                          Logit   Df Residuals:                     4136
Method:                           MLE   Df Model:                            0
Date:                Tue, 19 Jan 2021   Pseudo R-squ.:                0.005959
Time:                        19:12:16   Log-Likelihood:                -2823.3
converged:                       True   LL-Null:                       -2840.2
Covariance Type:            nonrobust   LLR p-value:                       nan
==============================================================================
                 coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------
x1             0.1514      0.017      9.134      0.000       0.119       0.184
==============================================================================
Accuracy of using Triglyceride to predict hypertension with cutoff 0.5: 0.5574087503021513
Optimization terminated successfully.
         Current function value: 0.685288
         Iterations 3

===============Logistic regression between hypertension and BMI===============
                           Logit Regression Results
==============================================================================
Dep. Variable:                      y   No. Observations:                 5557
Model:                          Logit   Df Residuals:                     5556
Method:                           MLE   Df Model:                            0
Date:                Tue, 19 Jan 2021   Pseudo R-squ.:                0.005117
Time:                        19:12:16   Log-Likelihood:                -3808.1
converged:                       True   LL-Null:                       -3827.7
Covariance Type:            nonrobust   LLR p-value:                       nan
==============================================================================
                 coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------
x1             0.0098      0.001      9.306      0.000       0.008       0.012
==============================================================================
Accuracy of using BMI to predict hypertension with cutoff 0.5: 0.5465179053446104
Optimization terminated successfully.
         Current function value: 0.687303
         Iterations 4

===============Logistic regression between hypertension and WaistHipRate===============
                           Logit Regression Results
==============================================================================
Dep. Variable:                      y   No. Observations:                 5557
Model:                          Logit   Df Residuals:                     5556
Method:                           MLE   Df Model:                            0
Date:                Tue, 19 Jan 2021   Pseudo R-squ.:                0.002193
Time:                        19:12:16   Log-Likelihood:                -3819.3
converged:                       True   LL-Null:                       -3827.7
Covariance Type:            nonrobust   LLR p-value:                       nan
==============================================================================
                 coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------
x1             0.2431      0.030      8.035      0.000       0.184       0.302
==============================================================================
Accuracy of using WaistHipRate to predict hypertension with cutoff 0.5: 0.5465179053446104
Optimization terminated successfully.
         Current function value: 0.685594
         Iterations 4

===============Logistic regression between hypertension and LDLoverHDL===============
                           Logit Regression Results
==============================================================================
Dep. Variable:                      y   No. Observations:                 4137
Model:                          Logit   Df Residuals:                     4136
Method:                           MLE   Df Model:                            0
Date:                Tue, 19 Jan 2021   Pseudo R-squ.:                0.001379
Time:                        19:12:16   Log-Likelihood:                -2836.3
converged:                       True   LL-Null:                       -2840.2
Covariance Type:            nonrobust   LLR p-value:                       nan
==============================================================================
                 coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------
x1             0.0922      0.012      7.859      0.000       0.069       0.115
==============================================================================
Accuracy of using LDLoverHDL to predict hypertension with cutoff 0.5: 0.5574087503021513


====Multivariable Logistic regression between clinical risk factors and hypertension ==========
After deleting empty-value patients, it remains 3804 patients.
Optimization terminated successfully.
         Current function value: 0.613759
         Iterations 5
                           Logit Regression Results
==============================================================================
Dep. Variable:                      y   No. Observations:                 3804
Model:                          Logit   Df Residuals:                     3790
Method:                           MLE   Df Model:                           13
Date:                Tue, 19 Jan 2021   Pseudo R-squ.:                  0.1040
Time:                        19:12:16   Log-Likelihood:                -2334.7
converged:                       True   LL-Null:                       -2605.6
Covariance Type:            nonrobust   LLR p-value:                1.980e-107
==============================================================================
                 coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------
x1            -0.0472      0.090     -0.522      0.602      -0.224       0.130
x2             0.0608      0.004     14.097      0.000       0.052       0.069
x3             0.0712      0.013      5.287      0.000       0.045       0.098
x4            -0.3194      0.024    -13.413      0.000      -0.366      -0.273
x5             0.0229      0.021      1.078      0.281      -0.019       0.065
x6            -0.0198      0.004     -5.552      0.000      -0.027      -0.013
x7             0.0372      0.033      1.126      0.260      -0.028       0.102
x8             0.0894      0.027      3.258      0.001       0.036       0.143
x9            -0.0033      0.011     -0.303      0.762      -0.025       0.018
x10           -0.1041      0.045     -2.289      0.022      -0.193      -0.015
x11            0.1331      0.036      3.699      0.000       0.063       0.204
x12            0.1416      0.012     12.256      0.000       0.119       0.164
x13            0.7815      0.565      1.384      0.166      -0.325       1.888
x14           -0.1217      0.052     -2.336      0.019      -0.224      -0.020
==============================================================================
Accuracy of using ['gender', 'Age', 'IOP', 'AxialLength', 'SmokePackYears', 'Pulse', 'Drink_quantity', 'Glucose', 'CRPL', 'Cholesterol', 'Triglyceride', 'BMI', 'WaistHipRate', 'LDLoverHDL']
 to predict hypertension with cutoff 0.5: 0.6561514195583596
With a different cut off:
{'threshold': 0.537, 'ACC': 0.656677181913775, 'TPR': 0.6955710955678529, 'TNR': 0.6063893911958627, 'Sum': 1.9586376686774905}
Where:
x1=gender; x2=Age; x3=IOP; x4=AxialLength; x5=SmokePackYears; x6=Pulse; x7=Drink_quantity; x8=Glucose; x9=CRPL; x10=Cholesterol; x11=Triglyceride; x12=BMI; x13=WaistHipRate; x14=LDLoverHDL;
=========================
list of x whose pvalue <=0.05
x2=Age, z=14.096921717188435, pvalue=3.966999793137572e-45
x3=IOP, z=5.286857743484339, pvalue=1.2443533288996497e-07
x4=AxialLength, z=-13.413135007273308, pvalue=5.065154183697109e-41
x6=Pulse, z=-5.551521739416451, pvalue=2.8319348958319192e-08
x8=Glucose, z=3.2581298337851825, pvalue=0.0011214908327010097
x10=Cholesterol, z=-2.288740215141951, pvalue=0.0220944509447221
x11=Triglyceride, z=3.6990793476487913, pvalue=0.00021638295043066667
x12=BMI, z=12.255963972141293, pvalue=1.5608220122516097e-34
x14=LDLoverHDL, z=-2.3358503378650624, pvalue=0.019499043033275744

Features of Pvalue> 0.05: gender, smoke, drink, CRPL, WaistHipRate.



# Jan 18th, Monday, 2021:
Deep learning model contains logistic regression model, so in theory, a neural network can do no worse than logistic regression.
In practice, a neural network model for binary classification can be worse than a logistic regression model
because neural networks are more difficult to train and are more prone to overfitting than logistic regression.

A deep learning model for hypertension with 9x9 sectors + 7 clinical features:
1 input: 9x9 thickness sectors + 7 clinical features;
2 FC layers: with batch normalization and ReLU at each layer, except at the final layer.
  Total observations in training data: 3171;
  88 -> 40->20-> 1: 89*40+41*20+21*1 = 4401 parameters
  observation/inputspace = 3171/88 = 36.0 > 30, good.
  Hui's estimation in deep learning:(here observation is the number of training samples)
  A observation/inputSpace > 10 or 30;
  B parameters/observation = 1~2  with considering data augmentation;
    4401/3171 = 1.39, good.


====Statistics patient number with non-empty clinical data ==========
Deleted empty values in ['gender', 'Age', 'IOP', 'AxialLength', 'SmokePackYears', 'BMI', 'WaistHipRate']
dataName,	#Original,	#Remaining
trainingData,	3600,	3171
validationData,	959,	934
testData,	    1000,	976
sum,            5559,   5081


3 loss: binary cross entropy loss;


# Jan 16th, Saturday, 2021:

Experiment: expOCT_9x9SectorsThicknessAnalyze_20210116_9x31x25

====== Use thickness only to predict hypertension =============
Input only thickness, it has 5559 patients.
Optimization terminated successfully.
         Current function value: 0.665056
         Iterations 7
                           Logit Regression Results
==============================================================================
Dep. Variable:                      y   No. Observations:                 5559
Model:                          Logit   Df Residuals:                     5478
Method:                           MLE   Df Model:                           80
Date:                Sat, 16 Jan 2021   Pseudo R-squ.:                 0.03445
Time:                        15:14:49   Log-Likelihood:                -3697.0
converged:                       True   LL-Null:                       -3828.9
Covariance Type:            nonrobust   LLR p-value:                 1.769e-21
==============================================================================
                 coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------
x1             0.0085      0.016      0.539      0.590      -0.022       0.039
x2            -0.0199      0.012     -1.595      0.111      -0.044       0.005
x3            -0.0208      0.013     -1.661      0.097      -0.045       0.004
x4             0.0234      0.015      1.587      0.112      -0.005       0.052
x5             0.0160      0.013      1.224      0.221      -0.010       0.042
x6             0.0051      0.008      0.648      0.517      -0.010       0.021
x7            -0.0006      0.008     -0.076      0.939      -0.016       0.014
x8             0.0037      0.008      0.452      0.651      -0.012       0.020
x9            -0.0013      0.009     -0.150      0.881      -0.019       0.016
x10           -0.0095      0.012     -0.791      0.429      -0.033       0.014
x11            0.0188      0.014      1.306      0.191      -0.009       0.047
x12           -0.0116      0.014     -0.860      0.390      -0.038       0.015
x13           -0.0049      0.015     -0.329      0.742      -0.034       0.024
x14           -0.0015      0.013     -0.116      0.907      -0.026       0.023
x15           -0.0093      0.016     -0.572      0.567      -0.041       0.022
x16            0.0408      0.021      1.915      0.056      -0.001       0.082
x17           -0.0302      0.019     -1.594      0.111      -0.067       0.007
x18           -0.0137      0.019     -0.739      0.460      -0.050       0.023
x19            0.0045      0.015      0.295      0.768      -0.026       0.035
x20           -0.0149      0.017     -0.883      0.377      -0.048       0.018
x21           -0.0224      0.018     -1.224      0.221      -0.058       0.013
x22           -0.0049      0.018     -0.275      0.783      -0.040       0.030
x23            0.0120      0.018      0.652      0.514      -0.024       0.048
x24            0.0267      0.018      1.456      0.145      -0.009       0.063
x25            0.0490      0.030      1.641      0.101      -0.010       0.107
x26            0.0077      0.019      0.411      0.681      -0.029       0.044
x27           -0.0142      0.027     -0.535      0.592      -0.066       0.038
x28           -0.0184      0.027     -0.678      0.498      -0.072       0.035
x29            0.0200      0.032      0.633      0.527      -0.042       0.082
x30            0.0087      0.033      0.261      0.794      -0.057       0.074
x31            0.0218      0.040      0.544      0.587      -0.057       0.100
x32           -0.0494      0.037     -1.341      0.180      -0.122       0.023
x33           -0.0368      0.036     -1.025      0.305      -0.107       0.034
x34           -0.1164      0.047     -2.494      0.013      -0.208      -0.025
x35            0.0070      0.044      0.158      0.874      -0.079       0.093
x36            0.0716      0.049      1.458      0.145      -0.025       0.168
x37            0.0062      0.015      0.405      0.685      -0.024       0.036
x38            0.0234      0.019      1.257      0.209      -0.013       0.060
x39           -0.0316      0.017     -1.850      0.064      -0.065       0.002
x40            0.0310      0.023      1.323      0.186      -0.015       0.077
x41           -0.0348      0.019     -1.810      0.070      -0.072       0.003
x42           -0.0025      0.027     -0.091      0.928      -0.056       0.051
x43            0.0544      0.028      1.940      0.052      -0.001       0.109
x44            0.0311      0.032      0.983      0.326      -0.031       0.093
x45            0.0140      0.030      0.468      0.640      -0.045       0.072
x46            0.0007      0.008      0.082      0.935      -0.016       0.017
x47            0.0217      0.015      1.448      0.148      -0.008       0.051
x48           -0.0191      0.014     -1.361      0.173      -0.047       0.008
x49            0.0425      0.016      2.727      0.006       0.012       0.073
x50            0.0083      0.016      0.533      0.594      -0.022       0.039
x51           -0.0284      0.017     -1.706      0.088      -0.061       0.004
x52            0.0247      0.017      1.438      0.150      -0.009       0.058
x53           -0.0209      0.016     -1.342      0.180      -0.051       0.010
x54           -0.0374      0.018     -2.111      0.035      -0.072      -0.003
x55            0.0674      0.035      1.904      0.057      -0.002       0.137
x56           -0.0353      0.032     -1.108      0.268      -0.098       0.027
x57           -0.0481      0.038     -1.265      0.206      -0.123       0.026
x58           -0.1144      0.058     -1.956      0.050      -0.229       0.000
x59            0.1334      0.060      2.242      0.025       0.017       0.250
x60            0.0076      0.018      0.423      0.672      -0.028       0.043
x61           -0.1519      0.044     -3.451      0.001      -0.238      -0.066
x62            0.0130      0.050      0.262      0.794      -0.085       0.111
x63            0.1348      0.060      2.237      0.025       0.017       0.253
x64            0.0120      0.023      0.512      0.608      -0.034       0.058
x65           -0.0169      0.036     -0.473      0.636      -0.087       0.053
x66           -0.0432      0.036     -1.187      0.235      -0.114       0.028
x67           -0.0017      0.030     -0.056      0.955      -0.060       0.056
x68           -0.0664      0.043     -1.529      0.126      -0.151       0.019
x69            0.0236      0.033      0.708      0.479      -0.042       0.089
x70           -0.0962      0.038     -2.551      0.011      -0.170      -0.022
x71            0.0073      0.035      0.207      0.836      -0.061       0.076
x72            0.1282      0.044      2.892      0.004       0.041       0.215
x73            0.1567      0.046      3.404      0.001       0.066       0.247
x74           -0.1033      0.056     -1.861      0.063      -0.212       0.006
x75           -0.0488      0.063     -0.776      0.438      -0.172       0.074
x76           -0.0840      0.058     -1.461      0.144      -0.197       0.029
x77            0.0161      0.071      0.226      0.821      -0.124       0.156
x78           -0.0095      0.063     -0.150      0.881      -0.133       0.114
x79           -0.0415      0.075     -0.554      0.580      -0.189       0.105
x80           -0.0282      0.060     -0.467      0.640      -0.146       0.090
x81            0.1711      0.075      2.273      0.023       0.024       0.319
==============================================================================
thickness only: accuracy with cutoff 0.5:0.5876956287101996
With a different cut off:
{'threshold': 0.529, 'ACC': 0.5921928404389278, 'TPR': 0.6071076011826025, 'TNR': 0.5742063492040707, 'Sum': 1.7735067908256013}
Where:
x1=sector[0,0]; x2=sector[0,1]; x3=sector[0,2]; x4=sector[0,3]; x5=sector[0,4]; x6=sector[0,5]; x7=sector[0,6]; x8=sector[0,7]; x9=sector[0,8];
x10=sector[1,0]; x11=sector[1,1]; x12=sector[1,2]; x13=sector[1,3]; x14=sector[1,4]; x15=sector[1,5]; x16=sector[1,6]; x17=sector[1,7]; x18=sector[1,8];
x19=sector[2,0]; x20=sector[2,1]; x21=sector[2,2]; x22=sector[2,3]; x23=sector[2,4]; x24=sector[2,5]; x25=sector[2,6]; x26=sector[2,7]; x27=sector[2,8];
x28=sector[3,0]; x29=sector[3,1]; x30=sector[3,2]; x31=sector[3,3]; x32=sector[3,4]; x33=sector[3,5]; x34=sector[3,6]; x35=sector[3,7]; x36=sector[3,8];
x37=sector[4,0]; x38=sector[4,1]; x39=sector[4,2]; x40=sector[4,3]; x41=sector[4,4]; x42=sector[4,5]; x43=sector[4,6]; x44=sector[4,7]; x45=sector[4,8];
x46=sector[5,0]; x47=sector[5,1]; x48=sector[5,2]; x49=sector[5,3]; x50=sector[5,4]; x51=sector[5,5]; x52=sector[5,6]; x53=sector[5,7]; x54=sector[5,8];
x55=sector[6,0]; x56=sector[6,1]; x57=sector[6,2]; x58=sector[6,3]; x59=sector[6,4]; x60=sector[6,5]; x61=sector[6,6]; x62=sector[6,7]; x63=sector[6,8];
x64=sector[7,0]; x65=sector[7,1]; x66=sector[7,2]; x67=sector[7,3]; x68=sector[7,4]; x69=sector[7,5]; x70=sector[7,6]; x71=sector[7,7]; x72=sector[7,8];
x73=sector[8,0]; x74=sector[8,1]; x75=sector[8,2]; x76=sector[8,3]; x77=sector[8,4]; x78=sector[8,5]; x79=sector[8,6]; x80=sector[8,7]; x81=sector[8,8];
=========================
list of x whose pvalues <=0.05
x34=sector[3,6], z=-2.4944366926568495, pvalue=0.012615722859644928
x49=sector[5,3], z=2.726730293656933, pvalue=0.006396529905683237
x54=sector[5,8], z=-2.111447339359526, pvalue=0.034733879745456483
x59=sector[6,4], z=2.2416662122883335, pvalue=0.02498295314877563
x61=sector[6,6], z=-3.451310154541705, pvalue=0.0005578720758859236
x63=sector[6,8], z=2.236593406023042, pvalue=0.025312926285495262
x70=sector[7,6], z=-2.5509993054321343, pvalue=0.010741453987966542
x72=sector[7,8], z=2.892256663207349, pvalue=0.0038248534191215205
x73=sector[8,0], z=3.404392990635457, pvalue=0.0006631127615927072
x81=sector[8,8], z=2.273093416442748, pvalue=0.023020551088510827

====Use 9x9 sector thickness and clinical features to predict Hypertension ==========
After deleting empty-value patients, it remains 5081 patients.
Optimization terminated successfully.
         Current function value: 0.602415
         Iterations 7
                           Logit Regression Results
==============================================================================
Dep. Variable:                      y   No. Observations:                 5081
Model:                          Logit   Df Residuals:                     4993
Method:                           MLE   Df Model:                           87
Date:                Sat, 16 Jan 2021   Pseudo R-squ.:                  0.1242
Time:                        15:14:52   Log-Likelihood:                -3060.9
converged:                       True   LL-Null:                       -3495.1
Covariance Type:            nonrobust   LLR p-value:                3.912e-129
==============================================================================
                 coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------
x1             0.0145      0.019      0.777      0.437      -0.022       0.051
x2            -0.0174      0.018     -0.994      0.320      -0.052       0.017
x3            -0.0293      0.015     -2.007      0.045      -0.058      -0.001
x4             0.0463      0.018      2.620      0.009       0.012       0.081
x5             0.0139      0.015      0.915      0.360      -0.016       0.044
x6             0.0133      0.009      1.413      0.158      -0.005       0.032
x7             0.0024      0.009      0.270      0.787      -0.015       0.020
x8            -0.0219      0.013     -1.723      0.085      -0.047       0.003
x9             0.0085      0.010      0.839      0.402      -0.011       0.029
x10            0.0080      0.014      0.588      0.557      -0.019       0.035
x11            0.0315      0.016      1.972      0.049       0.000       0.063
x12           -0.0056      0.015     -0.367      0.714      -0.036       0.024
x13           -0.0225      0.017     -1.335      0.182      -0.056       0.011
x14        -4.316e-05      0.014     -0.003      0.998      -0.028       0.028
x15           -0.0178      0.018     -0.969      0.333      -0.054       0.018
x16            0.0096      0.025      0.386      0.699      -0.039       0.059
x17           -0.0286      0.022     -1.317      0.188      -0.071       0.014
x18           -0.0157      0.021     -0.762      0.446      -0.056       0.025
x19            0.0109      0.018      0.619      0.536      -0.024       0.045
x20           -0.0024      0.019     -0.126      0.900      -0.040       0.035
x21            0.0034      0.021      0.162      0.872      -0.038       0.044
x22           -0.0117      0.020     -0.581      0.561      -0.051       0.028
x23            0.0098      0.021      0.470      0.638      -0.031       0.051
x24           -0.0021      0.021     -0.103      0.918      -0.043       0.038
x25            0.0325      0.034      0.948      0.343      -0.035       0.100
x26           -0.0108      0.022     -0.494      0.621      -0.053       0.032
x27            0.0041      0.030      0.137      0.891      -0.054       0.062
x28           -0.0654      0.032     -2.059      0.039      -0.128      -0.003
x29            0.0134      0.035      0.378      0.705      -0.056       0.083
x30           -0.0234      0.040     -0.583      0.560      -0.102       0.055
x31            0.0804      0.046      1.753      0.080      -0.009       0.170
x32           -0.0155      0.042     -0.374      0.708      -0.097       0.066
x33            0.0154      0.040      0.382      0.702      -0.063       0.094
x34           -0.0771      0.054     -1.429      0.153      -0.183       0.029
x35           -0.0106      0.052     -0.202      0.840      -0.113       0.092
x36            0.0229      0.055      0.417      0.677      -0.085       0.131
x37            0.0142      0.018      0.813      0.416      -0.020       0.049
x38            0.0039      0.021      0.185      0.853      -0.038       0.046
x39           -0.0082      0.021     -0.396      0.692      -0.049       0.033
x40            0.0021      0.025      0.087      0.931      -0.046       0.050
x41           -0.0088      0.024     -0.372      0.710      -0.055       0.038
x42           -0.0020      0.031     -0.064      0.949      -0.063       0.059
x43            0.0171      0.032      0.531      0.595      -0.046       0.080
x44            0.0349      0.035      1.007      0.314      -0.033       0.103
x45            0.0070      0.035      0.196      0.844      -0.063       0.076
x46           -0.0053      0.009     -0.564      0.573      -0.024       0.013
x47            0.0066      0.017      0.397      0.691      -0.026       0.039
x48           -0.0232      0.017     -1.338      0.181      -0.057       0.011
x49            0.0379      0.019      2.002      0.045       0.001       0.075
x50            0.0176      0.019      0.940      0.347      -0.019       0.054
x51           -0.0217      0.017     -1.245      0.213      -0.056       0.012
x52            0.0405      0.020      1.995      0.046       0.001       0.080
x53           -0.0245      0.021     -1.141      0.254      -0.067       0.018
x54           -0.0342      0.021     -1.622      0.105      -0.076       0.007
x55            0.0125      0.039      0.315      0.752      -0.065       0.090
x56           -0.0745      0.039     -1.902      0.057      -0.151       0.002
x57           -0.0180      0.042     -0.424      0.672      -0.101       0.065
x58           -0.0617      0.064     -0.968      0.333      -0.187       0.063
x59            0.0258      0.061      0.421      0.674      -0.094       0.146
x60            0.0124      0.018      0.704      0.481      -0.022       0.047
x61           -0.1183      0.049     -2.412      0.016      -0.214      -0.022
x62            0.0568      0.058      0.976      0.329      -0.057       0.171
x63            0.0580      0.068      0.850      0.395      -0.076       0.192
x64            0.0506      0.027      1.901      0.057      -0.002       0.103
x65           -0.0361      0.041     -0.883      0.377      -0.116       0.044
x66           -0.0614      0.045     -1.367      0.172      -0.149       0.027
x67            0.0074      0.033      0.221      0.825      -0.058       0.073
x68           -0.1134      0.049     -2.332      0.020      -0.209      -0.018
x69            0.0406      0.037      1.105      0.269      -0.031       0.113
x70           -0.0857      0.042     -2.020      0.043      -0.169      -0.003
x71            0.0006      0.042      0.015      0.988      -0.081       0.082
x72            0.1638      0.051      3.199      0.001       0.063       0.264
x73            0.0349      0.053      0.661      0.508      -0.068       0.138
x74           -0.0406      0.064     -0.633      0.526      -0.166       0.085
x75           -0.1427      0.077     -1.857      0.063      -0.293       0.008
x76            0.0545      0.069      0.786      0.432      -0.082       0.191
x77           -0.0649      0.080     -0.806      0.420      -0.223       0.093
x78           -0.0394      0.071     -0.557      0.578      -0.178       0.099
x79           -0.0238      0.086     -0.277      0.781      -0.192       0.144
x80           -0.1494      0.075     -1.997      0.046      -0.296      -0.003
x81            0.2220      0.086      2.581      0.010       0.053       0.391
x82            0.0333      0.083      0.399      0.690      -0.130       0.197
x83            0.0673      0.005     14.251      0.000       0.058       0.077
x84            0.0644      0.012      5.448      0.000       0.041       0.088
x85           -0.2201      0.041     -5.420      0.000      -0.300      -0.141
x86            0.0587      0.019      3.046      0.002       0.021       0.096
x87            0.1490      0.011     14.123      0.000       0.128       0.170
x88            1.9596      0.572      3.423      0.001       0.838       3.082
==============================================================================
9x9 sector thickness+7clinicalFeatures: accuracy  with cutoff 0.5:0.6725054123204094
With a different cut off:
{'threshold': 0.513, 'ACC': 0.6756543987404054, 'TPR': 0.7229560871091648, 'TNR': 0.6175438596464143, 'Sum': 2.0161543454959845}
Where:
x1=sector[0,0]; x2=sector[0,1]; x3=sector[0,2]; x4=sector[0,3]; x5=sector[0,4]; x6=sector[0,5]; x7=sector[0,6]; x8=sector[0,7]; x9=sector[0,8];
x10=sector[1,0]; x11=sector[1,1]; x12=sector[1,2]; x13=sector[1,3]; x14=sector[1,4]; x15=sector[1,5]; x16=sector[1,6]; x17=sector[1,7]; x18=sector[1,8];
x19=sector[2,0]; x20=sector[2,1]; x21=sector[2,2]; x22=sector[2,3]; x23=sector[2,4]; x24=sector[2,5]; x25=sector[2,6]; x26=sector[2,7]; x27=sector[2,8];
x28=sector[3,0]; x29=sector[3,1]; x30=sector[3,2]; x31=sector[3,3]; x32=sector[3,4]; x33=sector[3,5]; x34=sector[3,6]; x35=sector[3,7]; x36=sector[3,8];
x37=sector[4,0]; x38=sector[4,1]; x39=sector[4,2]; x40=sector[4,3]; x41=sector[4,4]; x42=sector[4,5]; x43=sector[4,6]; x44=sector[4,7]; x45=sector[4,8];
x46=sector[5,0]; x47=sector[5,1]; x48=sector[5,2]; x49=sector[5,3]; x50=sector[5,4]; x51=sector[5,5]; x52=sector[5,6]; x53=sector[5,7]; x54=sector[5,8];
x55=sector[6,0]; x56=sector[6,1]; x57=sector[6,2]; x58=sector[6,3]; x59=sector[6,4]; x60=sector[6,5]; x61=sector[6,6]; x62=sector[6,7]; x63=sector[6,8];
x64=sector[7,0]; x65=sector[7,1]; x66=sector[7,2]; x67=sector[7,3]; x68=sector[7,4]; x69=sector[7,5]; x70=sector[7,6]; x71=sector[7,7]; x72=sector[7,8];
x73=sector[8,0]; x74=sector[8,1]; x75=sector[8,2]; x76=sector[8,3]; x77=sector[8,4]; x78=sector[8,5]; x79=sector[8,6]; x80=sector[8,7]; x81=sector[8,8];
x82=gender; x83=Age; x84=IOP; x85=AxialLength; x86=SmokePackYears; x87=BMI; x88=WaistHipRate;
=========================
list of x whose pvalues <=0.05
x3=sector[0,2], z=-2.0071436249480525, pvalue=0.04473437227359201
x4=sector[0,3], z=2.6195735683188586, pvalue=0.008803978062427985
x11=sector[1,1], z=1.9715038295188991, pvalue=0.04866627541232191
x28=sector[3,0], z=-2.0592273235333054, pvalue=0.03947246684357818
x49=sector[5,3], z=2.0024277365817835, pvalue=0.045238747870388306
x52=sector[5,6], z=1.9949538755865384, pvalue=0.04604791069209327
x61=sector[6,6], z=-2.4122352705570256, pvalue=0.01585504677466387
x68=sector[7,4], z=-2.332242129391916, pvalue=0.019687957019112277
x70=sector[7,6], z=-2.020140554948887, pvalue=0.04336881024010007
x72=sector[7,8], z=3.199156196627409, pvalue=0.0013783047155136187
x80=sector[8,7], z=-1.9973296848199524, pvalue=0.045789380693936656
x81=sector[8,8], z=2.5807120582160668, pvalue=0.009859678077958234
x83=Age, z=14.251441623315257, pvalue=4.391216394236136e-46
x84=IOP, z=5.447802129633193, pvalue=5.0996043854560006e-08
x85=AxialLength, z=-5.420244622280784, pvalue=5.9517537977543504e-08
x86=SmokePackYears, z=3.0459276176712073, pvalue=0.0023196366973009114
x87=BMI, z=14.122733787368833, pvalue=2.751083375752029e-45
x88=WaistHipRate, z=3.4232088140207657, pvalue=0.0006188651689663687

excluding feature of pvalue>0.05: gender.

(base) [c-xwu000:testResult]#



# Jan 15th, Friday, 2021
Meeting with professor:
1  use surface and layer information to infer the thickness;
2  use red/blue to mark individual hypertension or not;
3  use color to mark the number of patient in univariable figure;
4  use random forest to analyze hypertension;
5  use 9 layerx9sector + risk factor to predict hypertension;
6  use radiomics to select features, with logistic method;



# Jan 14th, Thursday, 2021
cat output_20210114_120327.txt
Experiment: expOCT_9Sectors5thThicknessAnalyze_20210114_MultiVariable_statsmodels_1x31x25

====== Use thickness only to predict hypertension =============
Input only thickness, it has 5559 patients.
Optimization terminated successfully.
         Current function value: 0.686688
         Iterations 5
                           Logit Regression Results
==============================================================================
Dep. Variable:                      y   No. Observations:                 5559
Model:                          Logit   Df Residuals:                     5550
Method:                           MLE   Df Model:                            8
Date:                Thu, 14 Jan 2021   Pseudo R-squ.:                0.003040
Time:                        12:03:28   Log-Likelihood:                -3817.3
converged:                       True   LL-Null:                       -3828.9
Covariance Type:            nonrobust   LLR p-value:                  0.003020
==============================================================================
                 coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------
x1             0.0088      0.005      1.658      0.097      -0.002       0.019
x2            -0.0180      0.008     -2.394      0.017      -0.033      -0.003
x3            -0.0059      0.008     -0.713      0.476      -0.022       0.010
x4             0.0246      0.010      2.531      0.011       0.006       0.044
x5             0.0054      0.009      0.575      0.565      -0.013       0.024
x6             0.0185      0.008      2.238      0.025       0.002       0.035
x7            -0.0036      0.011     -0.326      0.744      -0.025       0.018
x8            -0.0049      0.010     -0.485      0.628      -0.024       0.015
x9            -0.0275      0.011     -2.467      0.014      -0.049      -0.006
==============================================================================
thickness only: accuracy:0.5429033998920669
Where:
x1=sector0; x2=sector1; x3=sector2; x4=sector3; x5=sector4; x6=sector5; x7=sector6; x8=sector7; x9=sector8;

====Use thickness and clinical features to predict==========
After deleting empty-value patients, it remains 5081 patients.
Optimization terminated successfully.
         Current function value: 0.616761
         Iterations 5
                           Logit Regression Results
==============================================================================
Dep. Variable:                      y   No. Observations:                 5081
Model:                          Logit   Df Residuals:                     5065
Method:                           MLE   Df Model:                           15
Date:                Thu, 14 Jan 2021   Pseudo R-squ.:                  0.1034
Time:                        12:03:28   Log-Likelihood:                -3133.8
converged:                       True   LL-Null:                       -3495.1
Covariance Type:            nonrobust   LLR p-value:                2.662e-144
==============================================================================
                 coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------
x1            -0.0011      0.006     -0.172      0.864      -0.013       0.011
x2            -0.0083      0.009     -0.952      0.341      -0.025       0.009
x3            -0.0075      0.010     -0.778      0.436      -0.026       0.011
x4             0.0131      0.012      1.073      0.283      -0.011       0.037
x5             0.0138      0.012      1.188      0.235      -0.009       0.037
x6             0.0088      0.008      1.052      0.293      -0.008       0.025
x7             0.0002      0.013      0.018      0.986      -0.024       0.025
x8            -0.0103      0.014     -0.749      0.454      -0.037       0.017
x9            -0.0328      0.013     -2.447      0.014      -0.059      -0.007
x10           -0.0916      0.070     -1.310      0.190      -0.229       0.045
x11            0.0576      0.004     15.962      0.000       0.051       0.065
x12            0.0565      0.011      4.924      0.000       0.034       0.079
x13           -0.3193      0.022    -14.840      0.000      -0.361      -0.277
x14            0.0571      0.018      3.093      0.002       0.021       0.093
x15            0.1440      0.010     14.350      0.000       0.124       0.164
x16            1.1652      0.507      2.296      0.022       0.171       2.160
==============================================================================
thickness+7clinicalFeatures: accuracy:0.6642393229679197
Where:
x1=sector0; x2=sector1; x3=sector2; x4=sector3; x5=sector4; x6=sector5; x7=sector6; x8=sector7; x9=sector8;
x10=gender; x11=Age; x12=IOP; x13=AxialLength; x14=SmokePackYears; x15=BMI; x16=WaistHipRate;

====Use sector8_Age_Age_IOP_AxialLength_Smoke_BMI_WaistHipRate to predict Hypertension ==========
After deleting empty-value patients, it remains 5081 patients.
Optimization terminated successfully.
         Current function value: 0.617685
         Iterations 5
                           Logit Regression Results
==============================================================================
Dep. Variable:                      y   No. Observations:                 5081
Model:                          Logit   Df Residuals:                     5074
Method:                           MLE   Df Model:                            6
Date:                Thu, 14 Jan 2021   Pseudo R-squ.:                  0.1020
Time:                        12:03:28   Log-Likelihood:                -3138.5
converged:                       True   LL-Null:                       -3495.1
Covariance Type:            nonrobust   LLR p-value:                8.089e-151
==============================================================================
                 coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------
x1            -0.0226      0.004     -5.715      0.000      -0.030      -0.015
x2             0.0576      0.004     16.112      0.000       0.051       0.065
x3             0.0558      0.011      4.878      0.000       0.033       0.078
x4            -0.3192      0.021    -15.266      0.000      -0.360      -0.278
x5             0.0657      0.017      3.973      0.000       0.033       0.098
x6             0.1413      0.010     14.355      0.000       0.122       0.161
x7             1.2187      0.501      2.431      0.015       0.236       2.201
==============================================================================
sector8+6clinicalFeatures: accuracy:0.6603030899429246
Where:
x1=sector8;
x2=Age; x3=IOP; x4=AxialLength; x5=SmokePackYears; x6=BMI; x7=WaistHipRate;




# Jan 12th, Tuesday, 2021

Experiment: expOCT_9Sectors5thThicknessAnalyze_20210112_1x31x25

Linear Regression between sector thickness and continuous data:
===============================================================

sector0_Age_5thThickness slope:-0.3261565808691843; r-value:-0.2943420826338276; P-value:1.611423996388955e-111;
sector0_IOP_5thThickness slope:0.16435550891085854; r-value:0.0428901704583285; P-value:0.0014004610112642185;
sector0_AxialLength_5thThickness slope:-1.7816428944285794; r-value:-0.16584280519773037; P-value:1.2892977314991688e-33;
sector0_SmokePackYears_5thThickness slope:0.5073775101341896; r-value:0.09164690702882196; P-value:1.4553255755808134e-11;
sector0_BMI_5thThickness slope:0.12497200883729431; r-value:0.04550610506472739; P-value:0.0006906595857870511;
sector0_WaistHipRate_5thThickness slope:0.28046105618625233; r-value:0.0018566957812447282; P-value:0.8899228627501018;

sector1_Age_5thThickness slope:-0.37518687011204255; r-value:-0.3069939525119401; P-value:1.2461839539594972e-121;
sector1_IOP_5thThickness slope:0.2041050292277695; r-value:0.04829840807383431; P-value:0.0003208980130874705;
sector1_AxialLength_5thThickness slope:-2.0341869390752265; r-value:-0.17126760312604378; P-value:9.046374714192415e-36;
sector1_SmokePackYears_5thThickness slope:0.7235181197219214; r-value:0.11818131452094417; P-value:2.7940709298515512e-18;
sector1_BMI_5thThickness slope:0.15201001537384934; r-value:0.05018051215239561; P-value:0.00018238952454193455;
sector1_WaistHipRate_5thThickness slope:2.427143374897339; r-value:0.014568659498002727; P-value:0.2774640849438226;

sector2_Age_5thThickness slope:-0.27816945978707136; r-value:-0.2705066701460617; P-value:7.962411669854728e-94;
sector2_IOP_5thThickness slope:0.1832211056644643; r-value:0.05149819272494509; P-value:0.00012480959830028765;
sector2_AxialLength_5thThickness slope:-1.5600473395471461; r-value:-0.1552786275852084; P-value:1.2525481730797941e-29;
sector2_SmokePackYears_5thThickness slope:0.4890793645395435; r-value:0.0956051195421684; P-value:1.8515270640916213e-12;
sector2_BMI_5thThickness slope:0.12484496351008102; r-value:0.048978361264479756; P-value:0.0002597231498122327;
sector2_WaistHipRate_5thThickness slope:0.3592236765286843; r-value:0.0025625683469157174; P-value:0.8485106166131244;

sector3_Age_5thThickness slope:-0.2205984939279367; r-value:-0.24985433199315243; P-value:7.023531102720918e-80;
sector3_IOP_5thThickness slope:0.18887754945525156; r-value:0.06186627768767918; P-value:4.0221396589249274e-06;
sector3_AxialLength_5thThickness slope:-1.1854359006265622; r-value:-0.1373777283017713; P-value:1.7272574296585292e-23;
sector3_SmokePackYears_5thThickness slope:0.39579152438224535; r-value:0.08987476445525691; P-value:3.563321613986417e-11;
sector3_BMI_5thThickness slope:0.06157180466294506; r-value:0.0281351364939724; P-value:0.03596833804605802;
sector3_WaistHipRate_5thThickness slope:0.1184746027721558; r-value:0.000984354598607574; P-value:0.9415071429549482;

sector4_Age_5thThickness slope:-0.31334490236363116; r-value:-0.33514427224923216; P-value:5.393491062350524e-146;
sector4_IOP_5thThickness slope:0.21491204348277873; r-value:0.06644502959183847; P-value:7.339025795702681e-07;
sector4_AxialLength_5thThickness slope:-1.5864549993623556; r-value:-0.17426067228146006; P-value:5.45768416808251e-37;
sector4_SmokePackYears_5thThickness slope:0.5026627897688202; r-value:0.10744736597703741; P-value:2.3240560011838085e-15;
sector4_BMI_5thThickness slope:0.09728651288488155; r-value:0.04198104473708251; P-value:0.001747081751241653;
sector4_WaistHipRate_5thThickness slope:-0.6918929289108093; r-value:-0.005428627377709029; P-value:0.6857249718411373;

sector5_Age_5thThickness slope:-0.27235722431577686; r-value:-0.2753603813442868; P-value:2.7473209508665303e-97;
sector5_IOP_5thThickness slope:0.1848077016869904; r-value:0.053999773358802995; P-value:5.743494909501438e-05;
sector5_AxialLength_5thThickness slope:-1.587985694886937; r-value:-0.1626981822477493; P-value:2.1173532934981907e-32;
sector5_SmokePackYears_5thThickness slope:0.504844841223379; r-value:0.10186456264398873; P-value:5.965568926429872e-14;
sector5_BMI_5thThickness slope:0.0650345523587726; r-value:0.026524980022737475; P-value:0.04801729752107605;
sector5_WaistHipRate_5thThickness slope:1.0612717605559308; r-value:0.007871022173672568; P-value:0.5573848489972113;

sector6_Age_5thThickness slope:-0.21093456180082878; r-value:-0.2819469794315784; P-value:4.2293793730788936e-102;
sector6_IOP_5thThickness slope:0.19303300933432793; r-value:0.07457420902297024; P-value:2.7033045794647423e-08;
sector6_AxialLength_5thThickness slope:-1.1223661086405534; r-value:-0.1526641543341305; P-value:1.1032629281158848e-28;
sector6_SmokePackYears_5thThickness slope:0.36781646343988594; r-value:0.09860391306956673; P-value:3.6679148921055594e-13;
sector6_BMI_5thThickness slope:0.037642390068491405; r-value:0.02029807434816214; P-value:0.13029457974091513;
sector6_WaistHipRate_5thThickness slope:-1.095419087889482; r-value:-0.010740932274067375; P-value:0.4233209971231843;

sector7_Age_5thThickness slope:-0.1837392648212562; r-value:-0.2382376151466091; P-value:1.388807963439743e-72;
sector7_IOP_5thThickness slope:0.16667452376604244; r-value:0.06246670995056659; P-value:3.238768997241621e-06;
sector7_AxialLength_5thThickness slope:-1.1711114546061063; r-value:-0.15732926652830165; P-value:2.2134551096619903e-30;
sector7_SmokePackYears_5thThickness slope:0.4074178758092756; r-value:0.1071116222343028; P-value:2.8386619127610356e-15;
sector7_BMI_5thThickness slope:0.020714214592586544; r-value:0.010835252318306631; P-value:0.4193444954463099;
sector7_WaistHipRate_5thThickness slope:0.3958346678442876; r-value:0.003764992878607489; P-value:0.7789782118503191;

sector8_Age_5thThickness slope:-0.2585116699690476; r-value:-0.33717432268462816; P-value:7.455869021279305e-148;
sector8_IOP_5thThickness slope:0.19702963459860434; r-value:0.07427133428573097; P-value:3.0769964783208815e-08;
sector8_AxialLength_5thThickness slope:-1.4061855818614597; r-value:-0.1866614976069694; P-value:2.7998919803675225e-42;
sector8_SmokePackYears_5thThickness slope:0.4567297676674977; r-value:0.11916567567281679; P-value:1.4606373887501718e-18;
sector8_BMI_5thThickness slope:0.03381306233894026; r-value:0.017791773428260854; P-value:0.1848067536724216;
sector8_WaistHipRate_5thThickness slope:-1.2949277412561282; r-value:-0.01238973016869539; P-value:0.35569987291367366;

Logistic Regression between sector thickness and binary data:
=================================================================

sector0_hypertension_5thThickness score:0.5465011692750494; coef:[-0.01208659]; intercept:1.3390994639177545;
sector0_gender_5thThickness score:0.5903939557474366; coef:[-0.02972402]; intercept:3.1389545880122074;

sector1_hypertension_5thThickness score:0.5493793847814356; coef:[-0.01346942]; intercept:1.2524564639562843;
sector1_gender_5thThickness score:0.5941716135995683; coef:[-0.02829829]; intercept:2.544558314263178;

sector2_hypertension_5thThickness score:0.5535168195718655; coef:[-0.0148614]; intercept:1.2941070746117176;
sector2_gender_5thThickness score:0.5853570786112611; coef:[-0.03146398]; intercept:2.6485849302412494;

sector3_hypertension_5thThickness score:0.5465011692750494; coef:[-0.01346022]; intercept:1.2918561148971162;
sector3_gender_5thThickness score:0.5882352941176471; coef:[-0.03331612]; intercept:3.038827900424826;

sector4_hypertension_5thThickness score:0.5470408346824969; coef:[-0.01706841]; intercept:1.547670736081914;
sector4_gender_5thThickness score:0.5813995322899802; coef:[-0.02575523]; intercept:2.3563285991509937;

sector5_hypertension_5thThickness score:0.5540564849793128; coef:[-0.01711062]; intercept:1.3337489623878853;
sector5_gender_5thThickness score:0.5885950710559453; coef:[-0.03113691]; intercept:2.3898290930326382;

sector6_hypertension_5thThickness score:0.5560352581399532; coef:[-0.02428197]; intercept:1.6928313428877029;
sector6_gender_5thThickness score:0.5878755171793488; coef:[-0.03779509]; intercept:2.647225917053261;

sector7_hypertension_5thThickness score:0.5509983810037776; coef:[-0.0199521]; intercept:1.5757991382594223;
sector7_gender_5thThickness score:0.596690052167656; coef:[-0.04590439]; intercept:3.4998320961953446;

sector8_hypertension_5thThickness score:0.5560352581399532; coef:[-0.02666199]; intercept:2.0590429329628708;
sector8_gender_5thThickness score:0.578161539845296; coef:[-0.03040699]; intercept:2.437447158662346;

Logistic Regression between other continuous variable and hypertension:
=================================================================
Hypertension_Age_5thThickness score:0.6013671523655334; coef:[0.04886154]; intercept:-2.907798971695493;
Hypertension_IOP_5thThickness score:0.5471596032461677; coef:[0.0351597]; intercept:-0.3216401805876325;
Hypertension_AxialLength_5thThickness score:0.5448644520809469; coef:[-0.07935186]; intercept:2.0104226019496885;
Hypertension_SmokePackYears_5thThickness score:0.5547337278106509; coef:[0.05716786]; intercept:0.1646799221239527;
Hypertension_BMI_5thThickness score:0.5852078459600504; coef:[0.13006554]; intercept:-3.1212026952399596;
Hypertension_WaistHipRate_5thThickness score:0.599388379204893; coef:[5.7348945]; intercept:-4.905733607216095;



# Jan 11th, 9-sector mask:
OD 9-sector Mask with image size 31x25:
========sectorMask=========



            6
        666666666
      6666666666666
     666666666666666
    76666666266666666
   7776662222222666655
  777772222222222265555
  777733222222222215555
 77777333222022221155555
 77773333300000211115555
 77773333000000011115555
 77773333000000011115555
7777333300000000011115555
 77773333000000011115555
 77773333000000011115555
 77773333400000111115555
 77777334444044411155555
  777734444444444115555
  777784444444444455555
   7788884444444888555
    88888888488888885
     888888888888888
      8888888888888
        888888888
            8



OS 9-sector Mask with image size 31x25:
========sectorMask=========



            6
        666666666
      6666666666666
     666666666666666
    56666666266666666
   5556662222222666677
  555552222222222267777
  555511222222222237777
 55555111222022223377777
 55551111100000233337777
 55551111000000033337777
 55551111000000033337777
5555111100000000033337777
 55551111000000033337777
 55551111000000033337777
 55551111400000333337777
 55555114444044433377777
  555514444444444337777
  555584444444444477777
   5588884444444888777
    88888888488888887
     888888888888888
      8888888888888
        888888888
            8




# Jan 9th, Saturday, 2021:
1  add augmentation does not help too much;
2  expOCT_thickness5th2HyT_20210108_ResNet_B_NoAdd_15x12 is the best for test result.

expOCT_thickness5th2HyT_20210108_ResNet_A_NoAdd_15x12
       Sum=1.76 in validation data with no add augmentation;
       =======net running parameters=========
        net.m_runParametersDict:
	    validationLoss:0.6217029690742493
	    epoch:58
	    accuracy:0.5787278415015641
	    learningRate:0.002097152000000001
	    threshold:0.47900000000000004

        =======Test Result=========
	    ACC:0.566
	    TPR:0.7624113475042126
	    TNR:0.3119266054974329
	    Sum:1.6403379530016453


expOCT_thickness5th2HyT_20210108_ResNet_B_NoAdd_15x12:
       Sum=1.744 in validation data with no add augmentation.
       =======net running parameters=========
        net.m_runParametersDict:
	    validationLoss:0.6240633726119995
	    epoch:46
	    accuracy:0.5380604796663191
	    learningRate:0.002621440000000001
	    threshold:0.437

        =======Test Result=========
	    ACC:0.579
	    TPR:0.7659574467949298
	    TNR:0.33715596329501935
	    Sum:1.6821134100899493


# Jan 8th, Friday, 2021:
Read papers:
Associations with photoreceptor thickness measures in the UK Biobank
at link: https://pubmed.ncbi.nlm.nih.gov/31857628/
1  this paper has similar result with our current initial observation:
   The hypertension patient has thinner layer at the 5th layer.

Longitudinal Changes in the Peripapillary Retinal Nerve Fiber Layer Thickness in Hypertension: 4-Year Prospective Observational Study
at link: https://iovs.arvojournals.org/article.aspx?articleid=2752029
1  this paper researched the pRNFL layer thickness of hypertension patients is decreasing in 4 years longitudianl changes;
2  its pRNFL layer = RNFL +GCL layers in our project

Some thinking on our project:
1  Use retina quadrant (9-sector) method to further process our enface thickness map;
   the center, inner, outer subfields have different association pattern with hypertension.
   Both above 2 papers used retina quadrant (one uses 4 sectors, another uses 9 sectors)

2  In the future: may consider to use systolic blood pressure/ diastolic blood pressure with input will bring more information for network;

3  The possible reasons between hypertension and retina thickness:
    A. Hypertension -> intermittent reduction in blood flow in the DCP -> ischemia in optic nerve -> retina thickness reduction
    B. Hypertension -> choroidal permeability changes
        -> increases choroidal interstitial fluid and extends into the subretinal space causing subretinal fluid accumulation
        -> subsequent photoreceptor defects


4  which risk factors are affecting the the thickness of the 5 layer?
   Age: from age 50 to age 93, the average thickness of the 5th layer may reduces about 8 micrometers;
   gender: the average thickness of the 5th layer of males is 3.5 micrometer less than females;
   Hypertension: the average thickness of the 5th layer of hypertension patients is just 2 micrometer less than non-hypertension patients;
   smoke:
   axil length: the elongation of the eye globe leads mechanical stretching and thinning of the retina.
   IOP:
   BMI: m/h^2, where m is kg unit, and h is meter unit.
   waist-hip-rate: w/hip;

   The thickness change brought by age and gender is enough to submerge the thickness change of hypertension.
   In other words, we must use age/gender/smoke/axil lenglth etc as adjusting factors to offset their affects on thickness, and then to predict hypertension.

Further work:
1  use 9-sector quadrant map to preprocess the thickness map;
2  Analys all above risk factors relation between 9-sector thickness value with hypertension;
3  combine above risk factors with thickness to predict hypertension;









# Jan 6th, Tuesday, 2021
Use 5th thickness plus mask to predict.

expOCT_thickness5th2HyT_20210105_ResNet_A_15x12
    channels:     [96, 128, 160, 192] # the final channel is for FC layer
    dropoutRate: 0  # the dropout rate at final fully connected layer.
    weightDecay: 1.0e-6
    learningRate: 1.0e-2  #
    Sum=1.853 at epoch 853.
    threshold:0.477  TPR: 0.74, TNR:0.48, ACC 0.627
    No overfitting. training loss stable 0.61, while validation loss stable at 0.62
    at stable, training acc 58%, while validation acc 56%.

expOCT_thickness5th2HyT_20210105_ResNet_B_15x12
    channels:     [98, 98, 98, 98] # the final channel is for FC layer
    dropoutRate: 0.5  # the dropout rate at final fully connected layer.
    weightDecay: 1.0e-5
    learningRate: 1.0e-2  #
    Sum=1.854 at epoch 453.
    threshold:0.491  TPR: 0.74, TNR:0.48, ACC 0.63
    No overfitting. training loss stable 0.62, while validation loss stable at 0.62
    at stable, training acc 58%, while validation acc 57%.

Use 5th thickness plus mask to predict:
1  as summing the 5th, 6th, 7th, 8th thickness layers reduces the number of statistical significance pixel to 47.78%;
   please refer slides page 31 and 32.
2  we used the 5th thicknes multiplying mask to feed into network to predict;
3  it got accuracy 63%, TPR 74%, and TNR 48% in validation data;
4  it got below result on test data:
    ACC:0.566
	TPR:0.663120567364129
	TNR:0.44036697246696405
	Sum:1.669487539831093
5  The result of test data is a little better than SVM method;
6  We need to continue to think feature selection and radiomics features.







# Jan 4th, Monday, 2021:
Professor:
1  Maybe adding gender is also an option. Do you know which layers can be used to distinguish genders?
2   For the texture features, again you need to select some radiomic features.

My answer:
For gender prediction, the (0 th , 5 th, 6 th, 7 th) thickness layer and the (1 th , 2 th ) texture enface maps have statistical significance difference crossing training, validation and test data.
There are some methods to use gender information:
1   use gender as input;
2   use gender as one of predection head to help better extract features;
3   use gender as pretraining network to get a better initialization network for further hypertension prediction;

===============================================
(base) [c-xwu000:dataAnalysis]#python3 ./analyzeHyt_pixel.py ./testConfig/expOCT_thicknessAnalyzeHyt_pixel_20210104_9x15x12.yaml
Experiment: expOCT_thicknessAnalyzeHyt_pixel_20210104_9x15x12
inputDataDir: /home/hxie1/data/BES_3K/W512NumpyVolumes/log/SurfacesNet/expBES3K_20201126A_genXml/testResult/thicknessEnfaceMap_9x15x12
mask shape: (9, 15, 12)
total statistical significance pixel number: 137
at channel 0, statistical significance pixel number: 0
at channel 1, statistical significance pixel number: 0
at channel 2, statistical significance pixel number: 0
at channel 3, statistical significance pixel number: 0
at channel 4, statistical significance pixel number: 6
at channel 5, statistical significance pixel number: 91
at channel 6, statistical significance pixel number: 0
at channel 7, statistical significance pixel number: 27
at channel 8, statistical significance pixel number: 13
================ End of anlayzing thickness in each pixel ===============
(base) [c-xwu000:dataAnalysis]#python3 ./analyzeHyt_pixel.py ./testConfig/expOCT_thicknessAnalyzeHyt_pixel_20210104_9x31x25.yaml
Experiment: expOCT_thicknessAnalyzeHyt_pixel_20210104_9x31x25
inputDataDir: /home/hxie1/data/BES_3K/W512NumpyVolumes/log/SurfacesNet/expBES3K_20201126A_genXml/testResult/thicknessEnfaceMap_9x31x25
mask shape: (9, 31, 25)
total statistical significance pixel number: 496
at channel 0, statistical significance pixel number: 0
at channel 1, statistical significance pixel number: 0
at channel 2, statistical significance pixel number: 1
at channel 3, statistical significance pixel number: 2
at channel 4, statistical significance pixel number: 11
at channel 5, statistical significance pixel number: 331
at channel 6, statistical significance pixel number: 0
at channel 7, statistical significance pixel number: 108
at channel 8, statistical significance pixel number: 43
================ End of anlayzing thickness in each pixel ===============
(base) [c-xwu000:dataAnalysis]#python3 ./analyzeHyt_pixel.py ./testConfig/expOCT_textureAnalyzeHyt_pixel_20210104_9x31x25.yaml
Experiment: expOCT_textureAnalyzeHyt_pixel_20210104_9x31x25
inputDataDir: /home/hxie1/data/BES_3K/W512NumpyVolumes/log/SurfacesNet/expBES3K_20201126A_genXml/testResult/textureEnfaceMap_9x31x25
mask shape: (9, 31, 25)
total statistical significance pixel number: 114
at channel 0, statistical significance pixel number: 1
at channel 1, statistical significance pixel number: 0
at channel 2, statistical significance pixel number: 0
at channel 3, statistical significance pixel number: 1
at channel 4, statistical significance pixel number: 0
at channel 5, statistical significance pixel number: 0
at channel 6, statistical significance pixel number: 89
at channel 7, statistical significance pixel number: 22
at channel 8, statistical significance pixel number: 1
================ End of anlayzing thickness in each pixel ===============
(base) [c-xwu000:dataAnalysis]#python3 ./analyzeHyt_pixel.py ./testConfig/expOCT_textureAnalyzeHyt_pixel_20210104_9x15x12.yaml
Experiment: expOCT_textureAnalyzeHyt_pixel_20210104_9x15x12
inputDataDir: /home/hxie1/data/BES_3K/W512NumpyVolumes/log/SurfacesNet/expBES3K_20201126A_genXml/testResult/textureEnfaceMap_9x15x12
mask shape: (9, 15, 12)
total statistical significance pixel number: 32
at channel 0, statistical significance pixel number: 0
at channel 1, statistical significance pixel number: 0
at channel 2, statistical significance pixel number: 0
at channel 3, statistical significance pixel number: 0
at channel 4, statistical significance pixel number: 0
at channel 5, statistical significance pixel number: 0
at channel 6, statistical significance pixel number: 26
at channel 7, statistical significance pixel number: 6
at channel 8, statistical significance pixel number: 0
================ End of anlayzing thickness in each pixel ===============

Further idea:
1  sum the thickness of 5th, 6th 7th, 8th layer to analyze its pixel-level p value;
2  sum the texture of 6th,7th layer to analyze its pixel-level p value;

Sum layer 5,6,7,8 together result:
(base) [c-xwu000:dataAnalysis]#python3 ./analyzeHyt_pixel_sum5678Layer.py ./testConfig/expOCT_thicknessAnalyzeHyt_pixel_sum5678_20210105_9x31x25.yaml
Experiment: expOCT_thicknessAnalyzeHyt_pixel_sum5678_20210105_9x31x25
inputDataDir: /home/hxie1/data/BES_3K/W512NumpyVolumes/log/SurfacesNet/expBES3K_20201126A_genXml/testResult/thicknessEnfaceMap_9x31x25
mask shape: (1, 31, 25)
total statistical significance pixel number: 334
at channel 0, statistical significance pixel number: 334
================ End of anlayzing thickness in each pixel ===============
(base) [c-xwu000:dataAnalysis]#python3 ./analyzeHyt_pixel_sum5678Layer.py ./testConfig/expOCT_thicknessAnalyzeHyt_pixel_sum5678_20210105_9x15x12.yaml
Experiment: expOCT_thicknessAnalyzeHyt_pixel_sum5678_20210105_9x15x12
inputDataDir: /home/hxie1/data/BES_3K/W512NumpyVolumes/log/SurfacesNet/expBES3K_20201126A_genXml/testResult/thicknessEnfaceMap_9x15x12
mask shape: (1, 15, 12)
total statistical significance pixel number: 86
at channel 0, statistical significance pixel number: 86
================ End of anlayzing thickness in each pixel =============

sum layer 5,6,7 together
(base) [c-xwu000:dataAnalysis]#python3 ./analyzeHyt_pixel_sum567Layer.py ./testConfig/expOCT_thicknessAnalyzeHyt_pixel_sum567_20210105_9x15x12.yaml
Experiment: expOCT_thicknessAnalyzeHyt_pixel_sum567_20210105_9x15x12
inputDataDir: /home/hxie1/data/BES_3K/W512NumpyVolumes/log/SurfacesNet/expBES3K_20201126A_genXml/testResult/thicknessEnfaceMap_9x15x12
mask shape: (1, 15, 12)
total statistical significance pixel number: 96
at channel 0, statistical significance pixel number: 96
================ End of anlayzing thickness in each pixel ===============



# Jan 2nd, Saturday, 2020
conclusion:
1 if fixe learning rate, it is better at 0.001;
2 with learning decay, start at 0.01;
3 weight decay change to 1.0e-6, reducing from 1.0e-5.

after experiment:
1 initial learning rate: 0.005;
2 expOCT_thickTexture2HyT_20210102_ResNet_D_15x12 looks good;
3 channels:     [128, 160, 192, 224] , without dropout.


expOCT_thickTexture2HyT_20210102_ResNet_A_15x12:
     learning Rate:1.0e-2
     channels:     [96, 128, 160, 192] # the final channel is for FC layer
     dropoutRate: 0  # the dropout rate at final fully connected layer.
     at stable, trianing acc vs validation acc: 64% vs 57%
     SUM =  1.855 at epoch 1.628K
     TPR TNR ACC Threshold:

expOCT_thickTexture2HyT_20210102_ResNet_B_15x12:
     learning Rate: 5.0e-3
     channels:     [96, 128, 160, 192] # the final channel is for FC layer
     dropoutRate: 0  # the dropout rate at final fully connected layer.

     when stable, training acc stuck at  59% vs 58%.  both training and validation loss are oscillating.
     Sum=  1.853  at epoch 531.
     TPR:  TNR:   ACC:  Threshold
     at about 2min per epoch.

expOCT_thickTexture2HyT_20210102_ResNet_C_15x12:
     learning Rate: 1.0e-2
     channels:     [128, 160, 192, 224] # the final channel is for FC layer
     dropoutRate: 0  # the dropout rate at final fully connected layer.

     when stable, training acc stuck at  64% vs 56%
     Sum=  1.85  at epoch 1.285K
     TPR:  TNR:   ACC:  Threshold
     at about 2min per epoch.


expOCT_thickTexture2HyT_20210102_ResNet_D_15x12:   Good. Not the best.
     learning Rate: 5.0e-3
     channels:     [128, 160, 192, 224] # the final channel is for FC layer
     dropoutRate: 0  # the dropout rate at final fully connected layer.
     when stable, training acc stuck at  60% vs 55%
     Sum= 1.86  at epoch 1.057K
     TPR:0.75   TNR: 0.48   ACC:0.63  Threshold 0.47
     at about 2min per epoch.

expOCT_thickTexture2HyT_20210102_ResNet_E_15x12:
     learning Rate: 1.0e-2
     channels:     [128, 160, 192, 224] # the final channel is for FC layer
     dropoutRate: 0.2  # the dropout rate at final fully connected layer.
     when stable, training acc stuck at  64% vs 58%
     Sum= 1.834  at epoch 1.064K
     TPR:  TNR:   ACC:  Threshold
     at about 2min per epoch.


expOCT_thickTexture2HyT_20210102_ResNet_F_15x12:
     learning Rate: 1.0e-2
     channels:     [128, 160, 192, 224] # the final channel is for FC layer
     dropoutRate: 0.5  # the dropout rate at final fully connected layer.
     when stable, training acc stuck at 61% vs 56%
     Sum= 1.838 at epoch 1.807
     TPR:  TNR:   ACC:  Threshold
     at about 2min per epoch.


=================
Some experiment result:
expOCT_thickTexture2HyT_20210101_ResNet_A_15x12:
    channels:     [98, 98, 98, 98] # the final channel is for FC layer
    dropoutRate: 0  # the dropout rate at final fully connected layer.
    with channel:  initial learning rate 0.1
    when stable, training acc stuck at  74% vs 56%
    Sum=  1.823 at epoch 719.  initial learning rate is too big.
    TPR:  TNR:   ACC:  Threshold
    at about 2min per epoch.

expOCT_thickTexture2HyT_20210101_ResNet_B_15x12:
    channels:     [98, 98, 98, 98] # the final channel is for FC layer
    dropoutRate: 0.2  # the dropout rate at final fully connected layer.
    with channel:  initial learning rate 0.1
    when stable, training acc stuck at  74% vs 57%
    Sum=  1.818 at epoch 654.
    TPR:  TNR:   ACC:  Threshold
    at about 2min per epoch.

expOCT_thickTexture2HyT_20210101_ResNet_C_15x12:
    channels:     [96, 128, 160, 192] # the final channel is for FC layer
    dropoutRate: 0.2  # the dropout rate at final fully connected layer.
    with channel:  initial learning rate 0.1
    when stable, training acc stuck at  75% vs 56%
    Sum=  1.849 at epoch 22.
    TPR:  TNR:   ACC:  Threshold
    at about 2min per epoch.

expOCT_thickTexture2HyT_20210101_ResNet_D_15x12: (it is good, not the best)
    channels:     [96, 128, 160, 192] # the final channel is for FC layer
    dropoutRate: 0  # the dropout rate at final fully connected layer.
    with channel:  initial learning rate 0.1
    when stable, training acc stuck at  75% vs 54%
    Sum=  1.855 at epoch 38.
    TPR: 0.69 TNR: 0.53  ACC: 0.63  Threshold 0.425
    at about 2min per epoch.

expOCT_thickTexture2HyT_20210101_ResNet_E_15x12:
    channels:     [96, 128, 160, 192] # the final channel is for FC layer
    dropoutRate: 0.5  # the dropout rate at final fully connected layer.
    with channel:  initial learning rate 0.1
    when stable, training acc stuck at  75% vs 53%
    Sum=  1.816 at epoch 22.
    TPR:  TNR:   ACC:  Threshold
    at about 2min per epoch.




# Dec 31th, Thursday, 2020:

expOCT_thickTexture2HyT_20201231_ResNet_A_15x12:
       with channel: 18
       when stable, training acc stuck at 0.62
       Sum=1.839
       TPR:0.60,  TNR: 0.63  ACC: 0.61


expOCT_thickTexture2HyT_20201231_ResNet_B_15x12:
       with channel: 36
       when stable, training acc stuck at 0.68
       Sum=1.879 at epoch 124.
       TPR:0.69  TNR:0.56  ACC: 0.63

expOCT_thickTexture2HyT_20201231_ResNet_C_15x12:
       with channel: 9
       when stable, training acc stuck at 0.58
       Sum=1.857
       TPR:0.65  TNR:0.59  ACC: 0.62

expOCT_thickTexture2HyT_20201231_ResNet_D_15x12:  still in program, ID=9193
       with channel: 9  using fixed 1.0e-4 learning rate.
       when stable, training acc stuck at
       Sum= 1.768 at epoch 2.04K
       TPR:  TNR:  ACC:

expOCT_thickTexture2HyT_20201231_ResNet_E_15x12:
       with channel: 64 initial learning rate 0.01
       when stable, training acc stuck at
       Sum=  1.826 at epoch 298.
       TPR:  TNR:  ACC:

expOCT_thickTexture2HyT_20201231_ResNet_F_15x12:  (the best)  it looks no overfitting. reduce dropout rate is good.
       with channel: [98,98,98,98] initial learning rate 0.01, dropout 0.5
       when stable, training acc stuck at 60%.
       Sum= 1.881 at epoch 585.
       TPR: 0.73 TNR: 0.52  ACC: 0.635 .Threshold 0.473.
       at about 2min per epoch.

expOCT_thickTexture2HyT_20201231_ResNet_G_15x12:
       with channel: 128 initial learning rate 0.01
       when stable, training acc stuck at 60% vs 55%
       Sum=  1.872 at epoch 547.
       TPR:  0.61 TNR: 0.64 ACC: 0.62

expOCT_thickTexture2HyT_20201231_ResNet_H_15x12:
       with channel: 64 initial learning rate 0.001
       when stable, training acc stuck at
       Sum= 1.831 at epoch 589.
       TPR:  TNR:  ACC:

expOCT_thickTexture2HyT_20201231_ResNet_I_15x12:
       with channel: 96 initial learning rate 0.001
       when stable, training acc stuck at
       Sum= 1.795 at epoch 220.
       TPR:  TNR:  ACC:

expOCT_thickTexture2HyT_20201231_ResNet_J_15x12:
       with channel: 128  initial learning rate 0.001
       when stable, training acc stuck at
       Sum=  1.804 at epoch 261.
       TPR:  TNR:  ACC:

expOCT_thickTexture2HyT_20201231_ResNet_K_15x12:
       with channel: 256  initial learning rate 0.0001
       when stable, training acc stuck at
       Sum= 1.736  at epoch 492.
       TPR:  TNR:  ACC:


sense:
A. Age is a good assistanted factor to judge hypertension.
B. thickness is good to judge age;
C. Add age as channel will help judge hypertension.



Age statistics:
values for Age$ have 1806 records
min=50.0; mean=63.38538205980066; max=93.0

total 481 raw IDs in file /home/hxie1/data/BES_3K/GTs/validationID_delNonExist_delErrWID_excludeMGM.csv
values for Age$ have 481 records
min=50.0; mean=64.17671517671518; max=88.0

total 501 raw IDs in file /home/hxie1/data/BES_3K/GTs/testID_delNonExist_delErrWID_excludeMGM.csv
values for Age$ have 501 records
min=50.0; mean=63.85429141716567; max=87.0

Age subgroup: 50-55, 55-60, 60-65, 65-70, 70-80,80-95; total 6 group.

Experiment: expOCT_thicknessAnalyzeAge_20201231_9x31x25

Note:
1 some patient has OD/OS eyes volumes; and some just has one eye volume;

=============================================================
============Age_train=======================================
AgeRange:	    50-55,	55-60,	60-65,	65-70,	70-80,	80-95,
NoHypertension:	470,	402,	265,	194,	274,	44,
Hypertension:	298,	322,	300,	313,	589,	129,
=============================================================

=============================================================
============Age_validation===================================
AgeRange:	    50-55,	55-60,	60-65,	65-70,	70-80,	80-95,
NoHypertension:	104,	91,	    70,	    56,	    96,	    18,
Hypertension:	81,	    88,	    78,	    84,	    155,	38,
============================================================

============================================================
============Age_test========================================
AgeRange:	    50-55,	55-60,	60-65,	65-70,	70-80,	80-95,
NoHypertension:	112,	100,	70,	    56,	    88,	    10,
Hypertension:	90,	    96,	    84,	    88,	    150,	56,
============================================================
================End of anlayzing thickness===================

check statistics significance (pvalue<0.05) between NoHypertension and Hypertension
crossing training, validation and test data
for different age groups and different layers
================================================================================
        layer0, layer1, layer2, layer3, layer4, layer5, layer6, layer7, layer8
50-55
55-60
60-65
65-70
70-80
80-95
================================================================================
No any age group and any layer has this statistics significance.

Some extra conclusions:
1  along age increasing, average of thickness layers 1,2,3,5 and 7 decrease;
2  along age increasing, average of thickness layers 4,6,and 8 increase;
3  This is one of reason that using retina thickness to predict age has a high accuracy;




Experiment: expOCT_thicknessAnalyzeAge_AllGroups_20201231_9x31x25

=============================================================
======================All patients============================
AgeRange:	50-55,	55-60,	60-65,	65-70,	70-80,	80-95,
All:	    1155,	1099,	867,	791,	1352,	295,
=============================================================
================End of anlayzing thickness===============







# Dec 30th, Wednesday, 2020:
expOCT_thickness2HyT_20201228_2Layers_A: input 9x31x25
    channels:     [16, 8]
    dropoutRates: [0.5,0.5]  # 2 dropout layers.
    Sum = 1.54, majority prediction.

expOCT_thickness2HyT_20201228_2Layers_B: input 9x15x12
    channels:     [16, 8]
    dropoutRates: [0.5,0.5]  # 2 dropout layers.
    Sum = 1.601.

=========================================
Generate 5th thickness channel and 6th texture enface map:
1  use 9x31x25 as input;
2  5th thickness as channle 0, and 6th texure as channel 1; save original save;
3  in the dataload class, use channel-dimension normalization;
4  in conv network, then use 2 head branches to process thickness and texture.
t test for features choose: https://www.quora.com/How-can-I-use-students-T-test-for-feature-selection



expOCT_thickTexture2HyT_20201230_ResNet_A: for input 2x31x25
    network: "ThickTexture2HyTension_ResNet"
    channels:     [18, 18, 18, 18, 18] # the final channel is for FC layer
    dropoutRate: 0.5  # the dropout rate at final fully connected layer.
    without validation augmentation.
    Sum= 1.737 at epoch 116.  Overfitting. while training accuracy stuck at 67%.
    TPR: 0.52, TNR: 0.63, ACC: 0.57


expOCT_thickTexture2HyT_20201230_ResNet_B: for input 2x31x25  (almost best)
    network: "ThickTexture2HyTension_ResNet"
    channels:     [18, 18, 18, 18, 18] # the final channel is for FC layer
    dropoutRate: 0.5  # the dropout rate at final fully connected layer.
    with validation augmentation.
    Sum = 1.814 at epoch 105. at epoch 16, it start to overfitting. training accuracy stuck at 69%.
    TPR: 0.51, TNR: 0.71; ACC: 0.60;






# Dec 29th, Tuesday, 2020
Use t-test to judge the statistics significane of average value of each layer each with corresponding target class:
We choose the layer with all p-values <0.05 crossing training, valdiation and test data.
Here all layer index start from zero.
For hypertension: for 9x31x25 image
      thickness map: 5th layer
      texture enface map: 6th layer

For gender:  for 9x31x25 image
      thickness map: 0th, 5th, 6th, 7th layer.
      texture enface map: 1th, 2th layer.

For hypertension: for 9x15x12 image
      thickness map: 5th layer
      texture enface map: 6th layer





# Dec 29th, Tuesday, 2020
Meeting with Shafkat on Thickness2Hypertension prediction:
Attendee: Shafkat, Hui.
Time: 2:00 pm - 02:50 pm, Dec 29th, Tuesday, 2020
Minutes:
1  The difference of 2 disease prediction projeccts:
   Shafkat's Optic Disk swelling prediction:
   A. Doctors used OCT enface folds and wrinkles image information to get the ground truth labels;
      so these known folds and wrinkles in OCT are helpful features;
   B  It has 200 slices each patients, so its blood vessel information is continuous;

   Hui's hypertension prediction:
   A. Doctors used another blood pressure measurement to get the ground truth labels;
      so there is no currently known pattern in OCT relating to hypertension;
   B. It has 31 slices each patients, so its blood vessel information in not continuous.

2  Possible improvements on OCT2Hypertension projects:
   A  RPE layer has richer blood vessel information;
   B  Using pretrained ResNext network in Shafkat's experience improved accuracy about 10%;
      B1. copy the weight of pretrained network 3 channels to 9 channels;
      B2. scale up the input image to 224x224  to fit the pretrained network;
      B3. Merge 9 layer thickness into 3 layers by choosing important, or more differentiating layers;
   C  analyze activation map to find more important pattern to choose more important layer;

3  input to Shafkat's network:
Let me summarize your input to disease prediction:
1  retinal blood segmentation information;
2  inner retina en-face image (Surface_1_4) ;
3  total retina en-face image (Surface_1_7);
4  RPE en-face image (surface_5_7);
5  total retinal thickness,
6  ONH shape features,


Shafkat, if this minutes is not complete, welcome to add your notes.  Thank you very much.



# Dec 29th, Tuesday, 2020
Meeting conclusions with professor
1  visualize thickness prediction result R with ground truth;
2  analyze the relationship between age and raw thickness map, use 9 layer averages;
3  analyze the pattern dominant in the input for predicting hypertension in Deep learning network and SVM;
4  refer the nature medical paper about the loss design and regulization;
5  add x,y coordinates into input tensor for the surface prediction;
6  use JHU method to prediction thickness Rift;


# Dec 28th, Monday, 2020
Answer professor Wu's questions:
Traditional machine learning:
1) It seems thickness maps are not powerful enough and texture features help. But simply averaging the intensity of the enface image may not be good enough. You may also need to use radiomic features.
A:  OK. I need to research some literature on how to design the radiomic features.  If you have further detailed ideas on this radiomic features, please share with me.

2) Should also try other method, like random forest?
A:  OK. I will try random forest method this week.

Deep learning:
1) Why 2-path independent prediction, in stead of using multiple channels to fuse the features?
A:  These 2 methods both are worth trying.  I worry that using 18 channels (9 thickness + 9 texture) will further increase the number of input features which may lead to further overfitting. But it is worth to try.

2) What is the activation function?
A:  ReLU in each Conv layer.   The final loss uses binary cross-entropy.

3) What is the number of latent features in our segmentation network? This is for our next step - using similar method as Yusen's for prognostication prediction.
A: The first layer has 24 filters, double the number of filters along each deeper layer, and the network has total 7 layers, so at the bottom we have 1536 filters with size 7x8 as the latent vector.
     In other words, the bottom latent vector has a size 1536x7x8 for each slice. If we consider 31 slices together each patient, each patient has 31x1536x7x8 input features, which is 1476 times of training samples(1806), which is highly probable to overfitting.


Data Statistics:
1  1806 training patients, 481 validation patients, and 501 test patients for this data.
2  Age for training data:
    values for Age$ have 1806 records
    min=50.0; mean=63.38538205980066; max=93.0
3  original thickness map;:9x15x12
   add age: 10x15x12  age as channel 15x12 of 60;
   add age as element: 9x15x12 +1
   normalization: range 50-93, thickness: 0-1, 1-10, -1 to 1
   add age, gender etc.
4  Analyze relation of Age and layer average thickness of each layer:
   in different data set:




# Dec 25th, Friday, 2020
expOCT_thickness2HyT_20201224_ResNet_A: with AddSample augmentation:
    at epoch 297, training acc got 97%, while validation acc got 53%;
    at epoch 10, validation loss > training loss, and validation loss continue to increase, while training loss continue to reduce.
    TPR+TNR+ACC= Sum=1.66.

expOCT_thickness2HyT_20201225_ResNet_A: with AddSample augmentation + 18 filters in each layer, and 2 conv in each layer.
    at epoch 406, training acc got 95%, while validation acc got 53%;
    at epoch 3, validation loss > training loss, and validation loss continue to increase, while training loss continue to reduce.
    TPR+TNR+ACC= Sum=1.653.

expOCT_thickness2HyT_20201225_ResNet_B:   with AddSample augmentation + 9 filters in each layer, and 2 conv in each layer. dropout 0.5
    Sum= 1.69.
    at stable, training acc = 77%, while validaiton accc =54%;
    at epoch 0, validation loss > training loss, and validation loss continue to increase, while training loss continue to reduce.

expOCT_thickness2HyT_20201225_ResNet_C:   with AddSample augmentation + 9 filters in each layer, and 2 conv in each layer. dropout 0.2
    Sum= 1.67.
    at stable, training acc = 84%, while validaiton accc =54%;
    at epoch 0, validation loss > training loss, and validation loss continue to increase, while training loss continue to reduce.


expOCT_thickness2HyT_20201225_ResNet_D:  with AddSample augmentation + 6 filters in each layer, and 2 conv in each layer. dropout 0.2
    Sum= 1.60.
    at stable, training acc = 80%, while validaiton accc =51%;
    at epoch 0, validation loss > training loss, and validation loss continue to increase, while training loss continue to reduce.



SVM test result:
Note: SVM use default parameters;

Summary:
1  We did total 8 combination experiments using different input size(9x31x25, 9x15x12), textureEnface or thickness map, and prediction of hypertension or gender;

2  For hypertension prediction:
   A. SVM with polynomial kernel and thickness 9x15x12 input got the best result of average accuracy of validation and test set: 0.575;
   B. Comparing with our deep learning network, our fine-tune deep learning network can get the current best validation accuracy: 0.62;

3  For gender prediction:
   A. SVM with linear kernel and thickness 9x15x12 input got the best result of average accuracy of validation and test set: 0.71;
   B. Comparing with our deep learning network, our hypertension network (not fine-tune for gender) can get the current best validation accuracy for gender: 0.72;

4  Both hypertension and gender prediction with SVM showed that good training accuracy does not mean a good validation and test accuracy;

5  These SVM experiments and deep learning experiments both show that for the same input sizes and forms, gender prediction always gets explicit better result than hypertension prediction;

6  These SVM experiments fit traditional expectation:
   Deep learning generally gets a better performance than traditional ML methods, because of the automatic feature extracting capability of DL.

7  Suggestions on further work:
   A  Further improve the accuracy on deep learning:
     A1. Combine thickness and texture enface map for 2-path independent predictions, and then assemble result;
     A2. Current thickness map is an approximate circle-symmetric map around fovea, can we futher extract one average thickness along same radius or four averages of 4 quadrants along same radius?
         This method will further reduce the size of input features for reducing overfitting, and it keeps core thickness information because of circle symmetric property.
         Maybe we need to ask professor Wang's suggestion on this idea, as this is a medical feature design problem.
   B Report current deep learning and SVM result to professor Wang, and ask her suggestions on further improvement idea;
   C From this SVM result, we may not have a unrealistic expectation that our accuracy must exceed 70%;

=== Accuracies of the 5thThickness and 6thTexture to hypertension_bp_plus_history$ Prediction with different SVM kernels ====
Experiment: expOCT_thickTexture2HyT_20210101_SVM_A
inputDataDir: /home/hxie1/data/BES_3K/W512NumpyVolumes/log/SurfacesNet/expBES3K_20201126A_genXml/testResult/5thThickness_6thTexture_2x15x12
========================================================================================================
SVM_Kernel,	 linear,                poly,                   rbf,                    sigmoid
Training,  	 0.6605555555555556,    0.6669444444444445,     0.6588888888888889,     0.5263888888888889
Validation,	 0.5245046923879041,    0.5453597497393118,     0.5453597497393118,     0.5307612095933264
Test,      	 0.507,                 0.559,                  0.567,                  0.512
========================================================================================================


============ Accuracies of Thickness to hypertension_bp_plus_history$ Prediction with different SVM kernels ====================
Experiment: expOCT_thickness2HyT_20201225_SVM_A
inputDataDir: /home/hxie1/data/BES_3K/W512NumpyVolumes/log/SurfacesNet/expBES3K_20201126A_genXml/testResult/thicknessEnfaceMap_9x15x12
=======================================================================================================
SVM_kernel,  linear,                poly,                   rbf,                    sigmoid
Training,  	 0.8202777777777778,    0.6036111111111111,     0.5986111111111111,     0.5425
Validation,	 0.5234619395203337,    0.5954118873826904,     0.5860271115745568,     0.5119916579770595
Test,      	 0.537,                 0.555,                  0.559,                  0.543
========================================================================================================

============ Accuracies of Thickness to hypertension_bp_plus_history$ Prediction with different SVM kernels ====================
Experiment: expOCT_thickness2HyT_20201225_SVM_B
inputDataDir: /home/hxie1/data/BES_3K/W512NumpyVolumes/log/SurfacesNet/expBES3K_20201126A_genXml/testResult/thicknessEnfaceMap_9x31x25
========================================================================================================
SVM_Kernel,	 linear,                poly,                   rbf,                    sigmoid
Training,  	 1.0,                   0.6097222222222223,     0.6075,                 0.5452777777777778
Validation,	 0.5140771637122002,    0.5828988529718456,     0.5912408759124088,     0.5130344108446299
Test,      	 0.519,                 0.551,                  0.558,                  0.543
========================================================================================================

============ Accuracies of TextureEnface to hypertension_bp_plus_history$ Prediction with different SVM kernels ====================
Experiment: expOCT_texture2HyT_20201226_SVM_A
inputDataDir: /home/hxie1/data/BES_3K/W512NumpyVolumes/log/SurfacesNet/expBES3K_20201126A_genXml/testResult/textureEnfaceMap_9x15x12
========================================================================================================
SVM_Kernel,	 linear,                poly,                   rbf,                    sigmoid
Training,  	 0.8736111111111111,    0.7502777777777778,     0.7388888888888889,     0.5094444444444445
Validation,	 0.5537017726798749,    0.5537017726798749,     0.5610010427528676,     0.5265901981230449
Test,      	 0.533,                 0.549,                  0.559,                  0.53
========================================================================================================

============ Accuracies of TextureEnface to hypertension_bp_plus_history$ Prediction with different SVM kernels ====================
Experiment: expOCT_texture2HyT_20201226_SVM_B
inputDataDir: /home/hxie1/data/BES_3K/W512NumpyVolumes/log/SurfacesNet/expBES3K_20201126A_genXml/testResult/textureEnfaceMap_9x31x25
========================================================================================================
SVM_Kernel,	 linear,                poly,                   rbf,                    sigmoid
Training,  	 1.0,                   0.8319444444444445,     0.8091666666666667,     0.5386111111111112
Validation,	 0.5516162669447341,    0.5547445255474452,     0.5672575599582899,     0.529718456725756
Test,      	 0.501,                 0.565,                  0.567,                  0.508
=======================================================================================================

============ Accuracies of TextureEnface to gender Prediction with different SVM kernels ====================
Experiment: expOCT_texture2Gender_20201226_SVM_A
inputDataDir: /home/hxie1/data/BES_3K/W512NumpyVolumes/log/SurfacesNet/expBES3K_20201126A_genXml/testResult/textureEnfaceMap_9x15x12
========================================================================================================
SVM_Kernel,	 linear,                poly,                   rbf,                    sigmoid
Training,  	 0.9613888888888888,    0.7658333333333334,     0.8161111111111111,     0.5566666666666666
Validation,	 0.656934306569343,     0.602711157455683,      0.6579770594369134,     0.5537017726798749
Test,      	 0.69,                  0.628,                  0.691,                  0.563
========================================================================================================

============ Accuracies of TextureEnface to gender Prediction with different SVM kernels ====================
Experiment: expOCT_texture2Gender_20201226_SVM_B
inputDataDir: /home/hxie1/data/BES_3K/W512NumpyVolumes/log/SurfacesNet/expBES3K_20201126A_genXml/testResult/textureEnfaceMap_9x31x25
========================================================================================================
SVM_Kernel,	 linear,                poly,                   rbf,                    sigmoid
Training,  	 1.0,                   0.8077777777777778,     0.865,                  0.5741666666666667
Validation,	 0.670490093847758,     0.5985401459854015,     0.6579770594369134,     0.5651720542231491
Test,      	 0.697,                 0.618,                  0.696,                  0.582
========================================================================================================

============ Accuracies of Thickness to gender Prediction with different SVM kernels ====================
Experiment: expOCT_thickness2Gender_20201226_SVM_C
inputDataDir: /home/hxie1/data/BES_3K/W512NumpyVolumes/log/SurfacesNet/expBES3K_20201126A_genXml/testResult/thicknessEnfaceMap_9x15x12
========================================================================================================
SVM_Kernel,	 linear,                poly,                   rbf,                    sigmoid
Training,  	 0.9102777777777777,    0.735,                  0.7311111111111112,     0.6152777777777778
Validation,	 0.7038581856100105,    0.6923879040667362,     0.6923879040667362,     0.5651720542231491
Test,      	 0.72,                  0.699,                  0.692,                  0.599
========================================================================================================

============ Accuracies of Thickness to gender Prediction with different SVM kernels ====================
Experiment: expOCT_thickness2Gender_20201226_SVM_D
inputDataDir: /home/hxie1/data/BES_3K/W512NumpyVolumes/log/SurfacesNet/expBES3K_20201126A_genXml/testResult/thicknessEnfaceMap_9x31x25
========================================================================================================
SVM_Kernel,	 linear,                poly,                   rbf,                    sigmoid
Training,  	 1.0,                   0.7458333333333333,     0.74,                   0.6194444444444445
Validation,	 0.6746611053180396,    0.6871741397288843,     0.6882168925964547,     0.5693430656934306
Test,      	 0.711,                 0.701,                  0.695,                  0.596
========================================================================================================


# Dec 24th, Thursday, 2020
Use SVM on Thickness map to hypertension,please review.

Assumption: our thickness to hypertension prediction is not a linear separable.
Solution:
1  use svc function, which support classification error and 4 kernal functions;
2  4 kernal functions: linear, polynomial, rbf, sigmoid tanh;
   one by one try to see which kernal give us best result;
3  use svc.score to get it accuracy;

Input:
1  thickness map of size 9x15x12 flat into a vector;
2  label [0,1] converts into [-1,1];

Possible results:
1  high prediction result: wonderful;
2  low prediction result, which is similar overfitting in deep learning:
   then further possible improvement:
   A  further consider to use feature engineering (SIFT etc0.) to design features;
   B  use a separate deep learning network to search features;
   C  reduce input features;

Plan:
1  This Friday, code;
2  This Saturday, test different kernal and parameter config;
3  Next Monday, report result;








# Dec 23rd, Wednesday, 2020
Let's us try 9x15x12 input size, which keeps 9 layers feature, and preserver X and Z same pixel resolution:
original size: 9x31*512 in CxZxX direction.
resulution: Z:240.555 um/pixel,  X: 11.29 um/pixel;
(240.555*2)/11.29 = 42.614 which means 2 pixels in Z direction has same resolution with 42.6 pixels in X direciton.
512/43 = 12, 31/2 = 15.5
new image size: 9x15x12 = 1620 features.

expOCT_thickness2HyT_20201223_ResNet_A:
        channels:     [4, 8, 16, 32] # the final channel is for FC layer
        dropoutRate: 0.5  # the dropout rate at final fully connected layer.
        TPR+TNR+ACC= Sum = 1.61;
        at epoch 7, validation Loss > training loss.

expOCT_thickness2HyT_20201223_ResNet_B:
        channels:     [16, 16, 16, 16] # the final channel is for FC layer
        dropoutRate: 0.5  # the dropout rate at final fully connected layer.
        Sum = 1.63, overfitting.

expOCT_thickness2HyT_20201223_ResNet_C:
        channels:     [32, 32, 32, 32] # the final channel is for FC layer
        dropoutRate: 0.5  # the dropout rate at final fully connected layer.
        Sum = 1.63, overfitting.



expOCT_thickness2HyT_20201223_ResNet_D:
        channels:     [64, 64, 64, 64] # the final channel is for FC layer
        dropoutRate: 0.5  # the dropout rate at final fully connected layer.
        Sum = 1.63, overfitting.

===============Use 1Layer network==============
expOCT_thickness2HyT_20201223_1Layer_A: 96 filters
    Sum= 1.659
    at epoch 3, validation loss > training loss
    at stable: training acc 65%, while validation acc 50%;

expOCT_thickness2HyT_20201223_1Layer_B: 64 filters
    Sum= 1.646
    at epoch 7, validation loss > training loss
    at stable: training acc 64%, while validation acc 53%;

expOCT_thickness2HyT_20201223_1Layer_C: 32 filters
    Sum= 1.653
    at epoch 3, validation loss > training loss
    at stable: training acc 61%, while validation acc 52%;

expOCT_thickness2HyT_20201223_1Layer_D: 16 filters
    Sum= 1.661
    at epoch 7, validation loss > training loss
    at stable: training acc 58%, while validation acc 54%;

expOCT_thickness2HyT_20201223_1Layer_E: 8 filters
    Sum= 1.621
    at epoch 0, validation loss > training loss
    at stable: training acc 56%, while validation acc 51%;

expOCT_thickness2HyT_20201223_1Layer_F: 4 filters
    Sum= 1.643
    at epoch 7, validation loss > training loss
    at stable: training acc 57%, while validation acc 51%;

Conclusion: single layer network is not good.


================================================
Use sample sum as data augmentation:  --done, training.
1  get one load index i1 from __getitem__ method;
2  random choose other 2 indexes: i2,i3;
3  if these 3 samples have same labels, average the 3 samples;
   elif i1 = i2, average i1 and i2;
   elif i1 = i3, average i1 and i3;
   else  average i2 and i3;
4  while using this method, validation data do not augmentation;
5  this method can generate sample: int(1806*0.45)*(int(1806*0.45)-1)/2+ int(1806*0.55)*(int(1806*0.55)-1)/2 = 821794
6  while  9*31*25 = 6975 features.
7  redo 9x31x25 map, cancel smooth.  --done

Exp: expOCT_thickness2HyT_20201224_ResNet_A.yaml for addSamples is training:






# Dec 22nd, Tuesday, 2020
Today, in the process of learning SVM, I found a problem which maybe is the root reason why we always encounter overfitting in both our OCT2HyperTension and
OvarianCancerCT to survival prediction.

The problem is that if the number of features in each sample is much greater than the number of samples, it is easy over-fitting.
A very good explanation of this problem is in link
https://www.quora.com/Is-it-possible-to-train-a-machine-learning-model-if-there-are-more-features-than-samples-in-the-data-set
in which, Alex Gilgur used linear equation system as example to illustrate this problem.

Whatever we use deep learning network or SVM, if the number of features in each sample is much greater than the number of samples, it is easy over-fitting.
In SVM method, avoid over-fitting in choosing Kernel functions and regularization term is crucial.
(please refer link: https://scikit-learn.org/stable/modules/svm.html )

We need first solve the feature number problem, and then go further.

In our thickness2Hypertension, our training data has 1806 samples (patients) with binary label for each,
while our input is 9x31x512 tensor which means input has 142848 features. In other words, our feature number is 79 times bigger than the number of samples.

I am planning to reduce features first, and then do the SVM and deep learning:
A Currently, we have 10 surface segmentation and 9 layers. we can use the sum of thickness of first 5 layers as a thickness, and use the sum of last 3 layers as thickness;
  so, we will get 2 thicknesses values;
B with a principle that that pixel resolutions are same in both Z and X direction, reduce enface map to 31x25 from 31x512 by averaging the neighbour pixels;
C Therefore, we got a input tensor of size 2x31x25 = 1550 features;

After this feature reduction(feature selection), go to SVM and deep learning.

Professor, How do you think?
====================================
In deep learning, methods of overcoming overfitting:
1  add the number of training samples;
2  reduce the number of input features;
3  L2 parameter regulization;
4  dropout;
5  add data augmentation;
6  reduce the layer number and filter number of networks to reduce model complexity;

too many features leads the spare of samples.
https://stackoverflow.com/questions/37776333/why-too-many-features-cause-over-fitting

I am thinking that 9x15x12 is still too big in input feature number.

For MNIST data set, input size is 28x28, and training sample is 60K, so the rate of training samples vs input feature = 78;
For ImageNet data set, input size is 3x224x224, and training sample is 14.2 million, so the rate of training sample vs input feature = 94.
For a common (x,y) 2D data point classification,   general we has 200 points,  so the rate for training sample vs input feature = 100;

For our 1806 training samples, it looks 20 input features is a good choice according to the above rough sense.

I am thinking whether we need to reduce input features to 20, for example, use 9x1x1 input, or some feature engineering like below:
Harris Corner Detection — Uses a Gaussian window function to detect corners. (read more)
Shi-Tomasi Corner Detector — The authors modified the scoring function used in Harris Corner Detection to achieve a better corner detection technique (read more)
Scale-Invariant Feature Transform (SIFT) — This technique is scale invariant unlike the previous two. (read more)
Speeded-Up Robust Features (SURF) — This is a faster version of SIFT as the name says. (read more)
Features from Accelerated Segment Test (FAST) — This is a much more faster corner detection technique compared to SURF. (read more)
Binary Robust Independent Elementary Features (BRIEF) — This is only a feature descriptor that can be used with any other feature detector. This technique reduces the memory usage by converting descriptors in floating point numbers to binary strings. (read more)
Oriented FAST and Rotated BRIEF (ORB) — SIFT and SURF are patented and this algorithm from OpenCV labs is a free alternative to them, that uses FAST keypoint detector and BRIEF descriptor. (read more)



# Dec 22nd, Tuesday, 2020
1  input image changes size from 9x31x512 to 9x31x25, 20 times reducing;
2  so we can increase batch size from 30 to 300;

expOCT_thickness2HyT_20201222_ResNet_A:  for 9x31x25 input
        channels:     [8, 16, 32, 64, 128] # the final channel is for FC layer
        dropoutRate: 0.5  # the dropout rate at final fully connected layer.
        at stable, training acc gets 84%, while validation accc gets 51%;
        at epoch 5, validation loss increases, while training loss decrease.
        TPR+TNR+ACC= Sum = 1.59, very low.

expOCT_thickness2HyT_20201222_ResNet_B:  for 9x31x25 input
        channels:     [4, 8, 16, 32, 64] # the final channel is for FC layer
        dropoutRate: 0.5  # the dropout rate at final fully connected layer.
        at stable, training acc gets 81%, while validation accc gets 50%;
        at epoch 21, validation loss increases, while training loss decrease.
        TPR+TNR+ACC= Sum = 1.637, low.





# Dec 18th, Friday, 2020

Professor,

If you have convenient time, please let me know.
I can show visualization training/validation loss, accuracy curves to you for all these experiments, which more more vivid.

=========================
Summary on traditional networks exploration:
Experements A series: Using VGG-16 network model:
     A. Used exactly VGG-16 4 layer (conv-maxPooling2d) +2FC layer model, with filter numbers[64, 128, 256, 512, 256]: Network get prediction of 1 (TPR=1, TNR=0)
        validation loss 0.6326, and then increase, it is explict overfitting;
     B. Added batchNormalization to VGG model with filter numbers [64, 128,256, 512, 256]:
        at epoch 69, training acc gets 1.0, while validation acc gets 0.54; Overfitting.
     C. gradually reduce network filter numbers to  [32, 64, 128, 256, 128], [16, 32, 64, 128, 128],
        [4, 8, 16, 32, 32],and [4, 4, 8, 8, 16]:
         they are still overfitting.  For the final [4,4,8,8,16] network,  at epoch 391, training acc gets 0.81, while validation acc gets 0.52.
         The key information is that all these networks do not reduce validation loss while training loss gradually reduces.

Experiment B series: Using ResNet network model:
     A. Used 4 layers with (Conv+ residualLink + max2dPooling) + 1FC model;
     B  initial channels: [32, 64, 128, 256, 512]: training accuracy quickly get 99% at epoch 74, while validation accuracy at 0.52.
     C  gradually reduce channels size  [8, 16, 32, 64, 128],  [4, 8, 16, 32, 32], [4, 4, 8, 8, 16];
        at final [4,4,8,8,16] model,  at epoch 378, training acc get 97%, while validation acc get 49%; TPR+TNR+ACC=Sum=1.60;

Expereiment C series: Using simple 2-layer model: 2 Conv+2dropout+1FC:
    After a series of network scale adjustments:
    expOCT2SysD_20201211_J: (the best)
    channels:     [16, 8]
    dropoutRates: [0.5,0.5]  # 2 dropout layers.
    at epoch 18, validaLoss > trainingLoss.  at stable, with training loss: 0.5909, validation loss: 0.6218
    threshold 0.44, TPR 0.71, TNR 0.51, Acc 0.62.  TPR+TNR+ACC=Sum=1.836

Experiment D series:  OCT thickness map predicts gender, instead of hypertension:
   A use same network, same input, but different binary ground truth (gender vs hypertension) from experiment C;
     (It just needs ONE line code modification from experiment C)
   B expOCT2Gender_20201218B_B:
        channels:     [16, 8]
        dropoutRates: [0.5,0.375]  # 2 dropout layers.
        at epoch  11, validationLoss > trainingLoss,
        At threshold  0.41, TPR 0.71 , TNR 0.73,    Acc 0.72 ,  TPR+TNR+ACc=Sum=2.151
   C Comparing experiment C and experiment D series, their only difference is different ground truth.
     OCT2Gender got better result than OCT2Hypertension. Different applications and data really matter.







#Dec 17th, Thursday, 2020
1  implemented HalfUnet model;  ResNet Model Architecture
    expOCT2SysD_20201217_HalfUnet_A:
        channels:     [32, 64, 128, 256, 512] # the final channel is for FC layer
        after epoch 15, overfitting;
        training accuracy quickly get 99% at epoch 74, while validation accuracy at 0.52.

    expOCT2SysD_20201217_HalfUnet_C:
        channels:     [8, 16, 32, 64, 128] # the final channel is for FC layer
        at epoch 20, validationLoss > training loss
        at epoch 95, training acc get 99%, while validation acc get 55%;

    expOCT2SysD_20201217_HalfUnet_B:
        channels:     [4, 8, 16, 32, 32] # the final channel is for FC layer
        at epoch 29, validationLoss > training loss
        at epoch 200, training acc get 99%, while validation acc get 52%;
    expOCT2SysD_20201217_HalfUnet_D:
        channels:     [4, 4, 8, 8, 16] # the final channel is for FC layer
        at epoch 13 , validationLoss > training loss
        at epoch 378, training acc get 97%, while validation acc get 49%;
        max TPR+TNR+ACC= sum=  1.60


2   standard VGG model:
    expOCT2SysD_20201216_VGG16_A: (standard VGG_16 model with only reducing one layer)
        channels:     [64, 128, 256, 512, 256]
        validationLoss is always less than trainingLoss;validationLoss = 0.6326; trainingLoss = 0.6331.
        validation always predict 1, majority prediction. TPR =1, TNR =0.

    expOCT2SysD_20201216_VGG16_B:
        channels:     [32, 64, 128, 256, 128]
        validationLoss is always less than trainingLoss;validationLoss = 0.6326; trainingLoss = 0.6331.
        validation always predict 1, majority prediction. TPR =1, TNR =0.

3  Add batchnorm to VGG16 model;
    expOCT2SysD_20201217_VGG16_A:
        channels:     [64, 128, 256, 512, 256]
        at epoch 69, training acc gets 1.0, while validation acc gets 0.54. Overfitting.

    expOCT2SysD_20201217_VGG16_B:
        channels:     [32, 64, 128, 256, 128]
        at epoch 69, training acc gets 1.0, while validation acc gets 0.53. Overfitting.

    expOCT2SysD_20201217_VGG16_C: cancel
        channels:     [16, 32, 64, 128, 128]

    expOCT2SysD_20201217_VGG16_D:  cancel
        channels:     [8, 16, 32, 64, 128]

    expOCT2SysD_20201217_VGG16_E:
        channels:     [4, 8, 16, 32, 32]
        at epoch 9, validationLoss > training loss
        at epoch 202, training acc gets 1.0, while validation acc gets 0.52. Overfitting.
    expOCT2SysD_20201217_VGG16_F:
        channels:     [4, 4, 8, 8, 16]
        at epoch 0, validationLoss > training loss
        at epoch 391, training acc gets 0.81, while validation acc gets 0.52. Overfitting.
        sum= 1.742.


4  prepare 2-layer network:
   expOCT2SysD_20201218E_A: remove norm before FC.
        channels:     [48, 16]
        dropoutRates: [0.5,0.8]  # 2 dropout layers.
        at epoch  181, validationLoss > trainingLoss, validation loss flat since then.
        At threshold 0.46 , TPR  0.76, TNR 0.41,    Acc 0.60,  Sum: 1.78

   expOCT2SysD_20201218E_B:
        channels:     [24, 16]
        dropoutRates: [0.5,0.8]  # 2 dropout layers.
        at epoch  85, validationLoss > trainingLoss, validation loss flat since then.
        At threshold  , TPR  , TNR ,    Acc ,  Sum: 1.751

   expOCT2SysD_20201218E_C:
        channels:     [16, 16]
        dropoutRates: [0.0, 0.8]  # 2 dropout layers.
        at epoch  49, validationLoss > trainingLoss, validation loss increases, overfitting.
        At threshold  , TPR  , TNR ,    Acc ,  Sum: 1.745

   expOCT2SysD_20201218E_D:
        channels:     [16, 8]
        dropoutRates: [0.5,0.625]  # 2 dropout layers.
        at epoch 19 , validationLoss > trainingLoss,
        At threshold  , TPR  , TNR ,    Acc ,  Sum: 1.762

   expOCT2SysD_20201218E_E:
        channels:     [16, 8]
        dropoutRates: [0.5,0.375]  # 2 dropout layers.
        at epoch  57, validationLoss > trainingLoss,
        At threshold  , TPR  , TNR ,    Acc ,  Sum: 1.792

    expOCT2SysD_20201219E_A: same with config of expOCT2SysD_20201211_J,  No norm before FC, (Good, not best)
        batchSize = 60
        channels:     [16, 8]
        dropoutRates: [0.5,0.5]  # 2 dropout layers.
        at stable of training, training acc 62%, while validation acc 60%
        at epoch  63, validationLoss > trainingLoss, and then validation loss reduce slowly, but training loss reduces a lot; No overfitting.
        At threshold  0.48, TPR 0.78 , TNR 0.40,    Acc 0.61  Sum: 1.792

5  OCT2Gender:
   expOCT2Gender_20201218B_A:
        channels:     [16, 8]
        dropoutRates: [0.5,0.625]  # 2 dropout layers.
        at epoch  38, validationLoss > trainingLoss; and the validatioin Loss slightly reduces;
        At threshold  0.49, TPR  0.69, TNR 0.69,  Acc 0.69,  Sum: 2.061


   expOCT2Gender_20201218B_B: (the best)
        channels:     [16, 8]
        dropoutRates: [0.5,0.375]  # 2 dropout layers.
        at epoch  11, validationLoss > trainingLoss,
        At threshold  0.41, TPR 0.71 , TNR 0.73,    Acc 0.72 ,  Sum: 2.151

   expOCT2Gender_20201218_ResNet_A:
        channels:     [8, 16, 32, 64, 128] # the final channel is for FC layer
        dropoutRate: 0.5  # the dropout rate at final fully connected layer.
        at epoch 310, training acc gets 1.0, while validation acc gets 66%;
        after epoch 99, validation loss increases, while training loss decreases.
        threshold 0.27   TPR 0.78   TNR 0.61    ACC 0.70     Sum 2.091

   expOCT2Gender_20201218_ResNet_B:
        channels:     [4, 8, 16, 32, 32] # the final channel is for FC layer
        dropoutRate: 0.5  # the dropout rate at final fully connected layer.
        at epoch 454, training acc gets 0.98, while validation acc gets 67%;
        after epoch 96, validation loss increases, while training loss decreases.
        threshold 0.48   TPR 0.65   TNR 0.74    ACC 0.69     Sum 2.079

   expOCT2Gender_20201219B_A:  same with config of expOCT2SysD_20201211_J,  No norm before FC,
        batchSize = 60
        channels:     [16, 8]
        dropoutRates: [0.5,0.5]  # 2 dropout layers.
        at statble stage, training acc 71%, validation acc 68%
        at epoch  5, validationLoss > trainingLoss. And validation slight increases, and flat.
        At threshold  0.46, TPR  0.71, TNR 0.70,    Acc  0.70,  Sum: 2.107



# Dec 16th, Wednesday, 2020
(base) [c-xwu000:dataPrepare]#python3 ./statisticsDataSet.py /home/hxie1/data/BES_3K/GTs/trainID_delNonExist_delErrWID_excludeMGM.csv gender 12binary None
total 1806 raw IDs in file /home/hxie1/data/BES_3K/GTs/trainID_delNonExist_delErrWID_excludeMGM.csv
values for gender have 1806 records
1 rate: 0.41472868217054265; 2 rate: 0.5852713178294574
emptyValueIDList = []

Thickness2Gender is training: nohup python3 ./OCT2SysD_Train.py ./testConfig/expOCT2Gender_20201216_A.yaml &
expOCT2Gender_20201216_A:
        channels:     [48, 24]
        dropoutRates: [0.5,0.8]  # 2 dropout layers.
        at epoch  109, validationLoss > trainingLoss, validation loss flat since then.
        At threshold 0.49 , TPR  0.66, TNR 0.73,    Acc 0.69,  Sum: 2.071



About applying traditional baseline network:
As our thickmap has a size 9x31x512, where 9 is channel, 31 is image height, and 512 is image width.
Below I listed standard traditional baseline network architectures for our OCT to hypertension application:
1  MobileNetv3: Its small model has 11 layers with filter size 3x3 or 5x5. Our image height 31 will reduce to 1 at the 5th layer,
                and following 6 layers with 5x5 convolution on 1 element in height will be meaningless.
2  VGG-16: it has 5 max pooling layer with filter 2x2 with stride 2, following 3 dense layers.
           At the 4th pooling layer, our image height reduces to 1, leading following 3x3 conv and 3 dense layers meaningless.
3  GoogleNet: it has 22 layers with filer size 7x7 and 3x3, after the 3th layer, our image height 31 will reduce to 1. Same conclusion with the above;
4  ResNet:    It has 34 layers with 7x7 and 3x3 convolution. It is too deep for our image height 31.

5  launched 2 variants of VGG16: 4 (Cov+ maxPooling) layers + 2 FC layers:
expOCT2SysD_20201216_VGG16_A: (standard VGG_16 model with only reducing one layer)
channels:     [64, 128, 256, 512, 256]
       validationLoss is always less than trainingLoss;validationLoss = 0.6326; trainingLoss = 0.6331.
       validation always predict 1, majority prediction. TPR =1, TNR =0.

expOCT2SysD_20201216_VGG16_B:
        channels:     [32, 64, 128, 256, 128]
        validationLoss is always less than trainingLoss;validationLoss = 0.6326; trainingLoss = 0.6331.
        validation always predict 1, majority prediction. TPR =1, TNR =0.




# Dec 15th, Tuesday, 2020
Meeting with professor:
1  use traditional baseline models for classification;
2  may use SVM to classification;

Further improve OCT2Hypertension Network:
expOCT2SysD_20201211_M:
    channels:     [48, 16]
    dropoutRates: [0.0,0.8]  # 2 dropout layers.
    at epoch  10, validationLoss > trainingLoss, validation loss increases;
    At threshold 0.45, TPR  0.72, TNR 0.45,    Acc 0.60 ,  Sum: 1.762

expOCT2SysD_20201211_N:
    channels:     [48, 16]
    dropoutRates: [0.2,0.8]  # 2 dropout layers.
    at epoch 52 , validationLoss > trainingLoss, validation loss flats;
    At threshold 0.50 , TPR 0.62 , TNR 0.54 ,    Acc 0.59,  Sum: 1.76

expOCT2SysD_20201211_P:
    channels:     [48, 16]
    dropoutRates: [0.5,0.8]  # 2 dropout layers.   (best)
    at epoch  105, validationLoss > trainingLoss, validation loss slightly increases and flats;
    At threshold  0.46, TPR  0.70, TNR 0.51,    Acc 0.61,  Sum: 1.824

expOCT2SysD_20201211_Q:
    channels:     [48, 16]
    dropoutRates: [0.5,0.5]  # 2 dropout layers.
    at epoch  43 , validationLoss > trainingLoss, validation loss slightly increase, flats;
    At threshold 0.44, TPR 0,65, TNR 0.54,    Acc 0.80,  Sum: 1.8

expOCT2SysD_20201211_R:
    channels:     [48, 24]
    dropoutRates: [0.5,0.8]  # 2 dropout layers.
    at epoch  109, validationLoss > trainingLoss, validation loss flat since then.
    At threshold 0.48 , TPR  0.73, TNR 0.46,    Acc 0.60,  Sum: 1.793


# Dec 14th, 2020
Experiment on Lnx-idea006.ecn.uiowa.edu:
Experiment: expOCT2SysD_20201211_J
Net starts training from scratch, and save at /home/hxie1/data/BES_3K/netParameters/ThicknessMap2HyperTensionNet_C/expOCT2SysD_20201211_J
Experiment: expOCT2SysD_20201211_E
Net starts training from scratch, and save at /home/hxie1/data/BES_3K/netParameters/ThicknessMap2HyperTensionNet_C/expOCT2SysD_20201211_E
Experiment: expOCT2SysD_20201211_H
Net starts training from scratch, and save at /home/hxie1/data/BES_3K/netParameters/ThicknessMap2HyperTensionNet_C/expOCT2SysD_20201211_H
Experiment: expOCT2SysD_20201211_F
Net starts training from scratch, and save at /home/hxie1/data/BES_3K/netParameters/ThicknessMap2HyperTensionNet_C/expOCT2SysD_20201211_F
Experiment: expOCT2SysD_20201211_I
Net starts training from scratch, and save at /home/hxie1/data/BES_3K/netParameters/ThicknessMap2HyperTensionNet_C/expOCT2SysD_20201211_I
Experiment: expOCT2SysD_20201211_G
Net starts training from scratch, and save at /home/hxie1/data/BES_3K/netParameters/ThicknessMap2HyperTensionNet_C/expOCT2SysD_20201211_G

Program in c-xwu000:
(base) [c-xwu000:network]#ps 23367 23346 23269 30671
  PID TTY      STAT   TIME COMMAND
23269 ?        Rl   2826:34 python3 ./OCT2SysD_Train.py ./testConfig/expOCT2SysD_20201212_C.yaml
23346 ?        Rl   2823:30 python3 ./OCT2SysD_Train.py ./testConfig/expOCT2SysD_20201212_B.yaml
23367 ?        Rl   2823:33 python3 ./OCT2SysD_Train.py ./testConfig/expOCT2SysD_20201212_D.yaml
30671 ?        Rl   2110:31 python3 ./OCT2SysD_Train.py ./testConfig/expOCT2SysD_20201212_J.yaml

program in c-iibi007:
ps 104438 104116 104226 104297 104369
   PID TTY      STAT   TIME COMMAND
104116 ?        Rl   2192:51 python3 ./OCT2SysD_Train.py ./testConfig/expOCT2SysD_20201212_E_iibi007.yaml
104226 ?        Rl   2190:57 python3 ./OCT2SysD_Train.py ./testConfig/expOCT2SysD_20201212_F_iibi007.yaml
104297 ?        Rl   2193:27 python3 ./OCT2SysD_Train.py ./testConfig/expOCT2SysD_20201212_G_iibi007.yaml
104369 ?        Rl   2209:29 python3 ./OCT2SysD_Train.py ./testConfig/expOCT2SysD_20201212_H_iibi007.yaml
104438 ?        Rl   2210:10 python3 ./OCT2SysD_Train.py ./testConfig/expOCT2SysD_20201212_I_iibi007.yaml

Analysis:
Best network for 1Conv + 1FC layer:
    expOCT2SysD_20201212_E:  on lnx-idea005 _> iibi007
    channels:     [32]  # 1 conv +avgPooling+ 1 FC
    dropoutRates: [0.8]  # 1 dropout layers.
    at epoch 57, validaLoss > trainingLoss.  but validation still decrease, with training loss: 0.6149, validation loss: 0.6223
    threshold 0.46, TPR 0.78, TNR 0.42, Acc 0.61.

Best network for 2Conv + 1Fc layer:
    expOCT2SysD_20201211_I: in lnx-idea006.ecn.uiowa.edu   (worth to research.)
    channels:     [32, 16]
    dropoutRates: [0.8,0.8]  # 2 dropout layers.
    at epoch 700, validaLoss = trainingLoss.  No explict overfitting, with training loss: 0.6261, validation loss: 0.6248
    threshold 0.47, TPR 0.84, TNR 0.35, Acc 0.62.

    expOCT2SysD_20201211_J: in lnx-idea006.ecn.uiowa.edu  (the best)
    channels:     [16, 8]
    dropoutRates: [0.5,0.5]  # 2 dropout layers.
    at epoch 18, validaLoss > trainingLoss.  overfitting. But sum is 1.823, with training loss: 0.5909, validation loss: 0.6218
    threshold 0.44, TPR 0.71, TNR 0.51, Acc 0.62.  sum: 1.836

Further improvement, and reduce batchSize:
expOCT2SysD_20201211_K:
    channels:     [16, 8]
    dropoutRates: [0.8,0.8]  # 2 dropout layers.
    No overfitting. It looks underfitting.
    threshold  0.49, TPR 0.84 , TNR 0.28,   Acc 0.59, sum 1.719

expOCT2SysD_20201211_L:
    channels:     [48, 16]
    dropoutRates: [0.8,0.8]  # 2 dropout layers.  (best)
    No overfitting, validation loss lock at 0.6244.  validation loss has same trend with training loss.
    threshold  0.48, TPR 0.79 , TNR 0.39,   Acc 0.61.  Sum: 1.797.

expOCT2SysD_20201212_K:  same with config expOCT2SysD_20201212_E
    channels:     [32]  # 1 conv +avgPooling+ 1 FC
    dropoutRates: [0.8]  # 1 dropout layers.
    at epoch 71, validationLoss > trainingLoss
    threshold  0.50, TPR  0.63, TNR 0.56 , Acc 0.60

expOCT2SysD_20201212_L:
    channels:     [24]  # 1 conv +avgPooling+ 1 FC
    dropoutRates: [0.8]  # 1 dropout layers.
    at epoch 71, validationLoss > trainingLoss
    threshold  0.49, TPR 0.65 , TNR 0.55,   Acc 0.60

expOCT2SysD_20201212_M:  on c-iibi007
    channels:     [1]  # 1 conv +avgPooling+ 1 FC
    dropoutRates: [0]  # 1 dropout layers =0 .
    at stable stage: validation loss is 0.6281, training loss is 0.6002.
    at threhold 0.45, TPR 0.62, TNR 0.55, Acc 0.59, Sum is 1..76

On Dec 14th,2020, 20:00, suspend below program:
python3 ./OCT2SysD_Train.py ./testConfig/expOCT2SysD_20201211_K.yaml
at Dec 14th, 2020, 20:41, resume the above progam.


# Dec 12th, Saturday,2020
Now 3 training programs are running on lnx-idea006.ecn.uiowa.edu.
Current program:
Gradually reduce network complexity (8 layers, 4 layers, 2 layers), and did experiments to reduce overfitting of thickness2Hypertension
thickness2Hypertension network now uses 2 layer network.
got result:threshold 0.47, TPR 0.71, TNR 0.49, Accuracy 0.61 on validation data with 45.6% of 0s and 54.4% of 1s.
But network still get overfitting at 30 epochs.
use the contrast of validation and training loss, instead of accuracy, to judge the reflection point of over-fitting;
loss directly indicates the error with respect with ground truth, without other factors;
while accuracy needs another threshold to measure accuracy values, and different thresholds will lead different accuracy values.





(base) [lnx-idea006:network]#nvidia-smi
Sat Dec 12 12:31:55 2020
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 455.45.01    Driver Version: 455.45.01    CUDA Version: 11.1     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Quadro RTX 6000     On   | 00000000:01:00.0 Off |                  Off |
| 34%   40C    P8    30W / 260W |     49MiB / 24215MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   1  Quadro RTX 6000     On   | 00000000:4B:00.0 Off |                  Off |
| 34%   49C    P2   175W / 260W |  20969MiB / 24220MiB |    100%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0   N/A  N/A      1529      G   /usr/lib/xorg/Xorg                 38MiB |
|    0   N/A  N/A      1916      G   /usr/bin/gnome-shell                6MiB |
|    0   N/A  N/A     17007      C   python3                             0MiB |
|    0   N/A  N/A     17055      C   python3                             0MiB |
|    0   N/A  N/A     17090      C   python3                             0MiB |
|    1   N/A  N/A      1529      G   /usr/lib/xorg/Xorg                  4MiB |
|    1   N/A  N/A      1916      G   /usr/bin/gnome-shell                0MiB |
|    1   N/A  N/A     17007      C   python3                          6987MiB |
|    1   N/A  N/A     17055      C   python3                          6987MiB |
|    1   N/A  N/A     17090      C   python3                          6987MiB |
+-----------------------------------------------------------------------------+
(base) [lnx-idea006:network]#ps 17007 17055 17090
    PID TTY      STAT   TIME COMMAND
  17007 pts/0    Rl     2:22 python3 ./OCT2SysD_Train.py ./testConfig/expOCT2SysD_20201211_E.yaml
  17055 pts/0    Rl     1:46 python3 ./OCT2SysD_Train.py ./testConfig/expOCT2SysD_20201211_F.yaml
  17090 pts/0    Rl     1:24 python3 ./OCT2SysD_Train.py ./testConfig/expOCT2SysD_20201211_G.yaml
(base) [lnx-idea006:network]#^C
(base) [lnx-idea006:network]#


#Dec 11th, Friday, 2020
lessons:
1  use the contrast of validation and training loss, instead of accuracy, to judge the reflection point of over-fitting;
   loss directly indicates the error with respect with ground truth, without other factors;
   while accuracy needs another threshold to measure accuracy values, and different thresholds will lead different accuracy values,
2  Training accuracy stuck at some point(e.g. 67%) means network that network stucks at a local minimum;

current best result: 20201210_D;




# Dec 10th, Thursday, 2020
Current the best result: expOCT2SysD_20201205_D:




# Dec 8th, 2020
"Overfitting is also caused by a deep model over training data. In that case, you'll observe divergence in loss between val and train very early."
--https://datascience.stackexchange.com/questions/43191/validation-loss-is-not-decreasing

# Dec 4th, Friday, 2020
The memory footprint of full loading all data into memory:
For Tongren data:
42*31*496*512*4 = 1.32 GB
For BES_3K thickness data:
2288*9*31*512*4 = 1.307 GB
1.307 GB x2   = 2.614 GB  for OD/OS eyes together.
Therefore all BES_3K all training and validation data can load into memory at dataset initialization.  --done

Observe the mean and std of thickness map:
(base) [c-xwu000:dataPrepare]#python3.7 ./statisticsThicknessMap.py /home/hxie1/data/BES_3K/W512NumpyVolumes/log/SurfacesNet/expBES3K_20201126A_genXml/testResult/thicknessEnfaceMap/33089_OS_7812_Volume_thickness_enface.npy
thicknessMap: C=9, H=31, W=512 for all below files:

/home/hxie1/data/BES_3K/W512NumpyVolumes/log/SurfacesNet/expBES3K_20201126A_genXml/testResult/thicknessEnfaceMap/33089_OS_7812_Volume_thickness_enface.npy:
 mean= 30.530215236283237, std=15.603827787207281
/home/hxie1/data/BES_3K/W512NumpyVolumes/log/SurfacesNet/expBES3K_20201126A_genXml/testResult/thicknessEnfaceMap/979_OD_8857_Volume_thickness_enface.npy:
 mean= 29.698770283127836, std=21.908612855917635
/home/hxie1/data/BES_3K/W512NumpyVolumes/log/SurfacesNet/expBES3K_20201126A_genXml/testResult/thicknessEnfaceMap/1955_OS_14474_Volume_thickness_enface.npy:
 mean= 32.7970074596143, std=17.958001387144986
/home/hxie1/data/BES_3K/W512NumpyVolumes/log/SurfacesNet/expBES3K_20201126A_genXml/testResult/thicknessEnfaceMap/1858_OD_13526_Volume_thickness_enface.npy:
 mean= 34.320023420447065, std=21.11553166304982

 Therefore, our Guassian noise to the thickness is N(0, 3) , which is about 20% of std of original thickness map.  --done;

 # delete ID for no xml file
 ID: 574,  from trianID

Todo:
1  all training data do a normalization and save its mean and std for validation and test data to use; --done
2  change gaussian noise std to 0.1 after the input data has normalization;   --done.

Experiment:
expOCT2SysD_20201204_A:  channels: [30, 30, 30, 60, 60, 60, 60, 60],
                         Result: Overfitting.
                         at epoch 100, training loss = 0.00164, and validation loss = 2.706
                         at stable status, validation acc = 54%
expOCT2SysD_20201204_B:  channels: [15, 15, 15, 30, 30, 30, 30, 30],
                         Result: Overfitting.
                         at epoch 100, training loss = 0.0117, and validation loss = 2.56
                         at stable status, validation acc = 53%

expOCT2SysD_20201205_A:  channels: [9, 9, 9, 15, 15, 15, 15, 15]
                         Result: Overfitting. Stop training at 40 epochs.

expOCT2SysD_20201205_B:  channels: [9, 9, 9, 9, 9, 9, 9, 9]
                         Result: Overfitting. at 300 epochs, traiing accruacy get 93% while validation get 50%;


expOCT2SysD_20201205_C: channels: [9, 8, 7, 6, 5, 4, 3, 3]
                        Result: overfitting.  at 300 epochs, traiing accruacy get 85% while validation get 55%;
                        at epoch 8. validation start exceed and deviate from training loss.



expOCT2SysD_20201205_D: channels:     [9, 8, 7, 6, 5, 4, 3, 3]
                        dropoutRates: [0.5,0.4,0.3,0.0, 0.5, 0.25, 0.0]  # 7 dropout layers.
                        validation accuray is 56%, and training accuracy is 58%.
                        at epoch 42, validation loss > training loss.
                        at threshold 0.45,  TPR 70%, TNR 0.47, Acc 60.0%


expOCT2SysD_20201205_E: channels:     [6, 6, 6, 6, 6, 6, 6, 6]
                        dropoutRates: [0.5,0.4,0.3,0.0, 0.5, 0.25, 0.0]  # # 7 dropout layers.
                        validation accuray is 55%, and training accuracy is 58%.
                        at epoch 34, validation loss > training loss.
                        at threshold 0.4333,  TPR 74%, TNR 0.43, Acc 60.0%


expOCT2SysD_20201205_F: channels:     [6, 6, 6, 6, 6, 6, 6, 6]
                        dropoutRates: [0.5,0.5,0.5,0.5, 0.5, 0.5, 0.0]  # # 7 dropout layers.
                        validation accuray is 45%, and training accuracy is 47%.
                        at epoch 159, validation loss > training loss.
                        at threshold 0.497,  TPR 1.0, TNR 0, Acc 54%

expOCT2SysD_20201205_G: channels:     [9, 8, 7, 6, 5, 4, 3, 3]
                        dropoutRates: [0.5,0.4,0.3,0.3, 0.5, 0.25, 0.0]  # # 7 dropout layers.
                        validation accuray is 55%, and training accuracy is 58%.
                        at epoch 45, validation loss > training loss.
                        at threshold 0.485,  TPR 0.685, TNR 0.474, Acc 59.5%

# add network capacities, and validation data without augmentation.
expOCT2SysD_20201206_D: channels:     [90, 80, 70, 60, 50, 40, 30, 30]
                        dropoutRates: [0.5,0.4,0.3,0.0, 0.5, 0.25, 0.0]  # 7 dropout layers.
                        validation accuray is 56%, and training accuracy is 69% at stable phase.
                        at epoch 5, validation loss > training loss.
                        at threshold 0.50,  TPR 53%, TNR 0.62, Acc 57.0%


expOCT2SysD_20201206_E: channels:     [60, 60, 60, 60, 60, 60, 60, 60]
                        dropoutRates: [0.5,0.4,0.3,0.0, 0.5, 0.25, 0.0]  # 7 dropout layers.
                        validation accuray is 55%, and training accuracy is 67%.
                        at epoch 10, validation loss > training loss.
                        at threshold 0.4333,  TPR 66%, TNR 0.47, Acc 58.0%


expOCT2SysD_20201206_F: channels:     [60, 60, 60, 60, 60, 60, 60, 60]
                        dropoutRates: [0.5,0.5,0.5,0.5, 0.5, 0.5, 0.0]  # 7 dropout layers.
                        validation accuray is 58%, and training accuracy is 60%.
                        at epoch 9, validation loss > training loss.
                        at threshold 0.48  TPR 62%, TNR 55%, Acc 59%

expOCT2SysD_20201206_G: channels:     [90, 80, 70, 60, 50, 40, 30, 30]
                        dropoutRates: [0.5,0.4,0.3,0.3, 0.5, 0.25, 0.0]  # 7 dropout layers.
                        validation accuray is 57%, and training accuracy is 64%.
                        at epoch 10, validation loss > training loss.
                        at threshold 0.485,  TPR 0.56, TNR 0.59, Acc 58%

# cancel dropout at beginning of network layers.
expOCT2SysD_20201206_D:  channels:     [9, 8, 7, 6, 5, 4, 3, 3]
                         dropoutRates: [0.0,0.0,0.0,0.0, 0.5, 0.25, 0.0]  # 7 dropout layers.
                         validation accuray is 55%, and training accuracy is 76%.
                        at epoch 1, validation loss > training loss.
                        at threshold 0.31,  TPR 0.69, TNR 0.42, Acc 57%

expOCT2SysD_20201207_E:  channels:     [6, 6, 6, 6, 6, 6, 6, 6]
                         dropoutRates: [0.0,0.0,0.0,0.0, 0.5, 0.25, 0.0]  # 7 dropout layers.
                         validation accuray is 54%, and training accuracy is 71%.
                        at epoch 12, validation loss > training loss.
                        at threshold 0.31,  TPR 0.76, TNR 0.33, Acc 57%

expOCT2SysD_20201207_F:  channels:     [6, 6, 6, 6, 6, 6, 6, 6]
                         dropoutRates: [0.0,0.0,0.0,0.0, 0.5, 0.5, 0.0]  # 7 dropout layers.
                         validation accuray is 54%, and training accuracy is 74%.
                        at epoch 6, validation loss > training loss.
                        at threshold 0.39,  TPR 0.70, TNR 0.40, Acc 56%

expOCT2SysD_20201207_G: channels:     [9, 8, 7, 6, 5, 4, 3, 3]
                        dropoutRates: [0.0,0.0,0.0,0.0, 0.5, 0.0, 0.0]  # 7 dropout layers.
                        validation accuray is 54%, and training accuracy is 77%.
                        at epoch 5, validation loss > training loss.
                        at threshold 0.72,  TPR 0.33, TNR 0.77 Acc 53%

# Dec 10th, 2020: change 4 FC layers into a AvgPooling + 1 FC:
# as accuracy depends on threshold, using loss to judge reflection point is better
expOCT2SysD_20201210_A: channels:     [9, 8, 7, 6]
                        dropoutRates: [0.0,0.0,0.0,0.0]  # 4 dropout layers.
                        at stable stage: 100 epochs,  training acc: 77% continue increasing  , validation acc: 54%
                        at epoch 2, validation loss > training loss.
                        at threshold 0.44,  TPR 0.63, TNR 0.55 , Acc 0.55


expOCT2SysD_20201210_B: channels:     [64, 64, 64, 64]
                        dropoutRates: [0.0,0.0,0.0,0.0]  # 4 dropout layers.
                        at stable stage: training acc: 99% , validation acc: 52%
                        at epoch 3, validation loss > training loss.
                        at threshold 0.90,  TPR 0.38, TNR 0.69 , Acc 0.52


expOCT2SysD_20201210_C: channels:     [32, 32, 32, 32]
                        dropoutRates: [0.0,0.0,0.0,0.0]  # 4 dropout layers.
                        at stable stage: training acc: 99% , validation acc: 54%
                        at epoch 0, validation loss > training loss.
                        at threshold 0.55,  TPR 0.57, TNR 0.52 , Acc 0.55

expOCT2SysD_20201210_D: channels:     [64, 64, 64, 64]
                        dropoutRates: [0.0,0.5,0.5,0.5]  # 4 dropout layers.
                        at stable stage: training acc: 69% , validation acc: 55%
                        at epoch 3, validation loss > training loss.
                        at threshold 0.46,  TPR 0.69, TNR 0.47 , Acc 0.59

# use 2 conv layer network with(31,31) filters.
expOCT2SysD_20201211_A:
channels:     [128, 64]
dropoutRates: [0.5,0.5]  # 2 dropout layers.
stable at training 0.77, validation 0.56
at epoch 8, validaLoss > trainingLoss.
threshold 0.48,, TPR 0.73, TNR 0.46, Acc 0.61.

expOCT2SysD_20201211_B:
channels:     [256, 128]
dropoutRates: [0.8,0.8]  # 2 dropout layers.
at epoch 43, validaLoss > trainingLoss.  overfitting.
threshold 0.47,, TPR 0.67, TNR 0.52, Acc 0.61.

expOCT2SysD_20201211_C:
channels:     [128, 64]
dropoutRates: [0.8,0.8]  # 2 dropout layers.
at epoch 76, validaLoss > trainingLoss.  overfitting
threshold 0.46,, TPR 0.76, TNR 0.42, Acc 0.61.

expOCT2SysD_20201211_D:
channels:     [64, 64]
dropoutRates: [0.5,0.5]  # 2 dropout layers.
at epoch 13, validaLoss > trainingLoss.
threshold 0.45,, TPR 0.70, TNR 0.50, Acc 0.61.
=======================================================
expOCT2SysD_20201211_E: in lnx-idea006.ecn.uiowa.edu
channels:     [64, 64]
dropoutRates: [0.8,0.8]  # 2 dropout layers.
at epoch 39, validaLoss > trainingLoss.  overfitting
threshold 0.47, TPR 0.66, TNR 0.53, Acc 0.60.

expOCT2SysD_20201211_F: in lnx-idea006.ecn.uiowa.edu
channels:     [512, 256]
dropoutRates: [0.8,0.8]  # 2 dropout layers.
at epoch 33, validaLoss > trainingLoss.  overfitting
threshold 0.48, TPR 0.66, TNR 0.52, Acc 0.60.

expOCT2SysD_20201211_G: in lnx-idea006.ecn.uiowa.edu
channels:     [128, 128]
dropoutRates: [0.8,0.8]  # 2 dropout layers.
at epoch 45, validaLoss > trainingLoss.  overfitting. validation loss didn't increase.
threshold 0.50, TPR 0.64, TNR 0.55, Acc 0.60.

expOCT2SysD_20201211_H: in lnx-idea006.ecn.uiowa.edu  (worth to research.)
channels:     [64, 32]
dropoutRates: [0.8,0.8]  # 2 dropout layers.
at epoch 625, validaLoss =  trainingLoss.  No explict overfitting
threshold 0.46, TPR 0.79, TNR 0.40, Acc 0.61.

expOCT2SysD_20201211_I: in lnx-idea006.ecn.uiowa.edu   (worth to research.)
channels:     [32, 16]
dropoutRates: [0.8,0.8]  # 2 dropout layers.
at epoch 700, validaLoss = trainingLoss.  No explict overfitting
threshold 0.47, TPR 0.84, TNR 0.35, Acc 0.62.  Sum= 1.807

expOCT2SysD_20201211_J: in lnx-idea006.ecn.uiowa.edu
channels:     [16, 8]
dropoutRates: [0.5,0.5]  # 2 dropout layers.
at epoch 18, validaLoss > trainingLoss.  overfitting. But sum is 1.823
threshold 0.44, TPR 0.67, TNR 0.55, Acc 0.61.


==============================================
# one layer network  on Dec 12th, 2020
expOCT2SysD_20201212_A:  on c-xwu000
channels:     [512]  # 1 conv +avgPooling+ 1 FC
dropoutRates: [0.8]  # 1 dropout layers.
at epoch 15, validationLoss > trainingLoss.


expOCT2SysD_20201212_B: on c-xwu000
channels:     [256]  # 1 conv +avgPooling+ 1 FC
dropoutRates: [0.8]  # 1 dropout layers.
at epoch 44, validationLoss > trainingLoss.  Validaiton loss increase after inflection point. explict overfitting.
threshold 0.46, TPR 0.7, TNR 0.49, Acc 0.61


expOCT2SysD_20201212_C:  on c-xwu000
channels:     [128]  # 1 conv +avgPooling+ 1 FC
dropoutRates: [0.8]  # 1 dropout layers.
at epoch 44, validationLoss > trainingLoss.
threshold 0.46, TPR 0.73, TNR 0.45, Acc 0.60


expOCT2SysD_20201212_D:  on c-xwu000
channels:     [64]  # 1 conv +avgPooling+ 1 FC
dropoutRates: [0.8]  # 1 dropout layers.
at epoch 54, validationLoss > trainingLoss. overfitting.
threshold 0.49, TPR 0.62, TNR 0.57, Acc 0.60

===========================================

expOCT2SysD_20201212_E:  on lnx-idea005 _> iibi007
channels:     [32]  # 1 conv +avgPooling+ 1 FC
dropoutRates: [0.8]  # 1 dropout layers.
at epoch 57, validaLoss > trainingLoss.  but validation still decrease. (Not bad)
threshold 0.46, TPR 0.78, TNR 0.42, Acc 0.61.

expOCT2SysD_20201212_F:  on lnx-idea005 _> iibi007
channels:     [32]  # 1 conv +avgPooling+ 1 FC
dropoutRates: [0.5]  # 1 dropout layers.
at epoch 13, validaLoss > trainingLoss.  explict overfitting, validation loss increases.
threshold 0.47, TPR 0.64, TNR 0.53, Acc 0.59.

expOCT2SysD_20201212_G:  on lnx-idea005 _> iibi007
channels:     [16]  # 1 conv +avgPooling+ 1 FC
dropoutRates: [0.8]  # 1 dropout layers.
at epoch 69, validaLoss > trainingLoss.   a liitle overfitting.
threshold 0.47, TPR 0.77, TNR 0.40, Acc 0.60.


expOCT2SysD_20201212_H:  on lnx-idea005 _> iibi007
channels:     [16]  # 1 conv +avgPooling+ 1 FC
dropoutRates: [0.5]  # 1 dropout layers.
at epoch 15, validaLoss > trainingLoss.  explicit overfitting.
threshold 0.47, TPR 0.72, TNR 0.47, Acc 0.60.

expOCT2SysD_20201212_I:  on lnx-idea005 _> iibi007
channels:     [8]  # 1 conv +avgPooling+ 1 FC
dropoutRates: [0.5]  # 1 dropout layers.
at epoch 22, validaLoss > trainingLoss.  explicit overfitting.
threshold 0.46, TPR 0.74, TNR 0.43, Acc 0.60.

expOCT2SysD_20201212_J:  on lnx-idea005  _> c-xwu000 with pid: 30671  (too small is also not good.)
channels:     [4]  # 1 conv +avgPooling+ 1 FC
dropoutRates: [0.5]  # 1 dropout layers.
at epoch 20, validaLoss > trainingLoss.  overfitting.
threshold 0.49, TPR 0.69, TNR 0.47, Acc 0.58.


# Dec 3th, Thursday, 2020
generated all thickness enface images with 3x3 smooth filter.
at /home/hxie1/data/BES_3K/W512NumpyVolumes/log/SurfacesNet/expBES3K_20201126A_genXml/testResult/thicknessEnfaceMap

statistics age:
python3.7 ./statisticsDataSet.py /home/hxie1/data/BES_3K/GTs/trainID_delNonExist_delErrWID_excludeMGM.csv Age$ number None
total 1807 raw IDs in file /home/hxie1/data/BES_3K/GTs/trainID_delNonExist_delErrWID_excludeMGM.csv
values for Age$ have 1807 records
min=50.0; mean=63.38295517432208; max=93.0

python3.7 ./statisticsDataSet.py /home/hxie1/data/BES_3K/GTs/validationID_delNonExist_delErrWID_excludeMGM.csv Age$ number None
total 481 raw IDs in file /home/hxie1/data/BES_3K/GTs/validationID_delNonExist_delErrWID_excludeMGM.csv
values for Age$ have 481 records
min=50.0; mean=64.17671517671518; max=88.0

python3.7 ./statisticsDataSet.py /home/hxie1/data/BES_3K/GTs/testID_delNonExist_delErrWID_excludeMGM.csv Age$ number None
total 502 raw IDs in file /home/hxie1/data/BES_3K/GTs/testID_delNonExist_delErrWID_excludeMGM.csv
values for Age$ have 502 records
min=50.0; mean=63.83864541832669; max=87.0

Age prediction:
Han Peng, Weikang Gong, Christian F. Beckmann, Andrea Vedaldi, Stephen M. Smith.
``Accurate brain age prediction with lightweight deep neural networks"
bioRxiv 2019.12.17.879346; doi: https://doi.org/10.1101/2019.12.17.879346
used KL divergence loss with a gaussian distribution of mu=age, and sigma=1.

Age range: 40-100.

Network design for age:
1  layer as channel, input 2D conv network;
2  basic layer design:
layer name,   ouputSize,    channels,
input         31x512        9
conv_3x3      16x256        30
conv_3x3      8x128         30
conv_3x3      4x64          30
conv_3x3      2x32          60
conv_2x3      1x16          60
conv_1x4      1x8           60
conv_1x4      1x4           60
conv_1x4      1x1           60
conv_1x1      1x1           60
softmax       1x1           60
3  use 2 losses:
   A  KL divergence loss with mu=age, sigma=1;
   B  soft argmax + MSE;

Professor Wu directed first to do hypertension prediction.

Network design for hypertension:
1  layer as channel, input 2D conv network;
2  basic layer design:
layer name,   ouputSize,    channels,
input         31x512        9
conv_3x3      16x256        30
conv_3x3      8x128         30
conv_3x3      4x64          30
conv_3x3      2x32          60
conv_2x3      1x16          60
conv_1x4      1x8           60
conv_1x4      1x4           60
conv_1x4      1x1           60
conv_1x1      1x1           60
FC             1
BCEWithLogitsLoss      1






# Dec 1st, 2020
read a paper:
Yim, J., Chopra, R., Spitz, T. et al.
Predicting conversion to wet age-related macular degeneration using deep learning.
Nat Med 26, 892–899 (2020). https://doi.org/10.1038/s41591-020-0867-7

This paper from DeepMind used 3D one-hot-code tissue segmentation maps and raw 3D OCT image to ensemble to predict
the exAMD conversion of the follow eye after the first eye diagnosed as exAMD. It first segments OCT into 13 tissues and 3 artifacts
including vitreous body, neural retina, RPE, and hyper-reflective foci etc, and then code this 3D segmentation into one-hot
segmentation map as 13 channels to feed a 3D-dense-analog classification network to predict exAMD. And raw 3D OCT also feed a 3D-dense-analog
classification network to predict exAMD. Its ensemble is interesting which includes each fold model of 4-fold cross validation,
and each fold has 4 different initial parameter model, and 2 path(raw 3D OCT and segmentation map), so total 4x3x2 models ensemble with TTA.

This is an excellent paper, but with huge hardware resource. It trained 300K epochs in 16 GPUs for just one model,
which is not achievable in common university labs.

Its one-hot-code tissue segmentation map and reduced-parameter dense block design can be our reference in the future.



# Nov 26th, 2020
some raw images has problems:
1  91002_OD_4330_Volume data has problem. but it is not at hour training,validation, test set;

# Nov 25th, Wednesday, 2020
Meeting minute of OCT2SysDisease on Nov 24th, 2020
Attendants: Prof. Wu, Prof. Wang, Hui
Time: 20:00-21:30(Iowa Time) Nov 24th, 2020
Minutes:
1  It is better to choose big/major diseases:first hypertension, then diabetes;
2  The core of this project is not at prediction self; it is at the backward retina manifestation or retina impairment of systemic diseases;
3  Thickness map is the most important input, which can consider to use an average of 3x3 grid to alleviate segmentation error;
   A  use thickness map to predict age;
   B  use thickness map to predict hypertension;
   C  use thickness map to predict the severity of hypertension (systolic blood level);
4  Further design for next phase:
   A  description of the surface curvature may act as an input;
   B  axial length can be an input to judge its relation with hypertension;
   C  use thickness map plus 3D layer texture as input;
   D  use the OCT volume 5 years before strokes occur to predict stroke;
   E  use retina layer while keeping its layer curvature without flatting;

Professor Wu's comment:
1  It is better to choose big/major diseases:first hypertension, then diabetes;
2  The core of this project is not at prediction self; it is at the backward retina manifestation or retina impairment of systemic diseases;
3  Thickness map is the most important input, which can consider to use an average of 3x3 grid to alleviate segmentation error;
   A  use thickness map to predict age;
It should not be a prediction problem, but study the thickness changes with respect to ages.
   B  use thickness map to predict hypertension;
then to identify the retina impairment by hypertension.
   C  use thickness map to predict the severity of hypertension (systolic blood level);
4  Further design for next phase:
   A  description of the surface curvature may act as an input;
According to Prof. Wang, may NOT consider surface curvatures.
   B  axial length can be an input to judge its relation with hypertension;
   C  use thickness map plus 3D layer texture as input;
Let's see the results from the first experiment first.
   D  use the OCT volume 5 years before strokes occur to predict stroke;
This is a totally different project.
   E  use retina layer while keeping its layer curvature without flatting;
Somehow it's same as C. Let's see the results from the first experiment first.







# Nov 24th, 2020
Statistics on Congnitive$:

Cognitive Tag on Dataset:
                #cases    min  mean     max
training:       1760      5    24.80    30
validaiton:     473       4    26.11    30
test:           490       6    26.46    30

python3.7 statisticsDataSet.py /home/hxie1/data/BES_3K/GTs/trainID_delNonExist_delErrWID_excludeMGM.csv Cognitive$ number 99
total 1807 raw IDs in file /home/hxie1/data/BES_3K/GTs/trainID_delNonExist_delErrWID_excludeMGM.csv
values for Cognitive$ have 1760 records
min=5.0; mean=24.79659090909091; max=30.0
 emptyValueIDList =
['287', '828', '1527', '1696', '2311', '2596', '3502', '4170', '4188', '4192', '4231', '4239', '4266', '4287', '4290', '4387', '4388', '4417', '4528', '4550', '4627', '4683', '4696', '4714', '4717', '4756', '4794', '4795', '4816', '4819', '4961', '4981', '4995', '5033', '5034', '5175', '5529', '6985', '31066', '34162', '34164', '34165', '34166', '34167', '34169', '34173', '120032']

python3.7 statisticsDataSet.py /home/hxie1/data/BES_3K/GTs/validationID_delNonExist_delErrWID_excludeMGM.csv Cognitive$ number 99
total 481 raw IDs in file /home/hxie1/data/BES_3K/GTs/validationID_delNonExist_delErrWID_excludeMGM.csv
values for Cognitive$ have 473 records
min=4.0; mean=26.11416490486258; max=30.0
 emptyValueIDList =
['4184', '4253', '4549', '4822', '4969', '5239', '34065', '34170']

python3.7 statisticsDataSet.py /home/hxie1/data/BES_3K/GTs/testID_delNonExist_delErrWID_excludeMGM.csv Cognitive$ number 99
total 502 raw IDs in file /home/hxie1/data/BES_3K/GTs/testID_delNonExist_delErrWID_excludeMGM.csv
values for Cognitive$ have 490 records
min=6.0; mean=26.46734693877551; max=30.0
 emptyValueIDList =
['551', '1186', '4182', '4187', '4191', '4475', '4477', '4682', '4779', '4913', '5021', '5174']





==================================
Hypertension data: 1: 1915; 0: 1535
input: 62-OCT
output: {0,1}

age range: [50,91], total 42 ranges


plan data division:
    training,   validation,    test,    sum
0,    1075  ,        230,     230,    1535
1,    1341  ,        287,     287,    1915
sum,  2416  ,        517,     517,    3450

Real data division according to hypertension:
    training,   validation,    test,    sum
0,    1007  ,        264,     264,    1535
1,    1257  ,        329,     329,    1915
sum,  2264  ,        593,     593,    3450

perAgeRange choice:
0,                    5-6       5-6
1,                    6-7       6-7

==========================================================================
=============Check Volumes and Clinical ID correspondence================
(base) [c-xwu000:dataPrepare]#python3.7 checkFileExist.py /home/hxie1/data/BES_3K/GTs/testID.csv
total 593 IDs in /home/hxie1/data/BES_3K/GTs/testID.csv
total 3288 OD volumes in /home/hxie1/data/BES_3K/raw
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/563_OD_5953_Volume', '/home/hxie1/data/BES_3K/raw/563_OD_5957_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/1426_OD_16481_Volume', '/home/hxie1/data/BES_3K/raw/1426_OD_16511_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/6892_OD_22210_Volume', '/home/hxie1/data/BES_3K/raw/6892_OD_27754_Volume']
find 560 corresponding volumes with ID
NonExistIDList: ['294', '365', '526', '528', '651', '1303', '1988', '2242', '2449', '3622', '4087', '4092', '4149', '4943', '5874', '6002', '6304', '6973', '32085', '34030', '34132', '34176', '110016', '110162', '110177', '110186', '110187', '120074', '170079', '170088']
total 30 IDs nonexist
output /home/hxie1/data/BES_3K/GTs/testID_delNonExist.csv
(base) [c-xwu000:dataPrepare]#python3.7 checkFileExist.py /home/hxie1/data/BES_3K/GTs/validationID.csv
total 593 IDs in /home/hxie1/data/BES_3K/GTs/validationID.csv
total 3288 OD volumes in /home/hxie1/data/BES_3K/raw
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/82_OD_2614_Volume', '/home/hxie1/data/BES_3K/raw/82_OD_2791_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/179_OD_4915_Volume', '/home/hxie1/data/BES_3K/raw/179_OD_4914_Volume', '/home/hxie1/data/BES_3K/raw/179_OD_4907_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/1703_OD_16532_Volume', '/home/hxie1/data/BES_3K/raw/1703_OD_16571_Volume', '/home/hxie1/data/BES_3K/raw/1703_OD_16531_Volume', '/home/hxie1/data/BES_3K/raw/1703_OD_16582_Volume', '/home/hxie1/data/BES_3K/raw/1703_OD_16585_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/5191_OD_29751_Volume', '/home/hxie1/data/BES_3K/raw/5191_OD_29755_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/34127_OD_24960_Volume', '/home/hxie1/data/BES_3K/raw/34127_OD_26784_Volume']
find 548 corresponding volumes with ID
NonExistIDList: ['88', '92', '203', '284', '1264', '1962', '1989', '2845', '4009', '4016', '4030', '4070', '4079', '4125', '4498', '4783', '4801', '4856', '4937', '4938', '4949', '5146', '5470', '5542', '5745', '6278', '6966', '32153', '33085', '34133', '34168', '34632', '110015', '120037', '120051', '120087', '120174', '170065', '170075', '170222']
total 40 IDs nonexist
output /home/hxie1/data/BES_3K/GTs/validationID_delNonExist.csv
(base) [c-xwu000:dataPrepare]#python3.7 checkFileExist.py /home/hxie1/data/BES_3K/GTs/trainID.csv
total 2264 IDs in /home/hxie1/data/BES_3K/GTs/trainID.csv
total 3288 OD volumes in /home/hxie1/data/BES_3K/raw
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/123_OD_25375_Volume', '/home/hxie1/data/BES_3K/raw/123_OD_1936_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/378_OD_954_Volume', '/home/hxie1/data/BES_3K/raw/378_OD_958_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/600_OD_4409_Volume', '/home/hxie1/data/BES_3K/raw/600_OD_4480_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/773_OD_5087_Volume', '/home/hxie1/data/BES_3K/raw/773_OD_5100_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/1064_OD_8896_Volume', '/home/hxie1/data/BES_3K/raw/1064_OD_8892_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/1070_OD_25149_Volume', '/home/hxie1/data/BES_3K/raw/1070_OD_16613_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/1296_OD_9602_Volume', '/home/hxie1/data/BES_3K/raw/1296_OD_24884_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/1536_OD_11367_Volume', '/home/hxie1/data/BES_3K/raw/1536_OD_11364_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/1690_OD_15989_Volume', '/home/hxie1/data/BES_3K/raw/1690_OD_15976_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/1947_OD_14086_Volume', '/home/hxie1/data/BES_3K/raw/1947_OD_13585_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/2293_OD_10524_Volume', '/home/hxie1/data/BES_3K/raw/2293_OD_10533_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/4479_OD_31798_Volume', '/home/hxie1/data/BES_3K/raw/4479_OD_31794_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/4973_OD_29833_Volume', '/home/hxie1/data/BES_3K/raw/4973_OD_29837_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/5152_OD_25166_Volume', '/home/hxie1/data/BES_3K/raw/5152_OD_25157_Volume', '/home/hxie1/data/BES_3K/raw/5152_OD_25171_Volume', '/home/hxie1/data/BES_3K/raw/5152_OD_25169_Volume', '/home/hxie1/data/BES_3K/raw/5152_OD_25167_Volume', '/home/hxie1/data/BES_3K/raw/5152_OD_25168_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/5834_OD_16804_Volume', '/home/hxie1/data/BES_3K/raw/5834_OD_16797_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/6049_OD_19216_Volume', '/home/hxie1/data/BES_3K/raw/6049_OD_20607_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/6253_OD_20370_Volume', '/home/hxie1/data/BES_3K/raw/6253_OD_20367_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/6963_OD_22638_Volume', '/home/hxie1/data/BES_3K/raw/6963_OD_22651_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/32009_OD_9268_Volume', '/home/hxie1/data/BES_3K/raw/32009_OD_12398_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/32132_OD_15813_Volume', '/home/hxie1/data/BES_3K/raw/32132_OD_15817_Volume', '/home/hxie1/data/BES_3K/raw/32132_OD_15812_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/33019_OD_7226_Volume', '/home/hxie1/data/BES_3K/raw/33019_OD_7229_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/34174_OD_31686_Volume', '/home/hxie1/data/BES_3K/raw/34174_OD_31683_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/34540_OD_27868_Volume', '/home/hxie1/data/BES_3K/raw/34540_OD_27872_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/34623_OD_28790_Volume', '/home/hxie1/data/BES_3K/raw/34623_OD_28817_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/120090_OD_3733_Volume', '/home/hxie1/data/BES_3K/raw/120090_OD_8398_Volume']
find 2034 corresponding volumes with ID
NonExistIDList: ['60', '289', '290', '315', '328', '333', '341', '349', '357', '530', '576', '577', '592', '626', '671', '696', '719', '755', '756', '900', '910', '911', '969', '1088', '1213', '1217', '1340', '1342', '1353', '1354', '1461', '1476', '1482', '1513', '1532', '1587', '1616', '1642', '1647', '1675', '1676', '1719', '1720', '1724', '1763', '1794', '1802', '1870', '1940', '1968', '1969', '2011', '2014', '2035', '2036', '2045', '2057', '2061', '2092', '2100', '2101', '2106', '2107', '2112', '2120', '2121', '2122', '2123', '2128', '2150', '2157', '2200', '2207', '2243', '2261', '2392', '2411', '2422', '2426', '2428', '2450', '2455', '2466', '2573', '2574', '2594', '2671', '2681', '2698', '2743', '2753', '2775', '2864', '3603', '3604', '3606', '3609', '3621', '4014', '4039', '4049', '4078', '4082', '4083', '4114', '4117', '4145', '4152', '4174', '4221', '4241', '4262', '4296', '4318', '4372', '4413', '4523', '4811', '4857', '4892', '4895', '4916', '4941', '4942', '4945', '4948', '4994', '5024', '5047', '5110', '5200', '5213', '5546', '5728', '5830', '5835', '5897', '5984', '6093', '6300', '6649', '6679', '6782', '6843', '6869', '6982', '7019', '31026', '31034', '31038', '31143', '32056', '32059', '32102', '32106', '32115', '32123', '32131', '32133', '32148', '32151', '32152', '32154', '32160', '32161', '34045', '34136', '34553', '34613', '34626', '110002', '110009', '110010', '110018', '110062', '110074', '110115', '110128', '120004', '120007', '120008', '120015', '120041', '120059', '120104', '120112', '120116', '120146', '120153', '120155', '120161', '120180', '120198', '120225', '120245', '120253', '120258', '140014', '140015', '170069', '170083', '170084', '170097', '170098', '170117']
total 205 IDs nonexist
output /home/hxie1/data/BES_3K/GTs/trainID_delNonExist.csv
(base) [c-xwu000:dataPrepare]#

================================Tidy on Oct 2nd 2020===============

About the correspondence between clinical data and OD volume images.

Summary:
1  From the BES clinical excel file, there are 3450 IDs with hypertension ground truth {0,1};
2  5 original IDs use ????.1 float ID, Other use integer ID; (as Notes for future)
3  In above 3450 IDs, there are 275 IDs without corresponding OD volume images;
4  In above 3450 IDs, there are 33 IDs with multiple different OD volume images;
5  I directly do not use 275+33= 308 IDs , which make total data set of 3142 IDs for training, validation and test;
6  In 3142 patients: training 2034; validation 548; test 560;

ID list without OD volume images:
['60', '289', '290', '315', '328', '333', '341', '349', '357', '530', '576', '577', '592', '626', '671', '696', '719',
'755', '756', '900', '910', '911', '969', '1088', '1213', '1217', '1340', '1342', '1353', '1354', '1461', '1476', '1482',
'1513', '1532', '1587', '1616', '1642', '1647', '1675', '1676', '1719', '1720', '1724', '1763', '1794', '1802', '1870',
'1940', '1968', '1969', '2011', '2014', '2035', '2036', '2045', '2057', '2061', '2092', '2100', '2101', '2106', '2107',
'2112', '2120', '2121', '2122', '2123', '2128', '2150', '2157', '2200', '2207', '2243', '2261', '2392', '2411', '2422',
'2426', '2428', '2450', '2455', '2466', '2573', '2574', '2594', '2671', '2681', '2698', '2743', '2753', '2775', '2864',
'3603', '3604', '3606', '3609', '3621', '4014', '4039', '4049', '4078', '4082', '4083', '4114', '4117', '4145', '4152',
'4174', '4221', '4241', '4262', '4296', '4318', '4372', '4413', '4523', '4811', '4857', '4892', '4895', '4916', '4941',
'4942', '4945', '4948', '4994', '5024', '5047', '5110', '5200', '5213', '5546', '5728', '5830', '5835', '5897', '5984',
'6093', '6300', '6649', '6679', '6782', '6843', '6869', '6982', '7019', '31026', '31034', '31038', '31143', '32056',
'32059', '32102', '32106', '32115', '32123', '32131', '32133', '32148', '32151', '32152', '32154', '32160', '32161',
'34045', '34136', '34553', '34613', '34626', '110002', '110009', '110010', '110018', '110062', '110074', '110115',
'110128', '120004', '120007', '120008', '120015', '120041', '120059', '120104', '120112', '120116', '120146', '120153',
'120155', '120161', '120180', '120198', '120225', '120245', '120253', '120258', '140014', '140015', '170069', '170083',
'170084', '170097', '170098', '170117', '88', '92', '203', '284', '1264', '1962', '1989', '2845', '4009', '4016', '4030',
 '4070', '4079', '4125', '4498', '4783', '4801', '4856', '4937', '4938', '4949', '5146', '5470', '5542', '5745', '6278',
 '6966', '32153', '33085', '34133', '34168', '34632', '110015', '120037', '120051', '120087', '120174', '170065', '170075',
 '170222', '294', '365', '526', '528', '651', '1303', '1988', '2242', '2449', '3622', '4087', '4092', '4149', '4943',
 '5874', '6002', '6304', '6973', '32085', '34030', '34132', '34176', '110016', '110162', '110177', '110186', '110187',
 '120074', '170079', '170088']

Same ID has mulitple different OD volume images:
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/123_OD_25375_Volume', '/home/hxie1/data/BES_3K/raw/123_OD_1936_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/378_OD_954_Volume', '/home/hxie1/data/BES_3K/raw/378_OD_958_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/600_OD_4409_Volume', '/home/hxie1/data/BES_3K/raw/600_OD_4480_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/773_OD_5087_Volume', '/home/hxie1/data/BES_3K/raw/773_OD_5100_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/1064_OD_8896_Volume', '/home/hxie1/data/BES_3K/raw/1064_OD_8892_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/1070_OD_25149_Volume', '/home/hxie1/data/BES_3K/raw/1070_OD_16613_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/1296_OD_9602_Volume', '/home/hxie1/data/BES_3K/raw/1296_OD_24884_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/1536_OD_11367_Volume', '/home/hxie1/data/BES_3K/raw/1536_OD_11364_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/1690_OD_15989_Volume', '/home/hxie1/data/BES_3K/raw/1690_OD_15976_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/1947_OD_14086_Volume', '/home/hxie1/data/BES_3K/raw/1947_OD_13585_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/2293_OD_10524_Volume', '/home/hxie1/data/BES_3K/raw/2293_OD_10533_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/4479_OD_31798_Volume', '/home/hxie1/data/BES_3K/raw/4479_OD_31794_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/4973_OD_29833_Volume', '/home/hxie1/data/BES_3K/raw/4973_OD_29837_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/5152_OD_25166_Volume', '/home/hxie1/data/BES_3K/raw/5152_OD_25157_Volume',
                    '/home/hxie1/data/BES_3K/raw/5152_OD_25171_Volume', '/home/hxie1/data/BES_3K/raw/5152_OD_25169_Volume',
                    '/home/hxie1/data/BES_3K/raw/5152_OD_25167_Volume', '/home/hxie1/data/BES_3K/raw/5152_OD_25168_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/5834_OD_16804_Volume', '/home/hxie1/data/BES_3K/raw/5834_OD_16797_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/6049_OD_19216_Volume', '/home/hxie1/data/BES_3K/raw/6049_OD_20607_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/6253_OD_20370_Volume', '/home/hxie1/data/BES_3K/raw/6253_OD_20367_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/6963_OD_22638_Volume', '/home/hxie1/data/BES_3K/raw/6963_OD_22651_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/32009_OD_9268_Volume', '/home/hxie1/data/BES_3K/raw/32009_OD_12398_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/32132_OD_15813_Volume', '/home/hxie1/data/BES_3K/raw/32132_OD_15817_Volume',
                    '/home/hxie1/data/BES_3K/raw/32132_OD_15812_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/33019_OD_7226_Volume', '/home/hxie1/data/BES_3K/raw/33019_OD_7229_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/34174_OD_31686_Volume', '/home/hxie1/data/BES_3K/raw/34174_OD_31683_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/34540_OD_27868_Volume', '/home/hxie1/data/BES_3K/raw/34540_OD_27872_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/34623_OD_28790_Volume', '/home/hxie1/data/BES_3K/raw/34623_OD_28817_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/120090_OD_3733_Volume', '/home/hxie1/data/BES_3K/raw/120090_OD_8398_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/82_OD_2614_Volume', '/home/hxie1/data/BES_3K/raw/82_OD_2791_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/179_OD_4915_Volume', '/home/hxie1/data/BES_3K/raw/179_OD_4914_Volume',
                    '/home/hxie1/data/BES_3K/raw/179_OD_4907_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/1703_OD_16532_Volume', '/home/hxie1/data/BES_3K/raw/1703_OD_16571_Volume',
                   '/home/hxie1/data/BES_3K/raw/1703_OD_16531_Volume', '/home/hxie1/data/BES_3K/raw/1703_OD_16582_Volume',
                   '/home/hxie1/data/BES_3K/raw/1703_OD_16585_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/5191_OD_29751_Volume', '/home/hxie1/data/BES_3K/raw/5191_OD_29755_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/34127_OD_24960_Volume', '/home/hxie1/data/BES_3K/raw/34127_OD_26784_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/563_OD_5953_Volume', '/home/hxie1/data/BES_3K/raw/563_OD_5957_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/1426_OD_16481_Volume', '/home/hxie1/data/BES_3K/raw/1426_OD_16511_Volume']
Mulitple ID files: ['/home/hxie1/data/BES_3K/raw/6892_OD_22210_Volume', '/home/hxie1/data/BES_3K/raw/6892_OD_27754_Volume']

# ID name strange:
ID: 5320, and 5320.1; 6084 and 6084.1 are different patients

# original raw data contain .1 volume:
ls -ld *.*_Volume
drwxr-xr-x 2 hxie1 Graduate-College-Students 4096 Jun 30 13:29 2697.1_OD_7130_Volume
drwxr-xr-x 2 hxie1 Graduate-College-Students 4096 Jun 30 13:27 2697.1_OS_7136_Volume
drwxr-xr-x 2 hxie1 Graduate-College-Students 4096 Jun 30 13:32 4453.1_OD_23184_Volume
drwxr-xr-x 2 hxie1 Graduate-College-Students 4096 Jun 30 13:31 4453.1_OS_23187_Volume
drwxr-xr-x 2 hxie1 Graduate-College-Students 4096 Jun 30 13:30 4912.1_OD_30008_Volume
drwxr-xr-x 2 hxie1 Graduate-College-Students 4096 Jun 30 13:34 4912.1_OS_30012_Volume
drwxr-xr-x 2 hxie1 Graduate-College-Students 4096 Jun 30 13:25 5320.1_OD_26315_Volume
drwxr-xr-x 2 hxie1 Graduate-College-Students 4096 Jun 30 13:27 5320.1_OS_26320_Volume
drwxr-xr-x 2 hxie1 Graduate-College-Students 4096 Jun 30 13:32 6084.1_OD_17542_Volume
drwxr-xr-x 2 hxie1 Graduate-College-Students 4096 Jun 30 13:33 6084.1_OS_17546_Volume

As voluem image save in integer Id directory, all above *.1 ID change 9*1 ID, eg. 2697.1 -> 926971
modify:
1  modify clinincal data 5 rows in the BESClinicalGT_Analysis.xlsx
2  modify 10 volume names below: eg. 2697.1 -> 926971;
    /home/hxie1/data/BES_3K/raw/2697.1_OD_7130_Volume,
    /home/hxie1/data/BES_3K/raw/2697.1_OS_7136_Volume,
    /home/hxie1/data/BES_3K/raw/4453.1_OD_23184_Volume
    /home/hxie1/data/BES_3K/raw/4453.1_OS_23187_Volume
    /home/hxie1/data/BES_3K/raw/4912.1_OD_30008_Volume
    /home/hxie1/data/BES_3K/raw/4912.1_OS_30012_Volume
    /home/hxie1/data/BES_3K/raw/5320.1_OD_26315_Volume
    /home/hxie1/data/BES_3K/raw/5320.1_OS_26320_Volume
    /home/hxie1/data/BES_3K/raw/6084.1_OD_17542_Volume
    /home/hxie1/data/BES_3K/raw/6084.1_OS_17546_Volume


below volumes are original *.1*_Volume:
[c-xwu000:raw]#ls -ld 9????1_*_Volume
drwxr-xr-x 2 hxie1 Graduate-College-Students 4096 Jun 30 13:29 926971_OD_7130_Volume
drwxr-xr-x 2 hxie1 Graduate-College-Students 4096 Jun 30 13:27 926971_OS_7136_Volume
drwxr-xr-x 2 hxie1 Graduate-College-Students 4096 Jun 30 13:32 944531_OD_23184_Volume
drwxr-xr-x 2 hxie1 Graduate-College-Students 4096 Jun 30 13:31 944531_OS_23187_Volume
drwxr-xr-x 2 hxie1 Graduate-College-Students 4096 Jun 30 13:30 949121_OD_30008_Volume
drwxr-xr-x 2 hxie1 Graduate-College-Students 4096 Jun 30 13:34 949121_OS_30012_Volume
drwxr-xr-x 2 hxie1 Graduate-College-Students 4096 Jun 30 13:25 953201_OD_26315_Volume
drwxr-xr-x 2 hxie1 Graduate-College-Students 4096 Jun 30 13:27 953201_OS_26320_Volume
drwxr-xr-x 2 hxie1 Graduate-College-Students 4096 Jun 30 13:32 960841_OD_17542_Volume
drwxr-xr-x 2 hxie1 Graduate-College-Students 4096 Jun 30 13:33 960841_OS_17546_Volume

Oct 2nd, 2020
Data division and basic statistics before coding:
below bracket() indicates patients number.

                    Training(2034)         Validation(548)     Test(560)
value               0,       1 ,          0,        1,       0,      1
hypertension:       44.4%  55.6%         44.9%     55.1%    44.3%   55.7%

                    1,       2 ,          1,        2,       1,       2
gender:             42.8%,  57.2%,       45.6%    54.4%,    45.4%,  54.6%


                      Training(2034)         Validation(548)            Test(560)
value               min,   avg,    max,      min,  avg,   max,         min, avg, max
age                 50,    64.0,   93,       50,   60.6,  88,          50,  64.5, 87


                       Training(1853)           Validation(547)              Test(560)
value               min,   avg,    max,      min,   avg,   max,         min,   avg,   max
AxialLength         18.96, 23.22, 30.88      19.39, 23.25, 30.69        21.09, 23.25, 26.76


                       Training(2033)           Validation(548)              Test(560)
value               min,   avg,    max,      min,   avg,   max,         min,   avg,   max
BP_Systolic:        78 ,   129 ,   217       74,    130,   216          70,    130,   205


                       Training(2034)           Validation(548)              Test(560)
value               min,   avg,    max,      min,   avg,   max,         min,   avg,   max
BP_Diastolic:       31,    69 ,    117       36,    69,    118          38,    70,   113


# Oct 3rd, 2020:
# check all volumes has 31 slices from the *_DelNonexist.csv list
(base) [c-xwu000:dataPrepare]#python3.7 checkFileExist.py /home/hxie1/data/BES_3K/GTs/trainID_delNonExist.csv
total 2034 IDs in /home/hxie1/data/BES_3K/GTs/trainID_delNonExist.csv
total 3252 OD volumes in /home/hxie1/data/BES_3K/W512NumpyVolumes
find 2031 corresponding volumes with ID
NonExistIDList: ['574', '2750', '120035']
total 3 IDs nonexist
output /home/hxie1/data/BES_3K/GTs/trainID_delNonExist_final.csv
(base) [c-xwu000:dataPrepare]#python3.7 checkFileExist.py /home/hxie1/data/BES_3K/GTs/validationID_delNonExist.csv
total 548 IDs in /home/hxie1/data/BES_3K/GTs/validationID_delNonExist.csv
total 3252 OD volumes in /home/hxie1/data/BES_3K/W512NumpyVolumes
find 546 corresponding volumes with ID
NonExistIDList: ['358', '1207']
total 2 IDs nonexist
output /home/hxie1/data/BES_3K/GTs/validationID_delNonExist_final.csv
(base) [c-xwu000:dataPrepare]#python3.7 checkFileExist.py /home/hxie1/data/BES_3K/GTs/testID_delNonExist.csv
total 560 IDs in /home/hxie1/data/BES_3K/GTs/testID_delNonExist.csv
total 3252 OD volumes in /home/hxie1/data/BES_3K/W512NumpyVolumes
find 559 corresponding volumes with ID
NonExistIDList: ['367']
total 1 IDs nonexist
output /home/hxie1/data/BES_3K/GTs/testID_delNonExist_final.csv

Final dataset division in the *_final.csv
train: 2031; validation: 546;  Test: 559;

# Oct 5th, 2020
(base) [c-xwu000:dataPrepare]#python3.7 ./statisticsDataSet.py /home/hxie1/data/BES_3K/GTs/trainID_delNonExist_final.csv hypertension_bp_plus_history$ binary
total 2031 raw IDs in file /home/hxie1/data/BES_3K/GTs/trainID_delNonExist_final.csv
values for hypertension_bp_plus_history$ have 2031 records
0 rate: 0.4441161989167898; 1 rate: 0.5558838010832102

total 546 raw IDs in file /home/hxie1/data/BES_3K/GTs/validationID_delNonExist_final.csv
values for hypertension_bp_plus_history$ have 546 records
0 rate: 0.45054945054945056; 1 rate: 0.5494505494505495

(base) [c-xwu000:dataPrepare]#python3.7 statisticsDataSet.py /home/hxie1/data/BES_3K/GTs/testID_delNonExist_final.csv hypertension_bp_plus_history$ binary
total 559 raw IDs in file /home/hxie1/data/BES_3K/GTs/testID_delNonExist_final.csv
values for hypertension_bp_plus_history$ have 559 records
0 rate: 0.44364937388193204; 1 rate: 0.556350626118068



# Oct 6th, 2020
tail a small dataset for pretrain
train: 200, validation: 50
which are extracted from the first 200, and first 50 from the final dataset.
(base) [c-xwu000:dataPrepare]#python3.7 ./statisticsDataSet.py /home/hxie1/data/BES_3K/GTs/trainID_delNonExist_final_small.csv hypertension_bp_plus_history$ binary
total 200 raw IDs in file /home/hxie1/data/BES_3K/GTs/trainID_delNonExist_final_small.csv
values for hypertension_bp_plus_history$ have 200 records
0 rate: 0.36; 1 rate: 0.64

(base) [c-xwu000:dataPrepare]#python3.7 ./statisticsDataSet.py /home/hxie1/data/BES_3K/GTs/validationID_delNonExist_final_small.csv hypertension_bp_plus_history$ binary
total 50 raw IDs in file /home/hxie1/data/BES_3K/GTs/validationID_delNonExist_final_small.csv
values for hypertension_bp_plus_history$ have 50 records
0 rate: 0.28; 1 rate: 0.72

# Oct 8th, 2020
delNonExist_final data:
training: 2031;  0: 44.4%;  1: 55.6%;
validation: 546; 0: 45.1%;  1: 54.9%;
test:     559;   0: 44.4%;  1: 55.6%;

A brief:
1 It needs 40 mins training for one epoch with an input of 31 slices per patients; It is unrealistic for training;
2 data set:
  training: 2031;  0: 44.4%;  1: 55.6%;
  validation: 546; 0: 45.1%;  1: 54.9%;
   test:     559;   0: 44.4%;  1: 55.6%;
3 Now I changed input as one middle slice of 31 slices of OD eye,
  it need one minute per epoch for VGG network; and 0.5 min per peoch for mobileNetV3;
4 Using mobileNet V3, it can get training accuracy 100% in about 400 epochs; but validation accuracy get stuck at 60%;
5 It shows nework at training, but overfiting, which is difefrent from Ovarian cancer project;
6 In future 2 days, I will spent time to reduce its overfitting;

If you are available, you may tell me your time when I can show some training result to you.

# Oct 8th, 2020
Experiment Analysis: for center slice as Input=====================================================================================
            Network                 Pooling     InputActivation LR     dropout  weightDecay    FC            OutputC     trainAccGet70%  trainAccGet100%  validation
20201008_A: Conv2DFeatureNet        Avg         True            0.1    0.5      None        [512, 256, 1]   1024        96              166             57% first big oscillaltion, plane
20201008_B: MobileNetV3_OCT2SysD    Avg         True            0.001  0.5      None        [512, 256, 1]   1024        272             418             56% small oscillation
20201008_C: MobileNetV3_OCT2SysD    Avg         False           0.01   0.5      1e-5        [512, 256, 1]   1024        29              160             57% later stable
20201008_D: Conv2DFeatureNet        Avg         False           0.1    0.5      None        [512, 256, 1]   1024        107             176             56% oscillation
20201008_G: MobileNetV3_OCT2SysD    Avg         False           0.01   0.5*2    1e-4        [512, 256, 1]   1024        29              121             55% oscillation ;  this is improved version of _C.
20201008_H: MobileNetV3_OCT2SysD    Avg         False           0.01   0.8      1e-3        [512,1]         1024        18              101             56% later stable;
20201009_A: moibleNetv3_small       Avg         False           0.01   0.5      1e-2        [64,1]          128         8               40              55% oscillation;
20201009_B: mobileNetv3_small       Max         False           0.01   0.8      1e-1        [64,1]          128         INF             INF             55%, (looks underfitting)
20201009_C: mobileNetv3_small       Max         False           0.01   0.5      1e-2        [64,1]          128         18              134             52%
*20201009_D: mobileNetv3_small       Max         False           0.01   0.8      1e-2        [64,1]          128         27              130             57.69% (Good basis)
20201009_E: mobileNetv3_small       Max         False           0.01   0.5      1e-1        [64,1]          128         INF             INF             55%, majority
20201009_F: mobileNetv3_small       Avg         False           0.01   0.5      1e-1        [64,1]          128         17              INF             55%, majority
20201009_G: mobileNetv3_small       Max         False           0.01   0.2      1e-1        [64,1]          128         INF             INF             55%, majority
20201009_H: mobileNetv3_small       Avg         False           0.01   0.8      1e-2        [64,1]          128         10              64              58%
20201009_I: mobileNetv3_small       IQR         False           0.01   0.8      1e-2        [64,1]          128         37              105             58%
20201009_J: mobileNetv3_small       Max         False           0.01   0.8      1e-2        [48,1]          96          29              127             53%
20201009_K: mobileNetv3_small       Avg         False           0.01   0.8      1e-2        [48,1]          96          11              70              57%
20201009_L: mobileNetv3_small       Avg         False           0.01   0.8      1e-2        [24,1]          48          9               135             56%
20201009_M: mobileNetv3_small       Max         False           0.01   0.8      1e-2        [24,1]          48          44              600             56%
20201009_N: mobileNetv3_small       Max         False           0.01   0.2      1e-2        [12,1]          24          26              153             54%
20201009_O: mobileNetv3_small       Avg         False           0.01   0.2      1e-2        [12,1]          24          8               74              57%
20201009_P: mobileNetv3_small       Max         False           0.01   0.2      1e-2        [1]             48          18              100             57%
20201009_Q: mobileNetv3_small       Max         False           0.01   0.2      1e-2        [1]             24          22              182             58% (Good result)
20201009_R: mobileNetv3_small       Avg         False           0.01   0.2      1e-2        [1]             12          5               70%             57%

Comparison:    OCT2SysD                OvarianCancer
data Size:      3136                    168
predict:        judge current status;   Predict future;
Image model:    Similar;                Various, Each patient cancer is unique;
Classification: Binary;                 Binary;
Network:        MobileNetV3;            MobileNetV3;


# Oct 10th, 2020
Use randoom single slice as input to network:

(base) [c-xwu000:dataPrepare]#python3.7 ./statisticsDataSet.py /home/hxie1/data/BES_3K/GTs/trainID_delNonExist.csv hypertension_bp_plus_history$  binary
total 2034 raw IDs in file /home/hxie1/data/BES_3K/GTs/trainID_delNonExist.csv
values for hypertension_bp_plus_history$ have 2034 records
0 rate: 0.443952802359882; 1 rate: 0.556047197640118

(base) [c-xwu000:dataPrepare]#python3.7 ./statisticsDataSet.py /home/hxie1/data/BES_3K/GTs/validationID_delNonExist.csv hypertension_bp_plus_history$  binary
total 548 raw IDs in file /home/hxie1/data/BES_3K/GTs/validationID_delNonExist.csv
values for hypertension_bp_plus_history$ have 548 records
0 rate: 0.4489051094890511; 1 rate: 0.551094890510949

(base) [c-xwu000:dataPrepare]#python3.7 ./statisticsDataSet.py /home/hxie1/data/BES_3K/GTs/testID_delNonExist.csv hypertension_bp_plus_history$  binary
total 560 raw IDs in file /home/hxie1/data/BES_3K/GTs/testID_delNonExist.csv
values for hypertension_bp_plus_history$ have 560 records
0 rate: 0.44285714285714284; 1 rate: 0.5571428571428572

delNonExist data:
training: 2034;  0: 44.4%;  1: 55.6%;
validation: 548; 0: 44.9%;  1: 55.1%;
test:     560;   0: 44.3%;  1: 55.7%;

delete W=384 image ID:
(base) [c-xwu000:dataPrepare]#python3.7 ./deleteNonStdID.py /home/hxie1/data/BES_3K/GTs/trainID_delNonExist.csv
deleted 1 IDs in /home/hxie1/data/BES_3K/GTs/trainID_delNonExist.csv
(base) [c-xwu000:dataPrepare]#python3.7 ./deleteNonStdID.py /home/hxie1/data/BES_3K/GTs/validationID_delNonExist.csv
No ID deleted.
(base) [c-xwu000:dataPrepare]#python3.7 ./deleteNonStdID.py /home/hxie1/data/BES_3K/GTs/testID_delNonExist.csv
deleted 1 IDs in /home/hxie1/data/BES_3K/GTs/testID_delNonExist.csv
(base) [c-xwu000:dataPrepare]#

20201010, statistics data distribution, with deleting error width ID
training: 2033;  0: 44.4%;  1: 55.6%;
validation: 548; 0: 44.9%;  1: 55.1%;
test:     559;   0: 44.4%;  1: 55.6%;

(base) [c-xwu000:dataPrepare]#python3.7 ./statisticsDataSet.py /home/hxie1/data/BES_3K/GTs/trainID_delNonExist_delErrWID.csv hypertension_bp_plus_history$ binary
total 2033 raw IDs in file /home/hxie1/data/BES_3K/GTs/trainID_delNonExist_delErrWID.csv
values for hypertension_bp_plus_history$ have 2033 records
0 rate: 0.4441711756025578; 1 rate: 0.5558288243974422

(base) [c-xwu000:dataPrepare]#python3.7 ./statisticsDataSet.py /home/hxie1/data/BES_3K/GTs/validationID_delNonExist_delErrWID.csv hypertension_bp_plus_history$ binary
total 548 raw IDs in file /home/hxie1/data/BES_3K/GTs/validationID_delNonExist_delErrWID.csv
values for hypertension_bp_plus_history$ have 548 records
0 rate: 0.4489051094890511; 1 rate: 0.551094890510949

(base) [c-xwu000:dataPrepare]#python3.7 ./statisticsDataSet.py /home/hxie1/data/BES_3K/GTs/testID_delNonExist_delErrWID.csv hypertension_bp_plus_history$ binary
total 559 raw IDs in file /home/hxie1/data/BES_3K/GTs/testID_delNonExist_delErrWID.csv
values for hypertension_bp_plus_history$ have 559 records
0 rate: 0.44364937388193204; 1 rate: 0.556350626118068

=================Use Random Slice as input to Network on Oct 10th, 2020================================================================================================
            Network                 Pooling     InputActivation LR     LRPatience   dropout  weighDecay    FC            OutputC     trainAccGet60%  trainAccGet70%     trainAccGet100%    validation
20201010_A: mobileNetv3_small       Avg         False           0.01   3             0.2     1e-2          [1]           12          150                                                   max60%
20201010_B: mobileNetv3_small       Avg         False           0.01   3             0.8     1e-2          [64,1]        128         161                                                   max60%
20201010_C: mobileNetv3_small       Avg         False           0.01   30            0.2     1e-2          [1]           12          75               1.8K                                 max61.5%
20201010_D: mobileNetv3_small       Avg         False           0.01   30            0.8     1e-2          [64,1]        128         100                                                   max62%

Oct 13th, 2020 13:29
Current running program:
(base) [c-xwu000:network]#ps 941 938 615 642
GPU   PID TTY      STAT   TIME COMMAND
2     615 ?        Rl   9161:56 python3.7 ./OCT2SysD_Train.py ../testConfig/expOCT2SysD_20201012_A.yaml
3     642 ?        Rl   8672:33 python3.7 ./OCT2SysD_Train.py ../testConfig/expOCT2SysD_20201012_B.yaml
1     938 ?        Rl   29848:39 python3.7 ./OCT2SysD_Train.py ../testConfig/expOCT2SysD_20201010_C.yaml
0     941 ?        Rl   29842:02 python3.7 ./OCT2SysD_Train.py ../testConfig/expOCT2SysD_20201010_D.yaml

=================Use Random Slice as input to Network on Oct 10th, 2020, with batch size 107 ========================================================================
            Network                 Pooling     InputActivation LR     LRPatience LrDecayFactor  dropout  weighDecay    FC            OutputC     trainAccGet60%  trainAccGet80%     trainAccGet100%    validation
20201012_A: mobileNetv3_small       Avg         False           0.1    62         0.826          0.8     1e-2          [512,256,1]    1024        50                                                   max60%
20201012_B: mobileNetv3_small       Avg         False           0.1    62         0.826          0.8     1e-2          [256,128,1]    512         36                                                   max61.68%
20201015_A: mobile_small(pretrain)  Avg         False           0.1    5          0.8            0.5     1e-3          [256,128,1]    512         Inf oscillation at 55%
20201015_B: mobileNetv2_small       Avg         False           0.1    5          0.8            0.5     1e-3          [256,128,1]    512         28              INf                                  58%(max60%)
20201015_C: mobileNetv2_small       Avg         False           0.1    4          0.8            0.2     1e-4          [256,128,1]    512         Inf             INf                                  55%
20201016_A: large                   Avg         False           0.1    5          0.8            0.2     1e-4          [512,256,1]    1024        ===Stop===
20201016_B: large (NoGauss)         Avg         False           0.1    5          0.8            0.3     1e-5          [512,256,1]    1024        40                                                   60%
            Above: when validation ACC gets 60%, its TPR 61.5%, TNR 58.5%, threshold 0.5027

# below expeiment add gaussian and salt pepper noise:
            Network            Notes     Pooling     InputActivation LR     LRPatience LrDecayFactor  dropout  weighDecay    FC            OutputC     trainingAcc  validation
20201017_A: Large                        Avg         False           0.1    6          0.8            0       1e-5          [512,256,1]    1024        63%          ACC61%,TNR45%; TPR75%; Threshold0.44;
20201017_B: Large(No flip aug)           Avg         False           0.1    6          0.8            0       1e-5          [512,256,1]    1024        64%          ACC61%,TNR48%; TPR72%; Threshold0.48;
20201017_C: large                        Avg         False           0.1    6          0.8            0.2     1e-5          [512,256,1]    1024        63.8%        ACC62%,TNR49%; TPR73%; Threshold0.44; (best)
            batchsize=40
20201017_D: Large                        Avg         False           0.1    6          0.8            0.5     1e-5          [512,256,1]    1024        63%          ACC61%,TNR51%; TPR69%; Threshold0.45;
20201019_A: Conv2DFeatureNet             Avg         False           0.1    6          0.8            0.2     1e-5          [512,256,1]    1024
            batchsize =20
20201019_B: Conv2DFeatureNet  ValidAug   Avg         False           0.1    6          0.8            0.2     1e-5          [512,256,1]    1024
            bathsize =20

# Oct 17th, 2020:
for 20201016_B: 4min /epoch

# Oct 20th, 2020:
exclude some patients with disease like below:
1. High myopia (Axiallength_26_ormore_exclude$ =1)
2. Glaucoma (Glaucoma_exclude$ =1)
3. Macula or retinal diseases (Retina_exclude$=1)

tag: excludeMGM (Myopia, Glaucoma, Macula disease)
(base) [c-xwu000:dataPrepare]#python3.7 ./excludeMyopiaGlaucomaMaculaD4.py  /home/hxie1/data/BES_3K/GTs/testID_delNonExist_delErrWID.csv
deleted 57 IDs in /home/hxie1/data/BES_3K/GTs/testID_delNonExist_delErrWID.csv
(base) [c-xwu000:dataPrepare]#python3.7 ./excludeMyopiaGlaucomaMaculaD4.py  /home/hxie1/data/BES_3K/GTs/validationID_delNonExist_delErrWID.csv
deleted 67 IDs in /home/hxie1/data/BES_3K/GTs/validationID_delNonExist_delErrWID.csv
(base) [c-xwu000:dataPrepare]#python3.7 ./excludeMyopiaGlaucomaMaculaD4.py  /home/hxie1/data/BES_3K/GTs/trainID_delNonExist_delErrWID.csv
deleted 226 IDs in /home/hxie1/data/BES_3K/GTs/trainID_delNonExist_delErrWID.csv
(base) [c-xwu000:dataPrepare]#

After deleting MGM,  statistic hypertension:

(base) [c-xwu000:dataPrepare]#python3.7 ./statisticsDataSet.py /home/hxie1/data/BES_3K/GTs/trainID_delNonExist_delErrWID_excludeMGM.csv  hypertension_bp_plus_history$ binary
total 1807 raw IDs in file /home/hxie1/data/BES_3K/GTs/trainID_delNonExist_delErrWID_excludeMGM.csv
values for hypertension_bp_plus_history$ have 1807 records
0 rate: 0.4565578306585501; 1 rate: 0.54344216934145

(base) [c-xwu000:dataPrepare]#python3.7 ./statisticsDataSet.py /home/hxie1/data/BES_3K/GTs/validationID_delNonExist_delErrWID_excludeMGM.csv  hypertension_bp_plus_history$ binary
total 481 raw IDs in file /home/hxie1/data/BES_3K/GTs/validationID_delNonExist_delErrWID_excludeMGM.csv
values for hypertension_bp_plus_history$ have 481 records
0 rate: 0.45322245322245325; 1 rate: 0.5467775467775468

(base) [c-xwu000:dataPrepare]#python3.7 ./statisticsDataSet.py /home/hxie1/data/BES_3K/GTs/testID_delNonExist_delErrWID_excludeMGM.csv  hypertension_bp_plus_history$ binary
total 502 raw IDs in file /home/hxie1/data/BES_3K/GTs/testID_delNonExist_delErrWID_excludeMGM.csv
values for hypertension_bp_plus_history$ have 502 records
0 rate: 0.4342629482071713; 1 rate: 0.5657370517928287

after delete MGM cases: high myopia, Glaucoma, Macula/Retina disease cases:

    dataset		&number &tag0  	&tag1 \\
	training	&1807  	&45.66\% &54.34\%  \\
	validation	&481  	&45.32\% &54.68\%  \\
	test		&502  	&43.43\% &56.57\%  \\

total: 2790 cases.


            Network            Notes     Pooling     InputActivation LR     LRPatience LrDecayFactor  dropout  weighDecay    FC            OutputC     trainingAcc  validation
20201020_A: large                        Avg         False           0.1    6          0.8            0.2     1e-5          [512,256,1]    1024         61%(max)    ACC61%,TNR53%; TPR68%; Threshold0.48;
            batchSize=40
            Validation Augment
            GPU=3

20201020_B: Conv2DFeatureNet             Avg         False           0.1    6          0.8            0.2     1e-5          [512,256,1]    1024        51%          55%(stop)
            bathsize =20
            Validation Augment
            GPU=2
20201020_C: large                        Avg         False           0.5    6          0.8            0.2     1e-5          [512,256,1]    1024        64%(max)     ACC61%,TNR51%; TPR69%; Threshold0.48;
            batchSize=40
            Validation Augment
            GPU=3

20201020_D: Conv2DFeatureNet             Avg         False           0.5    6          0.8            0.2     1e-5          [512,256,1]    1024        61%          57%(stop)
            bathsize =20
            Validation Augment
            GPU=2

20201021_A: large                        Avg         False           1      6          0.8            0.2     1e-5          [512,256,1]    1024       65%(max)      ACC63%,TNR56%; TPR68%; Threshold0.49; (best)
            batchSize=40
            Validation Augment
            GPU=0
            LR=1

20201022_A: large                        Avg         False           2      6           0.8            0.2     1e-5          [512,256,1]    1024      64%(max)      ACC61%,TNR59%; TPR63%; Threshold0.50;
            batchSize=40
            Validation Augment
            GPU=1
            LR=2
            LrSchedular uses sum.

20201022_B: large                        Avg         False           1      6           0.8            0.2     1e-5          [512,256,1]    1024      65(max)       ACC62%,TNR50%; TPR71%; Threshold0.50;             batchSize=40
            Validation Augment
            GPU=2
            LR=1
            LrSchedular uses sum.